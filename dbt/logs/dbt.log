2020-10-20 17:32:06.807623 (MainThread): Running with dbt=0.16.1
2020-10-20 17:32:07.208666 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-20 17:32:07.209744 (MainThread): Tracking: tracking
2020-10-20 17:32:07.233735 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104029c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110be9970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bf43a0>]}
2020-10-20 17:32:07.275619 (MainThread): Partial parsing not enabled
2020-10-20 17:32:07.279055 (MainThread): Parsing macros/core.sql
2020-10-20 17:32:07.311246 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 17:32:07.329939 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 17:32:07.333437 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 17:32:07.370907 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 17:32:07.427963 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 17:32:07.460995 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 17:32:07.465100 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 17:32:07.475829 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 17:32:07.497103 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 17:32:07.511456 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 17:32:07.525088 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 17:32:07.535672 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 17:32:07.537637 (MainThread): Parsing macros/etc/query.sql
2020-10-20 17:32:07.539933 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 17:32:07.543468 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 17:32:07.560950 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 17:32:07.631374 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 17:32:07.635524 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 17:32:07.652634 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 17:32:07.729725 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 17:32:07.733107 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 17:32:07.734912 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 17:32:07.736915 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 17:32:07.741950 (MainThread): Parsing macros/catalog.sql
2020-10-20 17:32:07.764814 (MainThread): Parsing macros/relations.sql
2020-10-20 17:32:07.767296 (MainThread): Parsing macros/adapters.sql
2020-10-20 17:32:07.801501 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 17:32:07.803766 (MainThread): Parsing macros/catalog.sql
2020-10-20 17:32:07.808309 (MainThread): Parsing macros/relations.sql
2020-10-20 17:32:07.811116 (MainThread): Parsing macros/adapters.sql
2020-10-20 17:32:07.839624 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 17:32:07.888601 (MainThread): Partial parsing not enabled
2020-10-20 17:32:07.939573 (MainThread): Acquiring new redshift connection "model.my_new_project.covid19_stats".
2020-10-20 17:32:07.939764 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:07.980410 (MainThread): Acquiring new redshift connection "model.my_new_project.my_first_dbt_model".
2020-10-20 17:32:07.980581 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:07.988226 (MainThread): Acquiring new redshift connection "model.my_new_project.my_second_dbt_model".
2020-10-20 17:32:07.988364 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:08.039710 (MainThread): Acquiring new redshift connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 17:32:08.039856 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:08.073929 (MainThread): Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id".
2020-10-20 17:32:08.074097 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:08.093836 (MainThread): Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id".
2020-10-20 17:32:08.093994 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:08.110329 (MainThread): Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id".
2020-10-20 17:32:08.110527 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:08.125388 (MainThread): Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id".
2020-10-20 17:32:08.125704 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:09.579384 (MainThread): scipy not found, skipping conversion test.
2020-10-20 17:32:09.585834 (MainThread): Found 3 models, 5 tests, 0 snapshots, 0 analyses, 149 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 17:32:09.593504 (MainThread): 
2020-10-20 17:32:09.593955 (MainThread): Acquiring new redshift connection "master".
2020-10-20 17:32:09.594082 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:32:09.631575 (ThreadPoolExecutor-1_0): Acquiring new redshift connection "list_warehouse_dbt_alice".
2020-10-20 17:32:09.631747 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-20 17:32:09.761384 (ThreadPoolExecutor-1_0): Using redshift connection "list_warehouse_dbt_alice".
2020-10-20 17:32:09.761551 (ThreadPoolExecutor-1_0): On list_warehouse_dbt_alice: BEGIN
2020-10-20 17:32:09.761746 (ThreadPoolExecutor-1_0): Connecting to Redshift using 'database' credentials
2020-10-20 17:32:09.762491 (ThreadPoolExecutor-1_0): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "127.0.0.1" and accepting
	TCP/IP connections on port 5439?
'
2020-10-20 17:32:09.762615 (ThreadPoolExecutor-1_0): Error running SQL: BEGIN
2020-10-20 17:32:09.762958 (ThreadPoolExecutor-1_0): Rolling back transaction.
2020-10-20 17:32:09.763113 (ThreadPoolExecutor-1_0): On list_warehouse_dbt_alice: No close available on handle
2020-10-20 17:32:09.763267 (ThreadPoolExecutor-1_0): Error running SQL: macro list_relations_without_caching
2020-10-20 17:32:09.763339 (ThreadPoolExecutor-1_0): Rolling back transaction.
2020-10-20 17:32:09.763944 (MainThread): Connection 'master' was properly closed.
2020-10-20 17:32:09.764053 (MainThread): Connection 'list_warehouse_dbt_alice' was properly closed.
2020-10-20 17:32:09.764179 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "127.0.0.1" and accepting
  	TCP/IP connections on port 5439?
  
2020-10-20 17:32:09.764431 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d848b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110db3280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e468b0>]}
2020-10-20 17:32:09.764724 (MainThread): Flushing usage events
2020-10-20 17:33:02.453989 (MainThread): Running with dbt=0.16.1
2020-10-20 17:33:02.825095 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 17:33:02.841692 (MainThread): Tracking: tracking
2020-10-20 17:33:02.858689 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1200b7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1200dd970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1200e73a0>]}
2020-10-20 17:33:02.928475 (MainThread): Partial parsing not enabled
2020-10-20 17:33:02.932720 (MainThread): Parsing macros/core.sql
2020-10-20 17:33:02.962556 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 17:33:02.983033 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 17:33:02.987782 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 17:33:03.028834 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 17:33:03.090846 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 17:33:03.125692 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 17:33:03.129686 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 17:33:03.140304 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 17:33:03.163017 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 17:33:03.175955 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 17:33:03.190927 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 17:33:03.200575 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 17:33:03.202772 (MainThread): Parsing macros/etc/query.sql
2020-10-20 17:33:03.205203 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 17:33:03.211858 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 17:33:03.229103 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 17:33:03.260540 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 17:33:03.269014 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 17:33:03.279365 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 17:33:03.381242 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 17:33:03.383102 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 17:33:03.384944 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 17:33:03.386922 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 17:33:03.390760 (MainThread): Parsing macros/catalog.sql
2020-10-20 17:33:03.407917 (MainThread): Parsing macros/relations.sql
2020-10-20 17:33:03.409633 (MainThread): Parsing macros/adapters.sql
2020-10-20 17:33:03.440328 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 17:33:03.443141 (MainThread): Parsing macros/catalog.sql
2020-10-20 17:33:03.447811 (MainThread): Parsing macros/relations.sql
2020-10-20 17:33:03.451416 (MainThread): Parsing macros/adapters.sql
2020-10-20 17:33:03.484796 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 17:33:03.534990 (MainThread): Partial parsing not enabled
2020-10-20 17:33:03.582956 (MainThread): Acquiring new redshift connection "model.my_new_project.covid19_stats".
2020-10-20 17:33:03.583111 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:03.615084 (MainThread): Acquiring new redshift connection "model.my_new_project.my_first_dbt_model".
2020-10-20 17:33:03.615234 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:03.623412 (MainThread): Acquiring new redshift connection "model.my_new_project.my_second_dbt_model".
2020-10-20 17:33:03.623562 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:03.671129 (MainThread): Acquiring new redshift connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 17:33:03.671271 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:03.698106 (MainThread): Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id".
2020-10-20 17:33:03.698246 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:03.715527 (MainThread): Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id".
2020-10-20 17:33:03.715674 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:03.728629 (MainThread): Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id".
2020-10-20 17:33:03.728780 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:03.741541 (MainThread): Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id".
2020-10-20 17:33:03.741760 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:04.606157 (MainThread): scipy not found, skipping conversion test.
2020-10-20 17:33:04.611630 (MainThread): Found 3 models, 5 tests, 0 snapshots, 0 analyses, 149 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 17:33:04.617271 (MainThread): 
2020-10-20 17:33:04.618180 (MainThread): Acquiring new redshift connection "master".
2020-10-20 17:33:04.618383 (MainThread): Opening a new connection, currently in state init
2020-10-20 17:33:04.645753 (ThreadPoolExecutor-0_0): Acquiring new redshift connection "list_warehouse".
2020-10-20 17:33:04.645966 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 17:33:04.788916 (ThreadPoolExecutor-0_0): Using redshift connection "list_warehouse".
2020-10-20 17:33:04.789072 (ThreadPoolExecutor-0_0): On list_warehouse: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
2020-10-20 17:33:04.789164 (ThreadPoolExecutor-0_0): Connecting to Redshift using 'database' credentials
2020-10-20 17:33:04.789803 (ThreadPoolExecutor-0_0): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "127.0.0.1" and accepting
	TCP/IP connections on port 5439?
'
2020-10-20 17:33:04.789922 (ThreadPoolExecutor-0_0): Error running SQL: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
2020-10-20 17:33:04.789997 (ThreadPoolExecutor-0_0): Rolling back transaction.
2020-10-20 17:33:04.790089 (ThreadPoolExecutor-0_0): On list_warehouse: No close available on handle
2020-10-20 17:33:04.790229 (ThreadPoolExecutor-0_0): Error running SQL: macro list_schemas
2020-10-20 17:33:04.790484 (ThreadPoolExecutor-0_0): Rolling back transaction.
2020-10-20 17:33:04.791401 (MainThread): Connection 'master' was properly closed.
2020-10-20 17:33:04.791660 (MainThread): Connection 'list_warehouse' was properly closed.
2020-10-20 17:33:04.791852 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "127.0.0.1" and accepting
  	TCP/IP connections on port 5439?
  
2020-10-20 17:33:04.792117 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120255f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1203256a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120315e20>]}
2020-10-20 17:33:04.792327 (MainThread): Flushing usage events
2020-10-20 18:00:35.724034 (MainThread): Running with dbt=0.16.1
2020-10-20 18:00:35.795747 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:00:35.797424 (MainThread): Tracking: tracking
2020-10-20 18:00:35.809749 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116d8aee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116d5f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117154bb0>]}
2020-10-20 18:00:35.830836 (MainThread): Partial parsing not enabled
2020-10-20 18:00:35.833257 (MainThread): Parsing macros/core.sql
2020-10-20 18:00:35.838932 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:00:35.847955 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:00:35.850167 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:00:35.879226 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:00:35.915482 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:00:35.937855 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:00:35.940110 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:00:35.953954 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:00:35.967560 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:00:35.975198 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:00:35.982010 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:00:35.987451 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:00:35.988694 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:00:35.990001 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:00:35.991869 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:00:35.994240 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:00:36.003498 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:00:36.005723 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:00:36.007023 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:00:36.051147 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:00:36.052743 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:00:36.053946 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:00:36.055372 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:00:36.058159 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:00:36.060886 (MainThread): Parsing macros/relations.sql
2020-10-20 18:00:36.072624 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:00:36.090799 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:00:36.109949 (MainThread): Partial parsing not enabled
2020-10-20 18:00:36.140235 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:36.140370 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.155072 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:36.155241 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.160237 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:36.160353 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.187923 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:00:36.188049 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.202897 (MainThread): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id".
2020-10-20 18:00:36.203017 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.211759 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id".
2020-10-20 18:00:36.211864 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.219751 (MainThread): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id".
2020-10-20 18:00:36.219904 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.227486 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id".
2020-10-20 18:00:36.227605 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.747533 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:00:36.751706 (MainThread): Found 3 models, 5 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:00:36.755474 (MainThread): 
2020-10-20 18:00:36.755775 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:00:36.755868 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:00:36.767132 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:00:36.767358 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:00:36.846827 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:00:36.846964 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:00:36.864345 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.02 seconds
2020-10-20 18:00:36.903476 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:00:36.903598 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:00:36.904933 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:00:36.905024 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:00:36.907081 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:00:36.907333 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:00:36.907418 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:00:36.927069 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:00:36.928437 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:00:36.956663 (MainThread): Using postgres connection "master".
2020-10-20 18:00:36.956789 (MainThread): On master: BEGIN
2020-10-20 18:00:36.970372 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:00:36.970546 (MainThread): Using postgres connection "master".
2020-10-20 18:00:36.970638 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:00:37.006939 (MainThread): SQL status: SELECT 0 in 0.04 seconds
2020-10-20 18:00:37.007923 (MainThread): On master: ROLLBACK
2020-10-20 18:00:37.009135 (MainThread): Using postgres connection "master".
2020-10-20 18:00:37.009254 (MainThread): On master: BEGIN
2020-10-20 18:00:37.011310 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:00:37.011464 (MainThread): On master: COMMIT
2020-10-20 18:00:37.011555 (MainThread): Using postgres connection "master".
2020-10-20 18:00:37.011630 (MainThread): On master: COMMIT
2020-10-20 18:00:37.012698 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:00:37.012996 (MainThread): 19:00:37 | Concurrency: 4 threads (target='dev')
2020-10-20 18:00:37.013111 (MainThread): 19:00:37 | 
2020-10-20 18:00:37.023197 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2020-10-20 18:00:37.023356 (Thread-2): Began running node model.my_new_project.covid19_stats
2020-10-20 18:00:37.023539 (Thread-1): 19:00:37 | 1 of 3 START table model public.my_first_dbt_model................... [RUN]
2020-10-20 18:00:37.023676 (Thread-2): 19:00:37 | 2 of 3 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:00:37.024008 (Thread-1): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.024274 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.024366 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:00:37.024462 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:00:37.024558 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2020-10-20 18:00:37.024646 (Thread-2): Compiling model.my_new_project.covid19_stats
2020-10-20 18:00:37.046250 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2020-10-20 18:00:37.047681 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:00:37.048392 (Thread-2): finished collecting timing info
2020-10-20 18:00:37.048635 (Thread-1): finished collecting timing info
2020-10-20 18:00:37.093859 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.095952 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.096045 (Thread-2): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:00:37.096144 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "ingestions"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-10-20 18:00:37.103849 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2020-10-20 18:00:37.106913 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.107087 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "ingestions"."public"."my_first_dbt_model__dbt_backup" cascade
2020-10-20 18:00:37.108977 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-10-20 18:00:37.111321 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2020-10-20 18:00:37.111972 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.112215 (Thread-1): On model.my_new_project.my_first_dbt_model: BEGIN
2020-10-20 18:00:37.113937 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:00:37.114092 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.114176 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "ingestions"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-10-20 18:00:37.115324 (Thread-2): SQL status: DROP VIEW in 0.02 seconds
2020-10-20 18:00:37.118486 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.118695 (Thread-2): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:00:37.120535 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:00:37.123321 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:00:37.124035 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.124206 (Thread-2): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:00:37.126226 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:00:37.126593 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.126694 (Thread-2): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:00:37.277027 (Thread-1): SQL status: SELECT 2 in 0.16 seconds
2020-10-20 18:00:37.279907 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.280082 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "ingestions"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-10-20 18:00:37.282648 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:00:37.283797 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2020-10-20 18:00:37.283959 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.284046 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2020-10-20 18:00:37.288860 (Thread-2): SQL status: CREATE VIEW in 0.16 seconds
2020-10-20 18:00:37.289111 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:00:37.292298 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.293855 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:00:37.293990 (Thread-2): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:00:37.294098 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "ingestions"."public"."my_first_dbt_model__dbt_backup" cascade
2020-10-20 18:00:37.296446 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-10-20 18:00:37.296562 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:00:37.298918 (Thread-1): finished collecting timing info
2020-10-20 18:00:37.299833 (Thread-2): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:00:37.300295 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c56f317-ef93-4d7a-8e00-b2c2ab16e22c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d53d1c0>]}
2020-10-20 18:00:37.300413 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.300657 (Thread-1): 19:00:37 | 1 of 3 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.28s]
2020-10-20 18:00:37.300728 (Thread-2): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:00:37.300888 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2020-10-20 18:00:37.301226 (Thread-4): Began running node model.my_new_project.my_second_dbt_model
2020-10-20 18:00:37.301369 (Thread-4): 19:00:37 | 3 of 3 START view model public.my_second_dbt_model................... [RUN]
2020-10-20 18:00:37.301632 (Thread-4): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.301727 (Thread-4): Opening a new connection, currently in state init
2020-10-20 18:00:37.301811 (Thread-4): Compiling model.my_new_project.my_second_dbt_model
2020-10-20 18:00:37.308412 (Thread-4): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2020-10-20 18:00:37.308614 (Thread-2): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:00:37.310358 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:00:37.310526 (Thread-2): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:00:37.310726 (Thread-4): finished collecting timing info
2020-10-20 18:00:37.316751 (Thread-4): Using postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.316873 (Thread-2): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:00:37.316999 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "ingestions"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-10-20 18:00:37.319168 (Thread-2): finished collecting timing info
2020-10-20 18:00:37.320365 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c56f317-ef93-4d7a-8e00-b2c2ab16e22c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d2a6d30>]}
2020-10-20 18:00:37.320627 (Thread-2): 19:00:37 | 2 of 3 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.30s]
2020-10-20 18:00:37.320750 (Thread-2): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:00:37.336670 (Thread-4): SQL status: DROP VIEW in 0.02 seconds
2020-10-20 18:00:37.339074 (Thread-4): Using postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.339194 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "ingestions"."public"."my_second_dbt_model__dbt_backup" cascade
2020-10-20 18:00:37.340578 (Thread-4): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:00:37.342149 (Thread-4): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2020-10-20 18:00:37.342552 (Thread-4): Using postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.342640 (Thread-4): On model.my_new_project.my_second_dbt_model: BEGIN
2020-10-20 18:00:37.343820 (Thread-4): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:00:37.343943 (Thread-4): Using postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.344021 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "ingestions"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "ingestions"."public"."my_first_dbt_model"
where id = 1
  );

2020-10-20 18:00:37.353329 (Thread-4): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:00:37.355964 (Thread-4): Using postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.356114 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "ingestions"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-10-20 18:00:37.357804 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:00:37.358836 (Thread-4): On model.my_new_project.my_second_dbt_model: COMMIT
2020-10-20 18:00:37.358954 (Thread-4): Using postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.359033 (Thread-4): On model.my_new_project.my_second_dbt_model: COMMIT
2020-10-20 18:00:37.362305 (Thread-4): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:00:37.364208 (Thread-4): Using postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:00:37.364368 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "ingestions"."public"."my_second_dbt_model__dbt_backup" cascade
2020-10-20 18:00:37.366079 (Thread-4): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:00:37.368415 (Thread-4): finished collecting timing info
2020-10-20 18:00:37.369024 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c56f317-ef93-4d7a-8e00-b2c2ab16e22c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d53d4c0>]}
2020-10-20 18:00:37.369238 (Thread-4): 19:00:37 | 3 of 3 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.07s]
2020-10-20 18:00:37.369352 (Thread-4): Finished running node model.my_new_project.my_second_dbt_model
2020-10-20 18:00:37.370359 (MainThread): Using postgres connection "master".
2020-10-20 18:00:37.370470 (MainThread): On master: BEGIN
2020-10-20 18:00:37.371913 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:00:37.372087 (MainThread): On master: COMMIT
2020-10-20 18:00:37.372173 (MainThread): Using postgres connection "master".
2020-10-20 18:00:37.372247 (MainThread): On master: COMMIT
2020-10-20 18:00:37.373558 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:00:37.373902 (MainThread): 19:00:37 | 
2020-10-20 18:00:37.374020 (MainThread): 19:00:37 | Finished running 1 table model, 2 view models in 0.62s.
2020-10-20 18:00:37.374111 (MainThread): Connection 'master' was left open.
2020-10-20 18:00:37.374185 (MainThread): On master: Close
2020-10-20 18:00:37.374285 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was left open.
2020-10-20 18:00:37.374354 (MainThread): On model.my_new_project.my_first_dbt_model: Close
2020-10-20 18:00:37.374441 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:00:37.374507 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:00:37.374593 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was left open.
2020-10-20 18:00:37.374659 (MainThread): On model.my_new_project.my_second_dbt_model: Close
2020-10-20 18:00:37.382598 (MainThread): 
2020-10-20 18:00:37.382763 (MainThread): Completed successfully
2020-10-20 18:00:37.382869 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-10-20 18:00:37.383041 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116d8aee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d538c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d538be0>]}
2020-10-20 18:00:37.383228 (MainThread): Flushing usage events
2020-10-20 18:01:42.286146 (MainThread): Running with dbt=0.16.1
2020-10-20 18:01:42.363967 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-20 18:01:42.374048 (MainThread): Tracking: tracking
2020-10-20 18:01:42.388404 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d94bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcfef70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcfeb20>]}
2020-10-20 18:01:42.408436 (MainThread): Partial parsing not enabled
2020-10-20 18:01:42.410696 (MainThread): Parsing macros/core.sql
2020-10-20 18:01:42.416145 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:01:42.424640 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:01:42.426861 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:01:42.444939 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:01:42.480785 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:01:42.503011 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:01:42.505305 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:01:42.511977 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:01:42.525422 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:01:42.532511 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:01:42.539044 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:01:42.544185 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:01:42.545379 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:01:42.546625 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:01:42.548558 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:01:42.550861 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:01:42.560095 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:01:42.562270 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:01:42.563686 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:01:42.606879 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:01:42.608455 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:01:42.609643 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:01:42.611029 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:01:42.613564 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:01:42.616140 (MainThread): Parsing macros/relations.sql
2020-10-20 18:01:42.618071 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:01:42.635724 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:01:42.659445 (MainThread): Partial parsing not enabled
2020-10-20 18:01:42.693710 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:01:42.693879 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:42.710973 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2020-10-20 18:01:42.711114 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:42.726798 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2020-10-20 18:01:42.726962 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:42.769884 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:01:42.770055 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:42.788717 (MainThread): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id".
2020-10-20 18:01:42.788885 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:42.799624 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id".
2020-10-20 18:01:42.799777 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:42.807471 (MainThread): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id".
2020-10-20 18:01:42.807741 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:42.816022 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id".
2020-10-20 18:01:42.816212 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:43.370973 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:01:43.375147 (MainThread): Found 3 models, 5 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:01:43.378982 (MainThread): 
2020-10-20 18:01:43.379285 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:01:43.379375 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:01:43.411385 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:01:43.411594 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-20 18:01:43.493840 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:01:43.493978 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:01:43.508674 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:01:43.508842 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:01:43.508928 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:01:43.517427 (ThreadPoolExecutor-1_0): SQL status: SELECT 4 in 0.01 seconds
2020-10-20 18:01:43.536528 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:01:43.565884 (MainThread): Using postgres connection "master".
2020-10-20 18:01:43.566013 (MainThread): On master: BEGIN
2020-10-20 18:01:43.578657 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:01:43.578834 (MainThread): Using postgres connection "master".
2020-10-20 18:01:43.578920 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:01:43.593540 (MainThread): SQL status: SELECT 2 in 0.01 seconds
2020-10-20 18:01:43.596180 (MainThread): On master: ROLLBACK
2020-10-20 18:01:43.597546 (MainThread): 19:01:43 | Concurrency: 4 threads (target='dev')
2020-10-20 18:01:43.597686 (MainThread): 19:01:43 | 
2020-10-20 18:01:43.610382 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-20 18:01:43.610561 (Thread-2): Began running node test.my_new_project.not_null_my_first_dbt_model_id
2020-10-20 18:01:43.610687 (Thread-1): 19:01:43 | 1 of 5 START test not_null_covid19_stats_country..................... [RUN]
2020-10-20 18:01:43.610766 (Thread-3): Began running node test.my_new_project.not_null_my_second_dbt_model_id
2020-10-20 18:01:43.610887 (Thread-2): 19:01:43 | 2 of 5 START test not_null_my_first_dbt_model_id..................... [RUN]
2020-10-20 18:01:43.610966 (Thread-4): Began running node test.my_new_project.unique_my_first_dbt_model_id
2020-10-20 18:01:43.611266 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:01:43.611419 (Thread-3): 19:01:43 | 3 of 5 START test not_null_my_second_dbt_model_id.................... [RUN]
2020-10-20 18:01:43.611745 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id".
2020-10-20 18:01:43.611886 (Thread-4): 19:01:43 | 4 of 5 START test unique_my_first_dbt_model_id....................... [RUN]
2020-10-20 18:01:43.611978 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:01:43.612237 (Thread-3): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id".
2020-10-20 18:01:43.612342 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:01:43.612566 (Thread-4): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id".
2020-10-20 18:01:43.612672 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-20 18:01:43.612752 (Thread-3): Opening a new connection, currently in state init
2020-10-20 18:01:43.612863 (Thread-2): Compiling test.my_new_project.not_null_my_first_dbt_model_id
2020-10-20 18:01:43.612958 (Thread-4): Opening a new connection, currently in state init
2020-10-20 18:01:43.624774 (Thread-3): Compiling test.my_new_project.not_null_my_second_dbt_model_id
2020-10-20 18:01:43.629015 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-20 18:01:43.636907 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id"
2020-10-20 18:01:43.637022 (Thread-4): Compiling test.my_new_project.unique_my_first_dbt_model_id
2020-10-20 18:01:43.644194 (Thread-3): Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id"
2020-10-20 18:01:43.651616 (Thread-4): Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id"
2020-10-20 18:01:43.652071 (Thread-1): finished collecting timing info
2020-10-20 18:01:43.652346 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:01:43.652435 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-20 18:01:43.652532 (Thread-3): finished collecting timing info
2020-10-20 18:01:43.652738 (Thread-2): finished collecting timing info
2020-10-20 18:01:43.652944 (Thread-4): finished collecting timing info
2020-10-20 18:01:43.653193 (Thread-3): Using postgres connection "test.my_new_project.not_null_my_second_dbt_model_id".
2020-10-20 18:01:43.653341 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_first_dbt_model_id".
2020-10-20 18:01:43.653479 (Thread-4): Using postgres connection "test.my_new_project.unique_my_first_dbt_model_id".
2020-10-20 18:01:43.653598 (Thread-3): On test.my_new_project.not_null_my_second_dbt_model_id: BEGIN
2020-10-20 18:01:43.653704 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id: BEGIN
2020-10-20 18:01:43.653795 (Thread-4): On test.my_new_project.unique_my_first_dbt_model_id: BEGIN
2020-10-20 18:01:43.656651 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:01:43.656828 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:01:43.656914 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "ingestions"."public"."covid19_stats"
where country is null


2020-10-20 18:01:43.670899 (Thread-1): SQL status: SELECT 1 in 0.01 seconds
2020-10-20 18:01:43.671341 (Thread-1): finished collecting timing info
2020-10-20 18:01:43.671655 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-20 18:01:43.672948 (Thread-1): 19:01:43 | 1 of 5 PASS not_null_covid19_stats_country........................... [PASS in 0.06s]
2020-10-20 18:01:43.673120 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-20 18:01:43.673251 (Thread-1): Began running node test.my_new_project.unique_my_second_dbt_model_id
2020-10-20 18:01:43.673459 (Thread-1): 19:01:43 | 5 of 5 START test unique_my_second_dbt_model_id...................... [RUN]
2020-10-20 18:01:43.673749 (Thread-1): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id".
2020-10-20 18:01:43.673838 (Thread-1): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-20 18:01:43.673921 (Thread-1): Compiling test.my_new_project.unique_my_second_dbt_model_id
2020-10-20 18:01:43.683153 (Thread-1): Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id"
2020-10-20 18:01:43.683837 (Thread-1): finished collecting timing info
2020-10-20 18:01:43.684166 (Thread-1): Using postgres connection "test.my_new_project.unique_my_second_dbt_model_id".
2020-10-20 18:01:43.684266 (Thread-1): On test.my_new_project.unique_my_second_dbt_model_id: BEGIN
2020-10-20 18:01:43.686621 (Thread-2): SQL status: BEGIN in 0.03 seconds
2020-10-20 18:01:43.686791 (Thread-3): SQL status: BEGIN in 0.03 seconds
2020-10-20 18:01:43.686902 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_first_dbt_model_id".
2020-10-20 18:01:43.686975 (Thread-4): SQL status: BEGIN in 0.03 seconds
2020-10-20 18:01:43.687076 (Thread-3): Using postgres connection "test.my_new_project.not_null_my_second_dbt_model_id".
2020-10-20 18:01:43.687163 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_my_first_dbt_model_id"} */




select count(*)
from "ingestions"."public"."my_first_dbt_model"
where id is null


2020-10-20 18:01:43.687250 (Thread-4): Using postgres connection "test.my_new_project.unique_my_first_dbt_model_id".
2020-10-20 18:01:43.687335 (Thread-3): On test.my_new_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_my_second_dbt_model_id"} */




select count(*)
from "ingestions"."public"."my_second_dbt_model"
where id is null


2020-10-20 18:01:43.687482 (Thread-4): On test.my_new_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.unique_my_first_dbt_model_id"} */




select count(*)
from (

    select
        id

    from "ingestions"."public"."my_first_dbt_model"
    where id is not null
    group by id
    having count(*) > 1

) validation_errors


2020-10-20 18:01:43.688211 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:01:43.688407 (Thread-1): Using postgres connection "test.my_new_project.unique_my_second_dbt_model_id".
2020-10-20 18:01:43.688500 (Thread-1): On test.my_new_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.unique_my_second_dbt_model_id"} */




select count(*)
from (

    select
        id

    from "ingestions"."public"."my_second_dbt_model"
    where id is not null
    group by id
    having count(*) > 1

) validation_errors


2020-10-20 18:01:43.692859 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-20 18:01:43.693244 (Thread-1): finished collecting timing info
2020-10-20 18:01:43.693519 (Thread-2): SQL status: SELECT 1 in 0.01 seconds
2020-10-20 18:01:43.693772 (Thread-1): On test.my_new_project.unique_my_second_dbt_model_id: ROLLBACK
2020-10-20 18:01:43.694064 (Thread-2): finished collecting timing info
2020-10-20 18:01:43.694382 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id: ROLLBACK
2020-10-20 18:01:43.703932 (Thread-3): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:01:43.704297 (Thread-3): finished collecting timing info
2020-10-20 18:01:43.704583 (Thread-3): On test.my_new_project.not_null_my_second_dbt_model_id: ROLLBACK
2020-10-20 18:01:43.705169 (Thread-2): 19:01:43 | 2 of 5 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 0.09s]
2020-10-20 18:01:43.705345 (Thread-2): Finished running node test.my_new_project.not_null_my_first_dbt_model_id
2020-10-20 18:01:43.705460 (Thread-4): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:01:43.705774 (Thread-1): 19:01:43 | 5 of 5 PASS unique_my_second_dbt_model_id............................ [PASS in 0.03s]
2020-10-20 18:01:43.706135 (Thread-4): finished collecting timing info
2020-10-20 18:01:43.706647 (Thread-3): 19:01:43 | 3 of 5 PASS not_null_my_second_dbt_model_id.......................... [PASS in 0.09s]
2020-10-20 18:01:43.706804 (Thread-4): On test.my_new_project.unique_my_first_dbt_model_id: ROLLBACK
2020-10-20 18:01:43.706916 (Thread-1): Finished running node test.my_new_project.unique_my_second_dbt_model_id
2020-10-20 18:01:43.707055 (Thread-3): Finished running node test.my_new_project.not_null_my_second_dbt_model_id
2020-10-20 18:01:43.708581 (Thread-4): 19:01:43 | 4 of 5 PASS unique_my_first_dbt_model_id............................. [PASS in 0.10s]
2020-10-20 18:01:43.708732 (Thread-4): Finished running node test.my_new_project.unique_my_first_dbt_model_id
2020-10-20 18:01:43.710715 (MainThread): 19:01:43 | 
2020-10-20 18:01:43.711271 (MainThread): 19:01:43 | Finished running 5 tests in 0.33s.
2020-10-20 18:01:43.711461 (MainThread): Connection 'master' was left open.
2020-10-20 18:01:43.711569 (MainThread): On master: Close
2020-10-20 18:01:43.712020 (MainThread): Connection 'test.my_new_project.unique_my_second_dbt_model_id' was left open.
2020-10-20 18:01:43.712136 (MainThread): On test.my_new_project.unique_my_second_dbt_model_id: Close
2020-10-20 18:01:43.712717 (MainThread): Connection 'test.my_new_project.not_null_my_first_dbt_model_id' was left open.
2020-10-20 18:01:43.712894 (MainThread): On test.my_new_project.not_null_my_first_dbt_model_id: Close
2020-10-20 18:01:43.713379 (MainThread): Connection 'test.my_new_project.not_null_my_second_dbt_model_id' was left open.
2020-10-20 18:01:43.713660 (MainThread): On test.my_new_project.not_null_my_second_dbt_model_id: Close
2020-10-20 18:01:43.720153 (MainThread): Connection 'test.my_new_project.unique_my_first_dbt_model_id' was left open.
2020-10-20 18:01:43.720880 (MainThread): On test.my_new_project.unique_my_first_dbt_model_id: Close
2020-10-20 18:01:43.739633 (MainThread): 
2020-10-20 18:01:43.739786 (MainThread): Completed with 1 error and 0 warnings:
2020-10-20 18:01:43.739900 (MainThread): 
2020-10-20 18:01:43.740000 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2020-10-20 18:01:43.740104 (MainThread):   Got 1 result, expected 0.
2020-10-20 18:01:43.740186 (MainThread): 
2020-10-20 18:01:43.740281 (MainThread):   compiled SQL at target/compiled/my_new_project/schema_test/not_null_my_first_dbt_model_id.sql
2020-10-20 18:01:43.740376 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2020-10-20 18:01:43.740526 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111df4f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dffaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dffd90>]}
2020-10-20 18:01:43.740699 (MainThread): Flushing usage events
2020-10-20 18:03:47.317933 (MainThread): Running with dbt=0.16.1
2020-10-20 18:03:47.397122 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-20 18:03:47.471511 (MainThread): Tracking: tracking
2020-10-20 18:03:47.567227 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e15fdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e52bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e52b6a0>]}
2020-10-20 18:03:47.588855 (MainThread): Partial parsing not enabled
2020-10-20 18:03:47.591335 (MainThread): Parsing macros/core.sql
2020-10-20 18:03:47.597071 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:03:47.605970 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:03:47.608275 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:03:47.627052 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:03:47.664462 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:03:47.711370 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:03:47.716605 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:03:47.732725 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:03:47.746798 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:03:47.754359 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:03:47.761313 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:03:47.769527 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:03:47.772266 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:03:47.774546 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:03:47.780116 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:03:47.783177 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:03:47.795807 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:03:47.798508 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:03:47.800664 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:03:47.847961 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:03:47.849559 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:03:47.850747 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:03:47.852139 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:03:47.854739 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:03:47.857527 (MainThread): Parsing macros/relations.sql
2020-10-20 18:03:47.859543 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:03:47.878266 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:03:47.898247 (MainThread): Partial parsing not enabled
2020-10-20 18:03:47.929644 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:03:47.929834 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:03:47.969233 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:03:47.969371 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:03:48.461217 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:03:48.462975 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:03:48.464347 (MainThread): 
2020-10-20 18:03:48.464701 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:03:48.464806 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:03:48.477714 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:03:48.477953 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-20 18:03:48.562404 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:03:48.562558 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:03:48.578320 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.02 seconds
2020-10-20 18:03:48.578501 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:03:48.578589 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:03:48.591243 (ThreadPoolExecutor-1_0): SQL status: SELECT 4 in 0.01 seconds
2020-10-20 18:03:48.609418 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:03:48.622334 (MainThread): Using postgres connection "master".
2020-10-20 18:03:48.622492 (MainThread): On master: BEGIN
2020-10-20 18:03:48.635726 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:03:48.635916 (MainThread): Using postgres connection "master".
2020-10-20 18:03:48.636008 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:03:48.661034 (MainThread): SQL status: SELECT 2 in 0.02 seconds
2020-10-20 18:03:48.663699 (MainThread): On master: ROLLBACK
2020-10-20 18:03:48.664955 (MainThread): 19:03:48 | Concurrency: 4 threads (target='dev')
2020-10-20 18:03:48.665103 (MainThread): 19:03:48 | 
2020-10-20 18:03:48.674764 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-20 18:03:48.674952 (Thread-1): 19:03:48 | 1 of 1 START test not_null_covid19_stats_country..................... [RUN]
2020-10-20 18:03:48.675234 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:03:48.675316 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:03:48.675396 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-20 18:03:48.690950 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-20 18:03:48.691342 (Thread-1): finished collecting timing info
2020-10-20 18:03:48.691597 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:03:48.691686 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-20 18:03:48.694114 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:03:48.694291 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:03:48.694383 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "ingestions"."public"."covid19_stats"
where country is null


2020-10-20 18:03:48.699055 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-20 18:03:48.699430 (Thread-1): finished collecting timing info
2020-10-20 18:03:48.699726 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-20 18:03:48.701274 (Thread-1): 19:03:48 | 1 of 1 PASS not_null_covid19_stats_country........................... [PASS in 0.03s]
2020-10-20 18:03:48.701456 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-20 18:03:48.703132 (MainThread): 19:03:48 | 
2020-10-20 18:03:48.703306 (MainThread): 19:03:48 | Finished running 1 test in 0.24s.
2020-10-20 18:03:48.703406 (MainThread): Connection 'master' was left open.
2020-10-20 18:03:48.703483 (MainThread): On master: Close
2020-10-20 18:03:48.703593 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-20 18:03:48.703662 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-20 18:03:48.707036 (MainThread): 
2020-10-20 18:03:48.707222 (MainThread): Completed successfully
2020-10-20 18:03:48.707369 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-20 18:03:48.707556 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1164a72b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11650da30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11650da00>]}
2020-10-20 18:03:48.707757 (MainThread): Flushing usage events
2020-10-20 18:13:57.523240 (MainThread): Running with dbt=0.16.1
2020-10-20 18:13:57.593089 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:13:57.603750 (MainThread): Tracking: tracking
2020-10-20 18:13:57.616329 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d13aee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d505700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d505f40>]}
2020-10-20 18:13:57.636096 (MainThread): Partial parsing not enabled
2020-10-20 18:13:57.638524 (MainThread): Parsing macros/core.sql
2020-10-20 18:13:57.644009 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:13:57.652532 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:13:57.654747 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:13:57.672863 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:13:57.709055 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:13:57.731004 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:13:57.733216 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:13:57.739766 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:13:57.753355 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:13:57.760633 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:13:57.767346 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:13:57.772583 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:13:57.773859 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:13:57.775303 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:13:57.777266 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:13:57.779555 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:13:57.789951 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:13:57.792212 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:13:57.793445 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:13:57.837327 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:13:57.838775 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:13:57.839944 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:13:57.841418 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:13:57.843991 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:13:57.846613 (MainThread): Parsing macros/relations.sql
2020-10-20 18:13:57.848571 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:13:57.866116 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:13:57.884802 (MainThread): Partial parsing not enabled
2020-10-20 18:13:57.913975 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:13:57.914112 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:13:57.934124 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:13:57.934261 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:13:57.968080 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:13:57.968228 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:13:57.980835 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:13:57.980964 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:13:58.046848 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d66a2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d66a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d649790>]}
2020-10-20 18:13:58.047075 (MainThread): Flushing usage events
2020-10-20 18:13:58.555121 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was properly closed.
2020-10-20 18:13:58.555310 (MainThread): Encountered an error:
2020-10-20 18:13:58.555421 (MainThread): cannot pickle 'ParserMacroCapture' object
2020-10-20 18:13:58.584299 (MainThread): Traceback (most recent call last):
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/parser/manifest.py", line 337, in load_all
    loader.write_parse_results()
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/parser/manifest.py", line 215, in write_parse_results
    pickle.dump(self.results, fp)
TypeError: cannot pickle 'ParserMacroCapture' object

2020-10-20 18:14:14.989830 (MainThread): Running with dbt=0.16.1
2020-10-20 18:14:15.058631 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:14:15.059419 (MainThread): Tracking: tracking
2020-10-20 18:14:15.071808 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b9e820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119fa0ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119fa0b80>]}
2020-10-20 18:14:15.092115 (MainThread): Partial parsing not enabled
2020-10-20 18:14:15.094000 (MainThread): Parsing macros/core.sql
2020-10-20 18:14:15.098695 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:14:15.107482 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:14:15.109365 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:14:15.127062 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:14:15.162630 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:14:15.184774 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:14:15.186750 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:14:15.193278 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:14:15.206693 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:14:15.213820 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:14:15.220440 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:14:15.225528 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:14:15.226508 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:14:15.227715 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:14:15.229434 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:14:15.231565 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:14:15.241010 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:14:15.243024 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:14:15.244107 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:14:15.287192 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:14:15.288411 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:14:15.289348 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:14:15.290467 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:14:15.292738 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:14:15.295794 (MainThread): Parsing macros/relations.sql
2020-10-20 18:14:15.297547 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:14:15.315307 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:14:15.334488 (MainThread): Partial parsing not enabled
2020-10-20 18:14:15.363547 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:15.363681 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:14:15.378147 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:14:15.378272 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:14:15.409277 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:14:15.409416 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:14:15.421291 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:14:15.421420 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:14:15.993770 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:14:15.996321 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:14:15.998700 (MainThread): 
2020-10-20 18:14:15.999464 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:14:15.999792 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:14:16.010489 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:14:16.010676 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:14:16.092854 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:14:16.093016 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:14:16.112517 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.02 seconds
2020-10-20 18:14:16.142218 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:14:16.142401 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:14:16.143896 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:14:16.144003 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:14:16.145587 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:14:16.145753 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:14:16.145839 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:14:16.159608 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.01 seconds
2020-10-20 18:14:16.161735 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:14:16.180066 (MainThread): Using postgres connection "master".
2020-10-20 18:14:16.180215 (MainThread): On master: BEGIN
2020-10-20 18:14:16.193847 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:14:16.194032 (MainThread): Using postgres connection "master".
2020-10-20 18:14:16.194221 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:14:16.212470 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:14:16.214272 (MainThread): On master: ROLLBACK
2020-10-20 18:14:16.215661 (MainThread): Using postgres connection "master".
2020-10-20 18:14:16.215811 (MainThread): On master: BEGIN
2020-10-20 18:14:16.218393 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:14:16.218588 (MainThread): On master: COMMIT
2020-10-20 18:14:16.218682 (MainThread): Using postgres connection "master".
2020-10-20 18:14:16.218756 (MainThread): On master: COMMIT
2020-10-20 18:14:16.220005 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:14:16.220356 (MainThread): 19:14:16 | Concurrency: 4 threads (target='dev')
2020-10-20 18:14:16.220488 (MainThread): 19:14:16 | 
2020-10-20 18:14:16.230741 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:14:16.230933 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:14:16.231063 (Thread-1): 19:14:16 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:14:16.231208 (Thread-2): 19:14:16 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:14:16.231534 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.231781 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:14:16.231891 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:14:16.231993 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:14:16.232094 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:14:16.232184 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:14:16.252088 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:14:16.255208 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:14:16.255895 (Thread-1): finished collecting timing info
2020-10-20 18:14:16.278162 (Thread-2): finished collecting timing info
2020-10-20 18:14:16.292115 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.304253 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:14:16.311855 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:14:16.319831 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:14:16.322086 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.322308 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:14:16.322780 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:14:16.322879 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:14:16.323819 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:14:16.325548 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:14:16.325988 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.326089 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:14:16.327899 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:14:16.328080 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.328177 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:14:16.339858 (Thread-2): SQL status: BEGIN in 0.02 seconds
2020-10-20 18:14:16.340043 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:14:16.340138 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

  create  table "ingestions"."public"."covid19_stats_incremental"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




GROUP BY country, day
  );
  
2020-10-20 18:14:16.352877 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2020-10-20 18:14:16.358236 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.358439 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:14:16.360468 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:14:16.363537 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.363773 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:14:16.366096 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:14:16.367293 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:14:16.367422 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.367546 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:14:16.372989 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:14:16.374887 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:14:16.375014 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:14:16.386246 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:14:16.388905 (Thread-1): finished collecting timing info
2020-10-20 18:14:16.389589 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b36e454f-5b30-43f0-93f4-31db29de4e81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11be06d30>]}
2020-10-20 18:14:16.389833 (Thread-1): 19:14:16 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.16s]
2020-10-20 18:14:16.389961 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:14:16.400837 (Thread-2): SQL status: SELECT 187 in 0.06 seconds
2020-10-20 18:14:16.401832 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:14:16.401949 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:14:16.402027 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:14:16.405325 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:14:16.407085 (Thread-2): finished collecting timing info
2020-10-20 18:14:16.407698 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b36e454f-5b30-43f0-93f4-31db29de4e81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bf19ee0>]}
2020-10-20 18:14:16.407971 (Thread-2): 19:14:16 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [SELECT 187 in 0.18s]
2020-10-20 18:14:16.408109 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:14:16.409222 (MainThread): Using postgres connection "master".
2020-10-20 18:14:16.409359 (MainThread): On master: BEGIN
2020-10-20 18:14:16.410601 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:14:16.410735 (MainThread): On master: COMMIT
2020-10-20 18:14:16.410820 (MainThread): Using postgres connection "master".
2020-10-20 18:14:16.410895 (MainThread): On master: COMMIT
2020-10-20 18:14:16.411914 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:14:16.412231 (MainThread): 19:14:16 | 
2020-10-20 18:14:16.412346 (MainThread): 19:14:16 | Finished running 1 view model, 1 incremental model in 0.41s.
2020-10-20 18:14:16.412440 (MainThread): Connection 'master' was left open.
2020-10-20 18:14:16.412514 (MainThread): On master: Close
2020-10-20 18:14:16.412640 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:14:16.412766 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:14:16.412935 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:14:16.413208 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:14:16.420683 (MainThread): 
2020-10-20 18:14:16.421100 (MainThread): Completed successfully
2020-10-20 18:14:16.421322 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:14:16.421637 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bee1fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bee1b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bee1ca0>]}
2020-10-20 18:14:16.421855 (MainThread): Flushing usage events
2020-10-20 18:15:15.030067 (MainThread): Running with dbt=0.16.1
2020-10-20 18:15:15.110242 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:15:15.110921 (MainThread): Tracking: tracking
2020-10-20 18:15:15.124119 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11188fee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111864a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117d7caf0>]}
2020-10-20 18:15:15.145425 (MainThread): Partial parsing not enabled
2020-10-20 18:15:15.147718 (MainThread): Parsing macros/core.sql
2020-10-20 18:15:15.153402 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:15:15.162535 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:15:15.164895 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:15:15.183835 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:15:15.220809 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:15:15.243027 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:15:15.245290 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:15:15.252054 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:15:15.265828 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:15:15.273284 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:15:15.280068 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:15:15.285478 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:15:15.286729 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:15:15.288026 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:15:15.290036 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:15:15.292463 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:15:15.302403 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:15:15.304630 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:15:15.305982 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:15:15.350565 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:15:15.352174 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:15:15.353420 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:15:15.354874 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:15:15.357526 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:15:15.360291 (MainThread): Parsing macros/relations.sql
2020-10-20 18:15:15.362280 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:15:15.380330 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:15:15.399097 (MainThread): Partial parsing not enabled
2020-10-20 18:15:15.427656 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:15.427791 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:15.478234 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:15.478389 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:15.510666 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:15:15.510805 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:15.522759 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:15:15.522880 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:15.932320 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:15:15.934644 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:15:15.937449 (MainThread): 
2020-10-20 18:15:15.937760 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:15:15.937853 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:15.945447 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:15:15.945600 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:15:16.027188 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:15:16.027334 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:15:16.043814 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.02 seconds
2020-10-20 18:15:16.060135 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:15:16.060319 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:15:16.061720 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:15:16.061814 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:15:16.063592 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:16.063753 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:15:16.063839 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:15:16.071640 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:15:16.074430 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:15:16.094616 (MainThread): Using postgres connection "master".
2020-10-20 18:15:16.094778 (MainThread): On master: BEGIN
2020-10-20 18:15:16.109664 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:15:16.109857 (MainThread): Using postgres connection "master".
2020-10-20 18:15:16.109956 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:15:16.127509 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:15:16.129202 (MainThread): On master: ROLLBACK
2020-10-20 18:15:16.130524 (MainThread): Using postgres connection "master".
2020-10-20 18:15:16.130675 (MainThread): On master: BEGIN
2020-10-20 18:15:16.132709 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:16.132899 (MainThread): On master: COMMIT
2020-10-20 18:15:16.133006 (MainThread): Using postgres connection "master".
2020-10-20 18:15:16.133091 (MainThread): On master: COMMIT
2020-10-20 18:15:16.134257 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:16.134610 (MainThread): 19:15:16 | Concurrency: 4 threads (target='dev')
2020-10-20 18:15:16.134740 (MainThread): 19:15:16 | 
2020-10-20 18:15:16.138926 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:15:16.139141 (Thread-1): 19:15:16 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:15:16.139275 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:15:16.139592 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.139812 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:15:16.139720 (Thread-2): 19:15:16 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:15:16.139896 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:15:16.140135 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.156142 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:15:16.156321 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:15:16.156648 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:15:16.163463 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:15:16.163868 (Thread-1): finished collecting timing info
2020-10-20 18:15:16.164122 (Thread-2): finished collecting timing info
2020-10-20 18:15:16.217342 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.224165 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:15:16.237102 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:15:16.246135 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.248992 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.249123 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191516242237"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:15:16.249215 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:15:16.251488 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:15:16.253167 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:15:16.253622 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.253735 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:15:16.255334 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:16.255526 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.255621 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:15:16.266217 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:15:16.270128 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.270279 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:15:16.271909 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:15:16.274385 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.274529 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:15:16.276664 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:15:16.277690 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:15:16.277833 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.277921 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:15:16.280880 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:16.282766 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:16.282911 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:15:16.286663 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:15:16.289033 (Thread-1): finished collecting timing info
2020-10-20 18:15:16.289680 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dc4d821-d0f1-450e-8f5c-3d346a9ee6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119d47df0>]}
2020-10-20 18:15:16.289923 (Thread-1): 19:15:16 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.15s]
2020-10-20 18:15:16.290060 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:15:16.303515 (Thread-2): SQL status: SELECT 187 in 0.05 seconds
2020-10-20 18:15:16.307120 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.307246 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:15:16.309375 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:16.309561 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.309664 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191516242237'
        
      order by ordinal_position

  
2020-10-20 18:15:16.348009 (Thread-2): SQL status: SELECT 6 in 0.04 seconds
2020-10-20 18:15:16.351615 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.351729 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:15:16.356048 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:15:16.363004 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.363132 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:15:16.366563 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:15:16.367641 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:15:16.368030 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.368118 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191516242237"
    );
  
2020-10-20 18:15:16.379122 (Thread-2): SQL status: INSERT 0 187 in 0.01 seconds
2020-10-20 18:15:16.380423 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:15:16.380552 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:16.380633 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:15:16.383612 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:16.385212 (Thread-2): finished collecting timing info
2020-10-20 18:15:16.385840 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dc4d821-d0f1-450e-8f5c-3d346a9ee6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f31610>]}
2020-10-20 18:15:16.386071 (Thread-2): 19:15:16 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 187 in 0.25s]
2020-10-20 18:15:16.386192 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:15:16.387215 (MainThread): Using postgres connection "master".
2020-10-20 18:15:16.387326 (MainThread): On master: BEGIN
2020-10-20 18:15:16.388659 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:16.388817 (MainThread): On master: COMMIT
2020-10-20 18:15:16.388910 (MainThread): Using postgres connection "master".
2020-10-20 18:15:16.388990 (MainThread): On master: COMMIT
2020-10-20 18:15:16.390357 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:16.390715 (MainThread): 19:15:16 | 
2020-10-20 18:15:16.390837 (MainThread): 19:15:16 | Finished running 1 view model, 1 incremental model in 0.45s.
2020-10-20 18:15:16.390930 (MainThread): Connection 'master' was left open.
2020-10-20 18:15:16.391005 (MainThread): On master: Close
2020-10-20 18:15:16.391108 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:15:16.391182 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:15:16.391272 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:15:16.391340 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:15:16.397023 (MainThread): 
2020-10-20 18:15:16.397196 (MainThread): Completed successfully
2020-10-20 18:15:16.397314 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:15:16.397487 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bc2ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119baae80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119baa9d0>]}
2020-10-20 18:15:16.397689 (MainThread): Flushing usage events
2020-10-20 18:15:34.171140 (MainThread): Running with dbt=0.16.1
2020-10-20 18:15:34.235847 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:15:34.236510 (MainThread): Tracking: tracking
2020-10-20 18:15:34.249647 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ace5e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b0b0e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b0b0520>]}
2020-10-20 18:15:34.271627 (MainThread): Partial parsing not enabled
2020-10-20 18:15:34.273617 (MainThread): Parsing macros/core.sql
2020-10-20 18:15:34.278711 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:15:34.287774 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:15:34.289854 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:15:34.309088 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:15:34.349752 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:15:34.374239 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:15:34.376412 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:15:34.383277 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:15:34.397337 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:15:34.404711 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:15:34.411459 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:15:34.416767 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:15:34.417760 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:15:34.419068 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:15:34.420929 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:15:34.423089 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:15:34.432922 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:15:34.434968 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:15:34.436075 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:15:34.481952 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:15:34.483296 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:15:34.484281 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:15:34.485568 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:15:34.488153 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:15:34.490836 (MainThread): Parsing macros/relations.sql
2020-10-20 18:15:34.492747 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:15:34.512499 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:15:34.532045 (MainThread): Partial parsing not enabled
2020-10-20 18:15:34.562907 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:34.563138 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:34.579477 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:34.579619 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:34.613092 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:15:34.613244 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:34.625338 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:15:34.625470 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:34.948799 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:15:34.951062 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:15:34.953787 (MainThread): 
2020-10-20 18:15:34.954112 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:15:34.954203 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:15:34.961973 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:15:34.962248 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:15:35.040802 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:15:35.040946 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:15:35.056301 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:15:35.072579 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:15:35.072761 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:15:35.074198 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:15:35.074289 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:15:35.075695 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:35.075838 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:15:35.075918 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:15:35.083357 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:15:35.086059 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:15:35.104280 (MainThread): Using postgres connection "master".
2020-10-20 18:15:35.104417 (MainThread): On master: BEGIN
2020-10-20 18:15:35.117101 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:15:35.117285 (MainThread): Using postgres connection "master".
2020-10-20 18:15:35.117370 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:15:35.131152 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-20 18:15:35.132811 (MainThread): On master: ROLLBACK
2020-10-20 18:15:35.134008 (MainThread): Using postgres connection "master".
2020-10-20 18:15:35.134130 (MainThread): On master: BEGIN
2020-10-20 18:15:35.136051 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:35.136210 (MainThread): On master: COMMIT
2020-10-20 18:15:35.136306 (MainThread): Using postgres connection "master".
2020-10-20 18:15:35.136381 (MainThread): On master: COMMIT
2020-10-20 18:15:35.137574 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:35.137906 (MainThread): 19:15:35 | Concurrency: 4 threads (target='dev')
2020-10-20 18:15:35.138030 (MainThread): 19:15:35 | 
2020-10-20 18:15:35.140743 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:15:35.140884 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:15:35.141038 (Thread-1): 19:15:35 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:15:35.141160 (Thread-2): 19:15:35 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:15:35.141454 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.141714 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.141795 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:15:35.141892 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:15:35.141996 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:15:35.142094 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:15:35.164978 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:15:35.165824 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:15:35.166223 (Thread-1): finished collecting timing info
2020-10-20 18:15:35.171513 (Thread-2): finished collecting timing info
2020-10-20 18:15:35.225254 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.231706 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:15:35.239241 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:15:35.244150 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.247113 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.247269 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191535240314"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:15:35.247360 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:15:35.249407 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:15:35.251246 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:15:35.251762 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.251885 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:15:35.253330 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:35.253506 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.253599 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:15:35.262631 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:15:35.267028 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.267189 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:15:35.268843 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:15:35.271506 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.271654 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:15:35.273594 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:15:35.274694 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:15:35.274845 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.274929 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:15:35.278326 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:35.280223 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:15:35.280369 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:15:35.284620 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:15:35.287041 (Thread-1): finished collecting timing info
2020-10-20 18:15:35.287730 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '004b1c93-c983-4bfa-9e79-882cdf4e275b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d012a00>]}
2020-10-20 18:15:35.287983 (Thread-1): 19:15:35 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.15s]
2020-10-20 18:15:35.288126 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:15:35.310857 (Thread-2): SQL status: SELECT 187 in 0.06 seconds
2020-10-20 18:15:35.314591 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.314734 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:15:35.316702 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:35.316873 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.316966 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191535240314'
        
      order by ordinal_position

  
2020-10-20 18:15:35.344758 (Thread-2): SQL status: SELECT 6 in 0.03 seconds
2020-10-20 18:15:35.348491 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.348630 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:15:35.354314 (Thread-2): SQL status: SELECT 6 in 0.01 seconds
2020-10-20 18:15:35.361439 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.361588 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:15:35.366692 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:15:35.367873 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:15:35.368293 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.368390 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191535240314"
    );
  
2020-10-20 18:15:35.373968 (Thread-2): SQL status: INSERT 0 187 in 0.01 seconds
2020-10-20 18:15:35.374965 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:15:35.375084 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:15:35.375158 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:15:35.378026 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:35.379786 (Thread-2): finished collecting timing info
2020-10-20 18:15:35.380458 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '004b1c93-c983-4bfa-9e79-882cdf4e275b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d260850>]}
2020-10-20 18:15:35.380686 (Thread-2): 19:15:35 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 187 in 0.24s]
2020-10-20 18:15:35.380805 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:15:35.382469 (MainThread): Using postgres connection "master".
2020-10-20 18:15:35.382638 (MainThread): On master: BEGIN
2020-10-20 18:15:35.384055 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:15:35.384231 (MainThread): On master: COMMIT
2020-10-20 18:15:35.384316 (MainThread): Using postgres connection "master".
2020-10-20 18:15:35.384387 (MainThread): On master: COMMIT
2020-10-20 18:15:35.385481 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:15:35.385864 (MainThread): 19:15:35 | 
2020-10-20 18:15:35.385996 (MainThread): 19:15:35 | Finished running 1 view model, 1 incremental model in 0.43s.
2020-10-20 18:15:35.386092 (MainThread): Connection 'master' was left open.
2020-10-20 18:15:35.386170 (MainThread): On master: Close
2020-10-20 18:15:35.386274 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:15:35.386342 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:15:35.386431 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:15:35.386498 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:15:35.392502 (MainThread): 
2020-10-20 18:15:35.392772 (MainThread): Completed successfully
2020-10-20 18:15:35.392925 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:15:35.393137 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cef56a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cf09fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cf09f70>]}
2020-10-20 18:15:35.393358 (MainThread): Flushing usage events
2020-10-20 18:16:24.911999 (MainThread): Running with dbt=0.16.1
2020-10-20 18:16:24.992142 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:16:24.997650 (MainThread): Tracking: tracking
2020-10-20 18:16:25.018355 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a331e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6fde20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6fd6a0>]}
2020-10-20 18:16:25.038629 (MainThread): Partial parsing not enabled
2020-10-20 18:16:25.040725 (MainThread): Parsing macros/core.sql
2020-10-20 18:16:25.045913 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:16:25.054479 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:16:25.056769 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:16:25.074718 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:16:25.110854 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:16:25.132826 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:16:25.134983 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:16:25.141759 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:16:25.155328 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:16:25.162700 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:16:25.169479 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:16:25.174702 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:16:25.175944 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:16:25.177349 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:16:25.181621 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:16:25.188681 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:16:25.200997 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:16:25.203993 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:16:25.205600 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:16:25.255866 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:16:25.257295 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:16:25.258434 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:16:25.259747 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:16:25.262419 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:16:25.265228 (MainThread): Parsing macros/relations.sql
2020-10-20 18:16:25.267300 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:16:25.285534 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:16:25.305217 (MainThread): Partial parsing not enabled
2020-10-20 18:16:25.335786 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:25.335939 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:25.351159 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:25.351289 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:25.383372 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:16:25.383518 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:25.395786 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:16:25.395924 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:25.815625 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:16:25.817997 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:16:25.820889 (MainThread): 
2020-10-20 18:16:25.821227 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:16:25.821324 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:25.828993 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:16:25.829145 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:16:25.911573 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:16:25.911762 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:16:25.931079 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:16:25.947668 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:16:25.947849 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:16:25.949268 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:16:25.949360 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:16:25.950954 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:25.951098 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:16:25.951182 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:16:25.958776 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:16:25.961546 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:16:25.979893 (MainThread): Using postgres connection "master".
2020-10-20 18:16:25.980029 (MainThread): On master: BEGIN
2020-10-20 18:16:25.992034 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:16:25.992216 (MainThread): Using postgres connection "master".
2020-10-20 18:16:25.992315 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:16:26.004951 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-20 18:16:26.006651 (MainThread): On master: ROLLBACK
2020-10-20 18:16:26.008313 (MainThread): Using postgres connection "master".
2020-10-20 18:16:26.008492 (MainThread): On master: BEGIN
2020-10-20 18:16:26.012047 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:26.012325 (MainThread): On master: COMMIT
2020-10-20 18:16:26.012507 (MainThread): Using postgres connection "master".
2020-10-20 18:16:26.012667 (MainThread): On master: COMMIT
2020-10-20 18:16:26.014712 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:26.015112 (MainThread): 19:16:26 | Concurrency: 4 threads (target='dev')
2020-10-20 18:16:26.015250 (MainThread): 19:16:26 | 
2020-10-20 18:16:26.020502 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:16:26.020695 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:26.020864 (Thread-1): 19:16:26 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:16:26.021004 (Thread-2): 19:16:26 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:16:26.021384 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.021490 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:16:26.021737 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.021836 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:16:26.021950 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:16:26.032508 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:26.043732 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:16:26.044225 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:16:26.044645 (Thread-2): finished collecting timing info
2020-10-20 18:16:26.050698 (Thread-1): finished collecting timing info
2020-10-20 18:16:26.115158 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.120840 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:16:26.125009 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.125219 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191626120358"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:16:26.127796 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:16:26.130376 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.130522 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:16:26.132148 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:16:26.133848 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:16:26.134298 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.134405 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:16:26.136041 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:26.136213 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.136310 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:16:26.146878 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:16:26.150754 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.150909 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:16:26.152567 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:16:26.155090 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.155231 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:16:26.157577 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:16:26.158599 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:16:26.158720 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.158799 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:16:26.162271 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:26.164155 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:26.164285 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:16:26.167977 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:16:26.170413 (Thread-1): finished collecting timing info
2020-10-20 18:16:26.171028 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da82b9ff-1e30-4086-a814-d5ff315bfa9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120765c40>]}
2020-10-20 18:16:26.171248 (Thread-1): 19:16:26 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.15s]
2020-10-20 18:16:26.171368 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:16:26.177116 (Thread-2): SQL status: SELECT 221 in 0.05 seconds
2020-10-20 18:16:26.180804 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.180958 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:16:26.182398 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:26.182562 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.182651 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191626120358'
        
      order by ordinal_position

  
2020-10-20 18:16:26.205687 (Thread-2): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:16:26.209348 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.209469 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:16:26.213375 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:16:26.220382 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.220511 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:16:26.223923 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:16:26.225024 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:16:26.225408 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.225495 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191626120358"
    );
  
2020-10-20 18:16:26.230894 (Thread-2): SQL status: INSERT 0 221 in 0.01 seconds
2020-10-20 18:16:26.231869 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:16:26.231974 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:26.232051 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:16:26.234698 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:26.236500 (Thread-2): finished collecting timing info
2020-10-20 18:16:26.237208 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da82b9ff-1e30-4086-a814-d5ff315bfa9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a04760>]}
2020-10-20 18:16:26.237452 (Thread-2): 19:16:26 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 221 in 0.22s]
2020-10-20 18:16:26.237576 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:26.238541 (MainThread): Using postgres connection "master".
2020-10-20 18:16:26.238659 (MainThread): On master: BEGIN
2020-10-20 18:16:26.239839 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:26.239960 (MainThread): On master: COMMIT
2020-10-20 18:16:26.240041 (MainThread): Using postgres connection "master".
2020-10-20 18:16:26.240111 (MainThread): On master: COMMIT
2020-10-20 18:16:26.241202 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:26.241521 (MainThread): 19:16:26 | 
2020-10-20 18:16:26.241636 (MainThread): 19:16:26 | Finished running 1 view model, 1 incremental model in 0.42s.
2020-10-20 18:16:26.241729 (MainThread): Connection 'master' was left open.
2020-10-20 18:16:26.241802 (MainThread): On master: Close
2020-10-20 18:16:26.241899 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:16:26.241969 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:16:26.242058 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:16:26.242131 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:16:26.247912 (MainThread): 
2020-10-20 18:16:26.248127 (MainThread): Completed successfully
2020-10-20 18:16:26.248437 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:16:26.248721 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12067b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12065b0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12065b310>]}
2020-10-20 18:16:26.248961 (MainThread): Flushing usage events
2020-10-20 18:16:30.744200 (MainThread): Running with dbt=0.16.1
2020-10-20 18:16:30.828753 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:16:30.829499 (MainThread): Tracking: tracking
2020-10-20 18:16:30.841049 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cc65880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cc65f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d02fe20>]}
2020-10-20 18:16:30.861072 (MainThread): Partial parsing not enabled
2020-10-20 18:16:30.863008 (MainThread): Parsing macros/core.sql
2020-10-20 18:16:30.867931 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:16:30.876490 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:16:30.878432 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:16:30.896295 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:16:30.931870 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:16:30.954932 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:16:30.956923 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:16:30.963387 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:16:30.976677 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:16:30.983718 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:16:30.990294 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:16:30.995286 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:16:30.996245 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:16:30.997325 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:16:30.998992 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:16:31.001065 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:16:31.010427 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:16:31.012570 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:16:31.013644 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:16:31.057489 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:16:31.058701 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:16:31.059634 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:16:31.060746 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:16:31.063063 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:16:31.065477 (MainThread): Parsing macros/relations.sql
2020-10-20 18:16:31.067234 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:16:31.085029 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:16:31.104063 (MainThread): Partial parsing not enabled
2020-10-20 18:16:31.132876 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.133011 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:31.147352 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.147470 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:31.178321 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:16:31.178464 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:31.190170 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:16:31.190291 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:31.551011 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:16:31.553426 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:16:31.556317 (MainThread): 
2020-10-20 18:16:31.556649 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:16:31.556754 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:31.564095 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:16:31.564327 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:16:31.644937 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:16:31.645082 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:16:31.660136 (ThreadPoolExecutor-0_0): SQL status: SELECT 8 in 0.01 seconds
2020-10-20 18:16:31.675685 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:16:31.675876 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:16:31.677384 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:16:31.677497 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:16:31.679318 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:31.679494 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:16:31.679584 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:16:31.687337 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:16:31.690251 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:16:31.709410 (MainThread): Using postgres connection "master".
2020-10-20 18:16:31.709559 (MainThread): On master: BEGIN
2020-10-20 18:16:31.727625 (MainThread): SQL status: BEGIN in 0.02 seconds
2020-10-20 18:16:31.727799 (MainThread): Using postgres connection "master".
2020-10-20 18:16:31.727885 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:16:31.747358 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:16:31.749079 (MainThread): On master: ROLLBACK
2020-10-20 18:16:31.750448 (MainThread): Using postgres connection "master".
2020-10-20 18:16:31.750605 (MainThread): On master: BEGIN
2020-10-20 18:16:31.754260 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:31.754472 (MainThread): On master: COMMIT
2020-10-20 18:16:31.754579 (MainThread): Using postgres connection "master".
2020-10-20 18:16:31.754658 (MainThread): On master: COMMIT
2020-10-20 18:16:31.756106 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:31.756499 (MainThread): 19:16:31 | Concurrency: 4 threads (target='dev')
2020-10-20 18:16:31.756648 (MainThread): 19:16:31 | 
2020-10-20 18:16:31.759812 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:16:31.760031 (Thread-1): 19:16:31 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:16:31.760187 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:31.760528 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.760659 (Thread-2): 19:16:31 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:16:31.760801 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:16:31.761099 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.761244 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:16:31.761373 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:16:31.766734 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:31.784069 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:16:31.785213 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:16:31.785774 (Thread-1): finished collecting timing info
2020-10-20 18:16:31.791217 (Thread-2): finished collecting timing info
2020-10-20 18:16:31.846190 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.852660 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:16:31.861845 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:16:31.870473 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.870607 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:16:31.870923 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.871035 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191631863860"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:16:31.872156 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:16:31.873813 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:16:31.874273 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.874388 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:16:31.876142 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:31.876322 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.876416 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:16:31.884845 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:16:31.888819 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.888972 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:16:31.890734 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:16:31.893332 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.893474 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:16:31.895186 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:16:31.896189 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:16:31.896310 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.896390 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:16:31.898819 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:31.900710 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:31.900853 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:16:31.904546 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:16:31.906978 (Thread-1): finished collecting timing info
2020-10-20 18:16:31.907642 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1b329af-3b2b-4456-9945-5dd912ea5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1210b5ac0>]}
2020-10-20 18:16:31.907893 (Thread-1): 19:16:31 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.15s]
2020-10-20 18:16:31.908020 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:16:31.915846 (Thread-2): SQL status: SELECT 40 in 0.04 seconds
2020-10-20 18:16:31.919458 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.919586 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:16:31.921063 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:31.921234 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.921324 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191631863860'
        
      order by ordinal_position

  
2020-10-20 18:16:31.944417 (Thread-2): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:16:31.948111 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.948241 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:16:31.952767 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:16:31.959792 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.959927 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:16:31.963363 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:16:31.964451 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:16:31.964820 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.964907 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191631863860"
    );
  
2020-10-20 18:16:31.968013 (Thread-2): SQL status: INSERT 0 40 in 0.00 seconds
2020-10-20 18:16:31.968943 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:16:31.969048 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:31.969125 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:16:31.971802 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:31.973365 (Thread-2): finished collecting timing info
2020-10-20 18:16:31.973933 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1b329af-3b2b-4456-9945-5dd912ea5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213023a0>]}
2020-10-20 18:16:31.974142 (Thread-2): 19:16:31 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 40 in 0.21s]
2020-10-20 18:16:31.974257 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:31.975300 (MainThread): Using postgres connection "master".
2020-10-20 18:16:31.975433 (MainThread): On master: BEGIN
2020-10-20 18:16:31.976725 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:31.976875 (MainThread): On master: COMMIT
2020-10-20 18:16:31.976959 (MainThread): Using postgres connection "master".
2020-10-20 18:16:31.977034 (MainThread): On master: COMMIT
2020-10-20 18:16:31.977969 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:31.978307 (MainThread): 19:16:31 | 
2020-10-20 18:16:31.978429 (MainThread): 19:16:31 | Finished running 1 view model, 1 incremental model in 0.42s.
2020-10-20 18:16:31.978524 (MainThread): Connection 'master' was left open.
2020-10-20 18:16:31.978601 (MainThread): On master: Close
2020-10-20 18:16:31.978701 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:16:31.978772 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:16:31.978863 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:16:31.978932 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:16:31.984788 (MainThread): 
2020-10-20 18:16:31.985097 (MainThread): Completed successfully
2020-10-20 18:16:31.985252 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:16:31.985471 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120f9fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120f8e1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120f8e040>]}
2020-10-20 18:16:31.985708 (MainThread): Flushing usage events
2020-10-20 18:16:36.193500 (MainThread): Running with dbt=0.16.1
2020-10-20 18:16:36.259147 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:16:36.259896 (MainThread): Tracking: tracking
2020-10-20 18:16:36.273484 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f320e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6e9700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6e9ee0>]}
2020-10-20 18:16:36.295217 (MainThread): Partial parsing not enabled
2020-10-20 18:16:36.297063 (MainThread): Parsing macros/core.sql
2020-10-20 18:16:36.301754 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:16:36.310013 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:16:36.311966 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:16:36.329588 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:16:36.365394 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:16:36.387406 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:16:36.389366 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:16:36.395856 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:16:36.409330 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:16:36.416412 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:16:36.423062 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:16:36.428274 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:16:36.429231 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:16:36.430298 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:16:36.431998 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:16:36.434186 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:16:36.443850 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:16:36.446026 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:16:36.447139 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:16:36.492258 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:16:36.493485 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:16:36.494418 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:16:36.495540 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:16:36.497944 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:16:36.500404 (MainThread): Parsing macros/relations.sql
2020-10-20 18:16:36.502134 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:16:36.519882 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:16:36.539155 (MainThread): Partial parsing not enabled
2020-10-20 18:16:36.568561 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:36.568701 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:36.583168 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:36.583288 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:36.614045 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:16:36.614179 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:36.625826 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:16:36.625945 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:37.030711 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:16:37.033216 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:16:37.036076 (MainThread): 
2020-10-20 18:16:37.036414 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:16:37.036511 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:16:37.044274 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:16:37.044479 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:16:37.124812 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:16:37.124955 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:16:37.143361 (ThreadPoolExecutor-0_0): SQL status: SELECT 8 in 0.02 seconds
2020-10-20 18:16:37.158867 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:16:37.159042 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:16:37.160496 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:16:37.160590 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:16:37.162207 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:37.162365 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:16:37.162451 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:16:37.170090 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:16:37.172820 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:16:37.190579 (MainThread): Using postgres connection "master".
2020-10-20 18:16:37.190713 (MainThread): On master: BEGIN
2020-10-20 18:16:37.202757 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:16:37.202935 (MainThread): Using postgres connection "master".
2020-10-20 18:16:37.203029 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:16:37.216139 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-20 18:16:37.217819 (MainThread): On master: ROLLBACK
2020-10-20 18:16:37.219105 (MainThread): Using postgres connection "master".
2020-10-20 18:16:37.219226 (MainThread): On master: BEGIN
2020-10-20 18:16:37.221355 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:37.221512 (MainThread): On master: COMMIT
2020-10-20 18:16:37.221607 (MainThread): Using postgres connection "master".
2020-10-20 18:16:37.221683 (MainThread): On master: COMMIT
2020-10-20 18:16:37.222672 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:37.222989 (MainThread): 19:16:37 | Concurrency: 4 threads (target='dev')
2020-10-20 18:16:37.223108 (MainThread): 19:16:37 | 
2020-10-20 18:16:37.225950 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:16:37.226101 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:37.226268 (Thread-1): 19:16:37 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:16:37.226399 (Thread-2): 19:16:37 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:16:37.226701 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.226951 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.227023 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:16:37.227115 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:16:37.227208 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:16:37.227296 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:37.249698 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:16:37.249986 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:16:37.250412 (Thread-2): finished collecting timing info
2020-10-20 18:16:37.261059 (Thread-1): finished collecting timing info
2020-10-20 18:16:37.300724 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.311781 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:16:37.317154 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.317280 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:16:37.317420 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191637313098"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:16:37.320319 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.320585 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:16:37.322199 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:16:37.323848 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:16:37.324310 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.324422 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:16:37.326339 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:37.326524 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.326622 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:16:37.337362 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:16:37.341181 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.341323 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:16:37.343010 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:16:37.345477 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.345615 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:16:37.347311 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:16:37.348326 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:16:37.348448 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.348525 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:16:37.351584 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:37.353501 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:16:37.353658 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:16:37.359547 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:16:37.362056 (Thread-1): finished collecting timing info
2020-10-20 18:16:37.362804 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a98d3109-dfb4-464a-a4fe-b59287e7810a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139b87f0>]}
2020-10-20 18:16:37.363156 (Thread-1): 19:16:37 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.14s]
2020-10-20 18:16:37.363319 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:16:37.364454 (Thread-2): SQL status: SELECT 44 in 0.04 seconds
2020-10-20 18:16:37.368031 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.368141 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:16:37.369687 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:37.369844 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.369929 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191637313098'
        
      order by ordinal_position

  
2020-10-20 18:16:37.388854 (Thread-2): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:16:37.392716 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.392857 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:16:37.396994 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:16:37.403944 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.404069 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:16:37.407607 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:16:37.408730 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:16:37.409121 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.409207 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191637313098"
    );
  
2020-10-20 18:16:37.413047 (Thread-2): SQL status: INSERT 0 44 in 0.00 seconds
2020-10-20 18:16:37.414006 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:16:37.414109 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:16:37.414184 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:16:37.416438 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:37.417992 (Thread-2): finished collecting timing info
2020-10-20 18:16:37.418559 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a98d3109-dfb4-464a-a4fe-b59287e7810a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113772b50>]}
2020-10-20 18:16:37.418769 (Thread-2): 19:16:37 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 44 in 0.19s]
2020-10-20 18:16:37.418885 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:16:37.419982 (MainThread): Using postgres connection "master".
2020-10-20 18:16:37.420107 (MainThread): On master: BEGIN
2020-10-20 18:16:37.422274 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:16:37.422457 (MainThread): On master: COMMIT
2020-10-20 18:16:37.422543 (MainThread): Using postgres connection "master".
2020-10-20 18:16:37.422621 (MainThread): On master: COMMIT
2020-10-20 18:16:37.424512 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:16:37.424935 (MainThread): 19:16:37 | 
2020-10-20 18:16:37.425065 (MainThread): 19:16:37 | Finished running 1 view model, 1 incremental model in 0.39s.
2020-10-20 18:16:37.425161 (MainThread): Connection 'master' was left open.
2020-10-20 18:16:37.425237 (MainThread): On master: Close
2020-10-20 18:16:37.425347 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:16:37.425417 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:16:37.425507 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:16:37.425575 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:16:37.431159 (MainThread): 
2020-10-20 18:16:37.431330 (MainThread): Completed successfully
2020-10-20 18:16:37.431447 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:16:37.431616 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136518b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136510a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113651160>]}
2020-10-20 18:16:37.431809 (MainThread): Flushing usage events
2020-10-20 18:17:01.768969 (MainThread): Running with dbt=0.16.1
2020-10-20 18:17:01.843315 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:17:01.860946 (MainThread): Tracking: tracking
2020-10-20 18:17:01.876590 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111276df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116416a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111641f10>]}
2020-10-20 18:17:01.896948 (MainThread): Partial parsing not enabled
2020-10-20 18:17:01.899527 (MainThread): Parsing macros/core.sql
2020-10-20 18:17:01.904937 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:17:01.914305 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:17:01.916702 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:17:01.947167 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:17:01.994098 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:17:02.024243 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:17:02.026555 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:17:02.033651 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:17:02.047706 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:17:02.055022 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:17:02.061950 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:17:02.067299 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:17:02.068567 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:17:02.070002 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:17:02.072011 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:17:02.074451 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:17:02.084339 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:17:02.086556 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:17:02.087930 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:17:02.133889 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:17:02.135501 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:17:02.136760 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:17:02.138226 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:17:02.140830 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:17:02.143604 (MainThread): Parsing macros/relations.sql
2020-10-20 18:17:02.145646 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:17:02.164983 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:17:02.184378 (MainThread): Partial parsing not enabled
2020-10-20 18:17:02.241014 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:02.241401 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:17:02.273435 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:02.273596 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:17:02.307079 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:17:02.307225 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:17:02.319587 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:17:02.319739 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:17:02.733156 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:17:02.735533 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:17:02.738360 (MainThread): 
2020-10-20 18:17:02.738674 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:17:02.738773 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:17:02.746480 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:17:02.746640 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:17:02.827084 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:17:02.827229 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:17:02.846153 (ThreadPoolExecutor-0_0): SQL status: SELECT 8 in 0.02 seconds
2020-10-20 18:17:02.862164 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:17:02.862344 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:17:02.863784 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:17:02.863883 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:17:02.865236 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:17:02.865387 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:17:02.865473 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:17:02.873399 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:17:02.876154 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:17:02.894608 (MainThread): Using postgres connection "master".
2020-10-20 18:17:02.894751 (MainThread): On master: BEGIN
2020-10-20 18:17:02.908944 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:17:02.909114 (MainThread): Using postgres connection "master".
2020-10-20 18:17:02.909205 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:17:02.929407 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:17:02.931394 (MainThread): On master: ROLLBACK
2020-10-20 18:17:02.932923 (MainThread): Using postgres connection "master".
2020-10-20 18:17:02.933078 (MainThread): On master: BEGIN
2020-10-20 18:17:02.936233 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:17:02.936426 (MainThread): On master: COMMIT
2020-10-20 18:17:02.936523 (MainThread): Using postgres connection "master".
2020-10-20 18:17:02.936600 (MainThread): On master: COMMIT
2020-10-20 18:17:02.937871 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:17:02.938224 (MainThread): 19:17:02 | Concurrency: 4 threads (target='dev')
2020-10-20 18:17:02.938366 (MainThread): 19:17:02 | 
2020-10-20 18:17:02.942534 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:17:02.942772 (Thread-1): 19:17:02 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:17:02.943085 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:02.943181 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:17:02.943297 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:17:02.943443 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:17:02.943635 (Thread-2): 19:17:02 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:17:02.954452 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:02.959913 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:17:02.960912 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:17:02.961044 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:17:02.968039 (Thread-1): finished collecting timing info
2020-10-20 18:17:02.974531 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:17:03.001562 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.001759 (Thread-2): finished collecting timing info
2020-10-20 18:17:03.002095 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:17:03.018022 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:17:03.026365 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.026541 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:17:03.033530 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:17:03.041052 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:17:03.049332 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:03.049534 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.049635 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191703044729"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:17:03.049738 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:17:03.053176 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:17:03.053366 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.053460 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:17:03.069498 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2020-10-20 18:17:03.073686 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.073852 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:17:03.075618 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:17:03.078222 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.078368 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:17:03.080100 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:17:03.081118 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:17:03.081250 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.081330 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:17:03.084300 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:17:03.086332 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:17:03.086520 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:17:03.095993 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:17:03.098478 (Thread-1): finished collecting timing info
2020-10-20 18:17:03.099165 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06b9544f-e9d6-4438-86f4-f0337f7ea280', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1156c6910>]}
2020-10-20 18:17:03.099430 (Thread-1): 19:17:03 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.16s]
2020-10-20 18:17:03.099561 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:17:03.116798 (Thread-2): SQL status: SELECT 66 in 0.07 seconds
2020-10-20 18:17:03.120765 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:03.120900 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:17:03.122781 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:17:03.122949 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:03.123036 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191703044729'
        
      order by ordinal_position

  
2020-10-20 18:17:03.148072 (Thread-2): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:17:03.151714 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:03.151826 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:17:03.157689 (Thread-2): SQL status: SELECT 6 in 0.01 seconds
2020-10-20 18:17:03.164629 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:03.164771 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:17:03.168302 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:17:03.169498 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:17:03.169876 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:03.169965 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191703044729"
    );
  
2020-10-20 18:17:03.173068 (Thread-2): SQL status: INSERT 0 66 in 0.00 seconds
2020-10-20 18:17:03.174012 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:17:03.174119 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:17:03.174196 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:17:03.177253 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:17:03.178852 (Thread-2): finished collecting timing info
2020-10-20 18:17:03.179442 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06b9544f-e9d6-4438-86f4-f0337f7ea280', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11593b340>]}
2020-10-20 18:17:03.179659 (Thread-2): 19:17:03 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 66 in 0.23s]
2020-10-20 18:17:03.179774 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:17:03.180784 (MainThread): Using postgres connection "master".
2020-10-20 18:17:03.180915 (MainThread): On master: BEGIN
2020-10-20 18:17:03.182479 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:17:03.182641 (MainThread): On master: COMMIT
2020-10-20 18:17:03.182730 (MainThread): Using postgres connection "master".
2020-10-20 18:17:03.182805 (MainThread): On master: COMMIT
2020-10-20 18:17:03.183976 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:17:03.184288 (MainThread): 19:17:03 | 
2020-10-20 18:17:03.184403 (MainThread): 19:17:03 | Finished running 1 view model, 1 incremental model in 0.45s.
2020-10-20 18:17:03.184496 (MainThread): Connection 'master' was left open.
2020-10-20 18:17:03.184571 (MainThread): On master: Close
2020-10-20 18:17:03.184670 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:17:03.184745 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:17:03.184835 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:17:03.184906 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:17:03.190336 (MainThread): 
2020-10-20 18:17:03.190499 (MainThread): Completed successfully
2020-10-20 18:17:03.190610 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:17:03.190779 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1155b5700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115595280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1155954f0>]}
2020-10-20 18:17:03.190975 (MainThread): Flushing usage events
2020-10-20 18:18:29.797421 (MainThread): Running with dbt=0.16.1
2020-10-20 18:18:29.923064 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:18:29.924229 (MainThread): Tracking: tracking
2020-10-20 18:18:29.941915 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dbb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6afb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a88aac0>]}
2020-10-20 18:18:29.977954 (MainThread): Partial parsing not enabled
2020-10-20 18:18:29.981033 (MainThread): Parsing macros/core.sql
2020-10-20 18:18:29.991547 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:18:30.002482 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:18:30.005124 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:18:30.030035 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:18:30.082253 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:18:30.124891 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:18:30.129181 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:18:30.140493 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:18:30.163231 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:18:30.174875 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:18:30.186862 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:18:30.195946 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:18:30.198048 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:18:30.199902 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:18:30.202558 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:18:30.207804 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:18:30.224290 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:18:30.228905 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:18:30.231833 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:18:30.303890 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:18:30.306820 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:18:30.309110 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:18:30.311173 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:18:30.316033 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:18:30.320931 (MainThread): Parsing macros/relations.sql
2020-10-20 18:18:30.324162 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:18:30.353632 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:18:30.384449 (MainThread): Partial parsing not enabled
2020-10-20 18:18:30.432183 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:30.432386 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:18:30.457556 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:30.457723 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:18:30.540343 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:18:30.541408 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:18:30.571681 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:18:30.571916 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:18:31.205427 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:18:31.210193 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:18:31.215443 (MainThread): 
2020-10-20 18:18:31.215835 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:18:31.215946 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:18:31.229621 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:18:31.229792 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:18:31.319448 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:18:31.319606 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:18:31.342000 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.02 seconds
2020-10-20 18:18:31.362568 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:18:31.362736 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:18:31.364386 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:18:31.364523 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:18:31.366055 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:18:31.366207 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:18:31.366308 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:18:31.377543 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:18:31.380636 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:18:31.402399 (MainThread): Using postgres connection "master".
2020-10-20 18:18:31.402549 (MainThread): On master: BEGIN
2020-10-20 18:18:31.421750 (MainThread): SQL status: BEGIN in 0.02 seconds
2020-10-20 18:18:31.421928 (MainThread): Using postgres connection "master".
2020-10-20 18:18:31.422017 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:18:31.441691 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:18:31.443817 (MainThread): On master: ROLLBACK
2020-10-20 18:18:31.448127 (MainThread): Using postgres connection "master".
2020-10-20 18:18:31.448306 (MainThread): On master: BEGIN
2020-10-20 18:18:31.452639 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:18:31.452855 (MainThread): On master: COMMIT
2020-10-20 18:18:31.452976 (MainThread): Using postgres connection "master".
2020-10-20 18:18:31.453063 (MainThread): On master: COMMIT
2020-10-20 18:18:31.454425 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:18:31.454900 (MainThread): 19:18:31 | Concurrency: 4 threads (target='dev')
2020-10-20 18:18:31.455072 (MainThread): 19:18:31 | 
2020-10-20 18:18:31.459286 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:18:31.459470 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:18:31.459670 (Thread-1): 19:18:31 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:18:31.459802 (Thread-2): 19:18:31 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:18:31.460184 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.460496 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.460590 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:18:31.460715 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:18:31.460839 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:18:31.460961 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:18:31.482300 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:18:31.484233 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:18:31.484701 (Thread-1): finished collecting timing info
2020-10-20 18:18:31.484987 (Thread-2): finished collecting timing info
2020-10-20 18:18:31.543444 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.548785 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:18:31.564511 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:18:31.567070 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.567229 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:18:31.574325 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.574488 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:18:31.574648 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191831569548"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:18:31.577498 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:18:31.578207 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.578334 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:18:31.581718 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:18:31.581910 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.582009 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:18:31.598486 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2020-10-20 18:18:31.602861 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.603024 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:18:31.605114 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:18:31.607739 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.607919 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:18:31.609991 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:18:31.611179 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:18:31.611351 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.611443 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:18:31.614456 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:18:31.616537 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:18:31.616708 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:18:31.623475 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:18:31.626132 (Thread-1): finished collecting timing info
2020-10-20 18:18:31.626859 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fd22c0f-4bea-4775-bbfa-eb76dc64075b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112da88b0>]}
2020-10-20 18:18:31.627140 (Thread-1): 19:18:31 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.17s]
2020-10-20 18:18:31.627277 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:18:31.648794 (Thread-2): SQL status: SELECT 100 in 0.07 seconds
2020-10-20 18:18:31.653005 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.653186 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:18:31.655108 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:18:31.655316 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.655434 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191831569548'
        
      order by ordinal_position

  
2020-10-20 18:18:31.705483 (Thread-2): SQL status: SELECT 6 in 0.05 seconds
2020-10-20 18:18:31.709602 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.709834 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:18:31.719267 (Thread-2): SQL status: SELECT 6 in 0.01 seconds
2020-10-20 18:18:31.726829 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.726977 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:18:31.734315 (Thread-2): SQL status: SELECT 6 in 0.01 seconds
2020-10-20 18:18:31.735565 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:18:31.735990 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.736097 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191831569548"
    );
  
2020-10-20 18:18:31.740572 (Thread-2): SQL status: INSERT 0 100 in 0.00 seconds
2020-10-20 18:18:31.741572 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:18:31.741799 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:18:31.741985 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:18:31.747556 (Thread-2): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:18:31.749199 (Thread-2): finished collecting timing info
2020-10-20 18:18:31.749855 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fd22c0f-4bea-4775-bbfa-eb76dc64075b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112afe6d0>]}
2020-10-20 18:18:31.750096 (Thread-2): 19:18:31 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 100 in 0.29s]
2020-10-20 18:18:31.750220 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:18:31.751322 (MainThread): Using postgres connection "master".
2020-10-20 18:18:31.751447 (MainThread): On master: BEGIN
2020-10-20 18:18:31.753140 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:18:31.753303 (MainThread): On master: COMMIT
2020-10-20 18:18:31.753392 (MainThread): Using postgres connection "master".
2020-10-20 18:18:31.753464 (MainThread): On master: COMMIT
2020-10-20 18:18:31.755197 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:18:31.755594 (MainThread): 19:18:31 | 
2020-10-20 18:18:31.755735 (MainThread): 19:18:31 | Finished running 1 view model, 1 incremental model in 0.54s.
2020-10-20 18:18:31.755835 (MainThread): Connection 'master' was left open.
2020-10-20 18:18:31.755916 (MainThread): On master: Close
2020-10-20 18:18:31.756037 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:18:31.756204 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:18:31.756320 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:18:31.756447 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:18:31.762547 (MainThread): 
2020-10-20 18:18:31.762942 (MainThread): Completed successfully
2020-10-20 18:18:31.763069 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:18:31.763239 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a1dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a04a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a04490>]}
2020-10-20 18:18:31.763425 (MainThread): Flushing usage events
2020-10-20 18:19:06.758703 (MainThread): Running with dbt=0.16.1
2020-10-20 18:19:06.901599 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:19:06.921390 (MainThread): Tracking: tracking
2020-10-20 18:19:06.944023 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c4d9e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8a1700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8a1ee0>]}
2020-10-20 18:19:06.980813 (MainThread): Partial parsing not enabled
2020-10-20 18:19:06.984681 (MainThread): Parsing macros/core.sql
2020-10-20 18:19:06.993273 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:19:07.007487 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:19:07.011476 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:19:07.044314 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:19:07.104843 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:19:07.140555 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:19:07.143619 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:19:07.154787 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:19:07.177308 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:19:07.189150 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:19:07.199260 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:19:07.208144 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:19:07.210303 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:19:07.212380 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:19:07.216323 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:19:07.220651 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:19:07.240411 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:19:07.245149 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:19:07.249748 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:19:07.341655 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:19:07.345169 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:19:07.347577 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:19:07.350471 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:19:07.355178 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:19:07.359884 (MainThread): Parsing macros/relations.sql
2020-10-20 18:19:07.362806 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:19:07.398403 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:19:07.438639 (MainThread): Partial parsing not enabled
2020-10-20 18:19:07.495270 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:07.495421 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:19:07.525434 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:07.525588 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:19:07.588990 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:19:07.589544 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:19:07.618909 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:19:07.619064 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:19:08.308277 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:19:08.311489 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:19:08.314891 (MainThread): 
2020-10-20 18:19:08.315485 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:19:08.315632 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:19:08.344437 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:19:08.344606 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:19:08.435497 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:19:08.435659 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:19:08.463837 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.03 seconds
2020-10-20 18:19:08.482648 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:19:08.482852 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:19:08.484453 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:19:08.484582 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:19:08.486203 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:19:08.486376 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:19:08.486470 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:19:08.496574 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:19:08.499516 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:19:08.523096 (MainThread): Using postgres connection "master".
2020-10-20 18:19:08.523353 (MainThread): On master: BEGIN
2020-10-20 18:19:08.543342 (MainThread): SQL status: BEGIN in 0.02 seconds
2020-10-20 18:19:08.543527 (MainThread): Using postgres connection "master".
2020-10-20 18:19:08.543612 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:19:08.579513 (MainThread): SQL status: SELECT 1 in 0.04 seconds
2020-10-20 18:19:08.581460 (MainThread): On master: ROLLBACK
2020-10-20 18:19:08.582975 (MainThread): Using postgres connection "master".
2020-10-20 18:19:08.583134 (MainThread): On master: BEGIN
2020-10-20 18:19:08.587836 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:19:08.588045 (MainThread): On master: COMMIT
2020-10-20 18:19:08.588146 (MainThread): Using postgres connection "master".
2020-10-20 18:19:08.588224 (MainThread): On master: COMMIT
2020-10-20 18:19:08.590095 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:19:08.590516 (MainThread): 19:19:08 | Concurrency: 4 threads (target='dev')
2020-10-20 18:19:08.590660 (MainThread): 19:19:08 | 
2020-10-20 18:19:08.596282 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:19:08.596473 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:19:08.596629 (Thread-1): 19:19:08 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:19:08.596766 (Thread-2): 19:19:08 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:19:08.597112 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.597394 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.597495 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:19:08.597586 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:19:08.597681 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:19:08.597787 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:19:08.617279 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:19:08.621109 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:19:08.621556 (Thread-2): finished collecting timing info
2020-10-20 18:19:08.621874 (Thread-1): finished collecting timing info
2020-10-20 18:19:08.674936 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.680222 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:19:08.694236 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.694410 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020191908690026"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:19:08.695889 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:19:08.699320 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.699483 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:19:08.701505 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:19:08.703239 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:19:08.703698 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.703806 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:19:08.709032 (Thread-1): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:19:08.709207 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.709299 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:19:08.738355 (Thread-1): SQL status: CREATE VIEW in 0.03 seconds
2020-10-20 18:19:08.743024 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.743319 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:19:08.745051 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:19:08.748180 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.748336 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:19:08.751291 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:19:08.752554 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:19:08.752708 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.752791 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:19:08.762288 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:19:08.764373 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:19:08.764540 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:19:08.769278 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:19:08.772044 (Thread-1): finished collecting timing info
2020-10-20 18:19:08.772794 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b02a1432-d01d-4083-b0d5-c38dd549bae1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e810c70>]}
2020-10-20 18:19:08.773076 (Thread-1): 19:19:08 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.18s]
2020-10-20 18:19:08.773214 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:19:08.816146 (Thread-2): SQL status: SELECT 100 in 0.12 seconds
2020-10-20 18:19:08.820429 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.820654 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:19:08.822595 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:19:08.822828 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.822920 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020191908690026'
        
      order by ordinal_position

  
2020-10-20 18:19:08.866768 (Thread-2): SQL status: SELECT 6 in 0.04 seconds
2020-10-20 18:19:08.870877 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.871031 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:19:08.883781 (Thread-2): SQL status: SELECT 6 in 0.01 seconds
2020-10-20 18:19:08.891419 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.891600 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:19:08.896220 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:19:08.897422 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:19:08.897870 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.897991 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020191908690026"
    );
  
2020-10-20 18:19:08.903204 (Thread-2): SQL status: INSERT 0 100 in 0.01 seconds
2020-10-20 18:19:08.904234 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:19:08.904363 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:19:08.904444 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:19:08.910786 (Thread-2): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:19:08.912696 (Thread-2): finished collecting timing info
2020-10-20 18:19:08.913484 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b02a1432-d01d-4083-b0d5-c38dd549bae1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e825cd0>]}
2020-10-20 18:19:08.913767 (Thread-2): 19:19:08 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 100 in 0.32s]
2020-10-20 18:19:08.913913 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:19:08.915027 (MainThread): Using postgres connection "master".
2020-10-20 18:19:08.915185 (MainThread): On master: BEGIN
2020-10-20 18:19:08.916561 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:19:08.916739 (MainThread): On master: COMMIT
2020-10-20 18:19:08.916830 (MainThread): Using postgres connection "master".
2020-10-20 18:19:08.916909 (MainThread): On master: COMMIT
2020-10-20 18:19:08.918619 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:19:08.919110 (MainThread): 19:19:08 | 
2020-10-20 18:19:08.919261 (MainThread): 19:19:08 | Finished running 1 view model, 1 incremental model in 0.60s.
2020-10-20 18:19:08.919370 (MainThread): Connection 'master' was left open.
2020-10-20 18:19:08.919451 (MainThread): On master: Close
2020-10-20 18:19:08.919564 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:19:08.919689 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:19:08.919805 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:19:08.919987 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:19:08.926607 (MainThread): 
2020-10-20 18:19:08.926815 (MainThread): Completed successfully
2020-10-20 18:19:08.926947 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:19:08.927165 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e850e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e850a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e6f15b0>]}
2020-10-20 18:19:08.927452 (MainThread): Flushing usage events
2020-10-20 18:38:20.206962 (MainThread): Running with dbt=0.16.1
2020-10-20 18:38:20.287986 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:38:20.288942 (MainThread): Tracking: tracking
2020-10-20 18:38:20.303636 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115672f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115647730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115a34ac0>]}
2020-10-20 18:38:20.333984 (MainThread): Partial parsing not enabled
2020-10-20 18:38:20.338672 (MainThread): Parsing macros/core.sql
2020-10-20 18:38:20.348447 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:38:20.365960 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:38:20.368773 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:38:20.387117 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:38:20.422812 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:38:20.444771 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:38:20.446983 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:38:20.453582 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:38:20.467175 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:38:20.474483 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:38:20.481147 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:38:20.486533 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:38:20.487845 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:38:20.489221 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:38:20.491229 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:38:20.493646 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:38:20.503253 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:38:20.505372 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:38:20.506704 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:38:20.549584 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:38:20.551176 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:38:20.552364 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:38:20.553741 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:38:20.556131 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:38:20.558829 (MainThread): Parsing macros/relations.sql
2020-10-20 18:38:20.560852 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:38:20.578907 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:38:20.597573 (MainThread): Partial parsing not enabled
2020-10-20 18:38:20.629712 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:20.629856 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:20.644681 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:20.644804 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:20.675725 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:38:20.675861 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:20.687683 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:38:20.687802 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:21.113441 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:38:21.115998 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:38:21.118766 (MainThread): 
2020-10-20 18:38:21.119077 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:38:21.119167 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:21.127005 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:38:21.127202 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:38:21.213261 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:38:21.213450 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:38:21.235938 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.02 seconds
2020-10-20 18:38:21.253691 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:38:21.253898 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:38:21.255673 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:38:21.255820 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:38:21.258293 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:21.258528 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:38:21.258693 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:38:21.268804 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:38:21.272187 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:38:21.301434 (MainThread): Using postgres connection "master".
2020-10-20 18:38:21.301712 (MainThread): On master: BEGIN
2020-10-20 18:38:21.315380 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:38:21.315564 (MainThread): Using postgres connection "master".
2020-10-20 18:38:21.315662 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:38:21.336725 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:38:21.340121 (MainThread): On master: ROLLBACK
2020-10-20 18:38:21.342066 (MainThread): Using postgres connection "master".
2020-10-20 18:38:21.342219 (MainThread): On master: BEGIN
2020-10-20 18:38:21.345030 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:21.345289 (MainThread): On master: COMMIT
2020-10-20 18:38:21.345400 (MainThread): Using postgres connection "master".
2020-10-20 18:38:21.345479 (MainThread): On master: COMMIT
2020-10-20 18:38:21.346763 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:38:21.347444 (MainThread): 19:38:21 | Concurrency: 4 threads (target='dev')
2020-10-20 18:38:21.347624 (MainThread): 19:38:21 | 
2020-10-20 18:38:21.354685 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:38:21.354857 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:38:21.355054 (Thread-1): 19:38:21 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:38:21.355189 (Thread-2): 19:38:21 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:38:21.355605 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.355951 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.356050 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:38:21.356169 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:38:21.356290 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:38:21.356412 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:38:21.380480 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:38:21.380596 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:38:21.381236 (Thread-2): finished collecting timing info
2020-10-20 18:38:21.381488 (Thread-1): finished collecting timing info
2020-10-20 18:38:21.457563 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.462835 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:38:21.466521 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.466818 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020193821461778"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:38:21.472299 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:38:21.475077 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.475227 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:38:21.477001 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:38:21.478773 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:38:21.479218 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.479320 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:38:21.481016 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:21.481217 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.481343 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:38:21.499167 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2020-10-20 18:38:21.503873 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.504127 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:38:21.506508 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:38:21.509237 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.509374 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:38:21.510846 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:38:21.511914 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:38:21.512135 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.512268 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:38:21.517823 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:38:21.520216 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:21.520385 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:38:21.525387 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:38:21.528323 (Thread-1): finished collecting timing info
2020-10-20 18:38:21.529065 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1d99c1a-0920-4201-a6a3-fc39d4bef97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dd52fa0>]}
2020-10-20 18:38:21.529313 (Thread-1): 19:38:21 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.17s]
2020-10-20 18:38:21.529436 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:38:21.533853 (Thread-2): SQL status: SELECT 0 in 0.07 seconds
2020-10-20 18:38:21.537995 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.538263 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:38:21.539826 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:21.540029 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.540125 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020193821461778'
        
      order by ordinal_position

  
2020-10-20 18:38:21.563929 (Thread-2): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:38:21.567706 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.567872 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:38:21.574400 (Thread-2): SQL status: SELECT 6 in 0.01 seconds
2020-10-20 18:38:21.582601 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.582770 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:38:21.587326 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:38:21.588473 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:38:21.588900 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.588997 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020193821461778"
    );
  
2020-10-20 18:38:21.591617 (Thread-2): SQL status: INSERT 0 0 in 0.00 seconds
2020-10-20 18:38:21.592614 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:38:21.592731 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:21.592807 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:38:21.596078 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:38:21.597684 (Thread-2): finished collecting timing info
2020-10-20 18:38:21.598279 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1d99c1a-0920-4201-a6a3-fc39d4bef97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dd4aca0>]}
2020-10-20 18:38:21.598495 (Thread-2): 19:38:21 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 0 in 0.24s]
2020-10-20 18:38:21.598614 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:38:21.599723 (MainThread): Using postgres connection "master".
2020-10-20 18:38:21.599874 (MainThread): On master: BEGIN
2020-10-20 18:38:21.601218 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:21.601391 (MainThread): On master: COMMIT
2020-10-20 18:38:21.601517 (MainThread): Using postgres connection "master".
2020-10-20 18:38:21.601603 (MainThread): On master: COMMIT
2020-10-20 18:38:21.603378 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:38:21.603778 (MainThread): 19:38:21 | 
2020-10-20 18:38:21.603902 (MainThread): 19:38:21 | Finished running 1 view model, 1 incremental model in 0.48s.
2020-10-20 18:38:21.603996 (MainThread): Connection 'master' was left open.
2020-10-20 18:38:21.604073 (MainThread): On master: Close
2020-10-20 18:38:21.604176 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:38:21.604293 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:38:21.604414 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:38:21.604545 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:38:21.610568 (MainThread): 
2020-10-20 18:38:21.610820 (MainThread): Completed successfully
2020-10-20 18:38:21.610950 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:38:21.611140 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11da8ad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d996fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d9adb20>]}
2020-10-20 18:38:21.611364 (MainThread): Flushing usage events
2020-10-20 18:38:56.301744 (MainThread): Running with dbt=0.16.1
2020-10-20 18:38:56.378976 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:38:56.394483 (MainThread): Tracking: tracking
2020-10-20 18:38:56.407213 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115930e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115cf9700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115cf9ee0>]}
2020-10-20 18:38:56.427725 (MainThread): Partial parsing not enabled
2020-10-20 18:38:56.429807 (MainThread): Parsing macros/core.sql
2020-10-20 18:38:56.435209 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:38:56.443689 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:38:56.445901 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:38:56.463537 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:38:56.498289 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:38:56.519719 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:38:56.521930 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:38:56.528532 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:38:56.541991 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:38:56.549512 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:38:56.556905 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:38:56.563551 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:38:56.564919 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:38:56.566482 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:38:56.569590 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:38:56.575592 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:38:56.599481 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:38:56.602435 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:38:56.604093 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:38:56.671171 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:38:56.674751 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:38:56.677301 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:38:56.679393 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:38:56.682254 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:38:56.686051 (MainThread): Parsing macros/relations.sql
2020-10-20 18:38:56.688108 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:38:56.706741 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:38:56.726019 (MainThread): Partial parsing not enabled
2020-10-20 18:38:56.756179 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:56.756323 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:56.773266 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:56.773425 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:56.812488 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:38:56.812648 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:56.826527 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:38:56.826680 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:57.260196 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:38:57.262703 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:38:57.265644 (MainThread): 
2020-10-20 18:38:57.265969 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:38:57.266066 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:38:57.274972 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:38:57.275188 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:38:57.354866 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:38:57.355013 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:38:57.370488 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.02 seconds
2020-10-20 18:38:57.386758 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:38:57.386926 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:38:57.388355 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:38:57.388449 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:38:57.389939 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:57.390097 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:38:57.390182 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:38:57.397948 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:38:57.400683 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:38:57.418484 (MainThread): Using postgres connection "master".
2020-10-20 18:38:57.418618 (MainThread): On master: BEGIN
2020-10-20 18:38:57.431253 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:38:57.431433 (MainThread): Using postgres connection "master".
2020-10-20 18:38:57.431523 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:38:57.447934 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:38:57.449621 (MainThread): On master: ROLLBACK
2020-10-20 18:38:57.450845 (MainThread): Using postgres connection "master".
2020-10-20 18:38:57.450961 (MainThread): On master: BEGIN
2020-10-20 18:38:57.452825 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:57.452964 (MainThread): On master: COMMIT
2020-10-20 18:38:57.453056 (MainThread): Using postgres connection "master".
2020-10-20 18:38:57.453132 (MainThread): On master: COMMIT
2020-10-20 18:38:57.454107 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:38:57.454434 (MainThread): 19:38:57 | Concurrency: 4 threads (target='dev')
2020-10-20 18:38:57.454559 (MainThread): 19:38:57 | 
2020-10-20 18:38:57.458430 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:38:57.458573 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:38:57.458740 (Thread-1): 19:38:57 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:38:57.458867 (Thread-2): 19:38:57 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:38:57.459176 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.459418 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.459516 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:38:57.459613 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:38:57.459709 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:38:57.459798 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:38:57.474578 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:38:57.480587 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:38:57.481064 (Thread-1): finished collecting timing info
2020-10-20 18:38:57.487614 (Thread-2): finished collecting timing info
2020-10-20 18:38:57.533652 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.539819 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:38:57.548079 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:38:57.559514 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.562645 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.562821 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020193857555601"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:38:57.563025 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:38:57.566044 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:38:57.567863 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:38:57.568362 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.568515 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:38:57.570362 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:57.570527 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.570609 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:38:57.583575 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:38:57.587499 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.587642 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:38:57.589610 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:38:57.592234 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.592388 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:38:57.594535 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:38:57.595585 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:38:57.595710 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.595787 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:38:57.602755 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:38:57.604724 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:38:57.604879 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:38:57.609068 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:38:57.611539 (Thread-1): finished collecting timing info
2020-10-20 18:38:57.612224 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5324627c-47f5-47c0-8f92-9ae97337041d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bfff850>]}
2020-10-20 18:38:57.612497 (Thread-1): 19:38:57 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.15s]
2020-10-20 18:38:57.612640 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:38:57.614574 (Thread-2): SQL status: SELECT 0 in 0.05 seconds
2020-10-20 18:38:57.618471 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.618621 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:38:57.620282 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:57.620448 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.620535 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020193857555601'
        
      order by ordinal_position

  
2020-10-20 18:38:57.647439 (Thread-2): SQL status: SELECT 6 in 0.03 seconds
2020-10-20 18:38:57.651279 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.651416 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:38:57.655850 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:38:57.663399 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.663552 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:38:57.667286 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:38:57.668422 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:38:57.668864 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.668985 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020193857555601"
    );
  
2020-10-20 18:38:57.671226 (Thread-2): SQL status: INSERT 0 0 in 0.00 seconds
2020-10-20 18:38:57.672235 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:38:57.672359 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:38:57.672440 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:38:57.675063 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:38:57.676684 (Thread-2): finished collecting timing info
2020-10-20 18:38:57.677290 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5324627c-47f5-47c0-8f92-9ae97337041d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd506a0>]}
2020-10-20 18:38:57.677516 (Thread-2): 19:38:57 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 0 in 0.22s]
2020-10-20 18:38:57.677631 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:38:57.678588 (MainThread): Using postgres connection "master".
2020-10-20 18:38:57.678704 (MainThread): On master: BEGIN
2020-10-20 18:38:57.680463 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:38:57.680644 (MainThread): On master: COMMIT
2020-10-20 18:38:57.680734 (MainThread): Using postgres connection "master".
2020-10-20 18:38:57.680806 (MainThread): On master: COMMIT
2020-10-20 18:38:57.681847 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:38:57.682219 (MainThread): 19:38:57 | 
2020-10-20 18:38:57.682346 (MainThread): 19:38:57 | Finished running 1 view model, 1 incremental model in 0.42s.
2020-10-20 18:38:57.682443 (MainThread): Connection 'master' was left open.
2020-10-20 18:38:57.682517 (MainThread): On master: Close
2020-10-20 18:38:57.682622 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:38:57.682694 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:38:57.682781 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:38:57.682849 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:38:57.688346 (MainThread): 
2020-10-20 18:38:57.688528 (MainThread): Completed successfully
2020-10-20 18:38:57.688631 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:38:57.688800 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bc62f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bc57970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bc57160>]}
2020-10-20 18:38:57.689006 (MainThread): Flushing usage events
2020-10-20 18:39:18.415279 (MainThread): Running with dbt=0.16.1
2020-10-20 18:39:18.481771 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:39:18.482597 (MainThread): Tracking: tracking
2020-10-20 18:39:18.494700 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c0e0ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c4a9e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c4a9730>]}
2020-10-20 18:39:18.514076 (MainThread): Partial parsing not enabled
2020-10-20 18:39:18.515896 (MainThread): Parsing macros/core.sql
2020-10-20 18:39:18.520918 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:39:18.529412 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:39:18.531357 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:39:18.548622 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:39:18.583330 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:39:18.604323 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:39:18.606212 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:39:18.613084 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:39:18.628656 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:39:18.636498 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:39:18.643827 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:39:18.649414 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:39:18.650415 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:39:18.651525 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:39:18.653501 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:39:18.655901 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:39:18.666182 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:39:18.668548 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:39:18.669768 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:39:18.716290 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:39:18.717573 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:39:18.718552 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:39:18.719711 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:39:18.722075 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:39:18.724575 (MainThread): Parsing macros/relations.sql
2020-10-20 18:39:18.726356 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:39:18.744470 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:39:18.764828 (MainThread): Partial parsing not enabled
2020-10-20 18:39:18.795740 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:18.795902 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:18.811716 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:18.811868 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:18.844898 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:39:18.845072 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:18.858768 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:39:18.859120 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:19.171905 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:39:19.174241 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:39:19.176942 (MainThread): 
2020-10-20 18:39:19.177271 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:39:19.177362 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:19.184477 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:39:19.184592 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:39:19.264380 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:39:19.264522 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:39:19.282305 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.02 seconds
2020-10-20 18:39:19.298090 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:39:19.298270 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:39:19.299698 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:39:19.299797 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:39:19.301483 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:19.301633 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:39:19.301731 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:39:19.310424 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-20 18:39:19.313352 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:39:19.331010 (MainThread): Using postgres connection "master".
2020-10-20 18:39:19.331150 (MainThread): On master: BEGIN
2020-10-20 18:39:19.344178 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:39:19.344361 (MainThread): Using postgres connection "master".
2020-10-20 18:39:19.344452 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:39:19.357408 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-20 18:39:19.359141 (MainThread): On master: ROLLBACK
2020-10-20 18:39:19.360403 (MainThread): Using postgres connection "master".
2020-10-20 18:39:19.360520 (MainThread): On master: BEGIN
2020-10-20 18:39:19.362476 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:19.362628 (MainThread): On master: COMMIT
2020-10-20 18:39:19.362725 (MainThread): Using postgres connection "master".
2020-10-20 18:39:19.362803 (MainThread): On master: COMMIT
2020-10-20 18:39:19.363788 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:39:19.364115 (MainThread): 19:39:19 | Concurrency: 4 threads (target='dev')
2020-10-20 18:39:19.364241 (MainThread): 19:39:19 | 
2020-10-20 18:39:19.366903 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:39:19.367047 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:39:19.367227 (Thread-1): 19:39:19 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:39:19.367359 (Thread-2): 19:39:19 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:39:19.367663 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.367964 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.368067 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:39:19.368165 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:39:19.368263 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:39:19.368367 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:39:19.391436 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:39:19.392244 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:39:19.392604 (Thread-2): finished collecting timing info
2020-10-20 18:39:19.398659 (Thread-1): finished collecting timing info
2020-10-20 18:39:19.455703 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.462162 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:39:19.470675 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.470819 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:39:19.470911 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201020193919466509"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-20 18:39:19.473880 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.474168 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:39:19.476017 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:39:19.477809 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:39:19.478262 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.478368 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:39:19.479956 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:19.480132 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.480233 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:39:19.493332 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-20 18:39:19.502663 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.503189 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:39:19.506036 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:39:19.513919 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.514091 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:39:19.515119 (Thread-2): SQL status: SELECT 0 in 0.04 seconds
2020-10-20 18:39:19.519186 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.519299 (Thread-1): SQL status: ALTER TABLE in 0.01 seconds
2020-10-20 18:39:19.519437 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:39:19.520287 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:39:19.520538 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.520644 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:39:19.522606 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:19.523101 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.523334 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201020193919466509'
        
      order by ordinal_position

  
2020-10-20 18:39:19.525015 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:39:19.527235 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:19.527384 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:39:19.531486 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:39:19.536989 (Thread-1): finished collecting timing info
2020-10-20 18:39:19.538888 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4372381a-ac01-4e4a-933c-1408f9ea94c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e65bfd0>]}
2020-10-20 18:39:19.539463 (Thread-1): 19:39:19 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.17s]
2020-10-20 18:39:19.539905 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:39:19.547445 (Thread-2): SQL status: SELECT 6 in 0.02 seconds
2020-10-20 18:39:19.551317 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.551492 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:39:19.555645 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:39:19.562648 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.562776 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-20 18:39:19.566441 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-20 18:39:19.567531 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:39:19.567978 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.568071 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201020193919466509"
    );
  
2020-10-20 18:39:19.570485 (Thread-2): SQL status: INSERT 0 0 in 0.00 seconds
2020-10-20 18:39:19.571509 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:39:19.571621 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:19.571699 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:39:19.574312 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:39:19.575895 (Thread-2): finished collecting timing info
2020-10-20 18:39:19.576463 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4372381a-ac01-4e4a-933c-1408f9ea94c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e40eb80>]}
2020-10-20 18:39:19.576675 (Thread-2): 19:39:19 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 0 in 0.21s]
2020-10-20 18:39:19.576791 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:39:19.577770 (MainThread): Using postgres connection "master".
2020-10-20 18:39:19.577873 (MainThread): On master: BEGIN
2020-10-20 18:39:19.579275 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:19.579448 (MainThread): On master: COMMIT
2020-10-20 18:39:19.579546 (MainThread): Using postgres connection "master".
2020-10-20 18:39:19.579630 (MainThread): On master: COMMIT
2020-10-20 18:39:19.581067 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:39:19.581434 (MainThread): 19:39:19 | 
2020-10-20 18:39:19.581560 (MainThread): 19:39:19 | Finished running 1 view model, 1 incremental model in 0.40s.
2020-10-20 18:39:19.581656 (MainThread): Connection 'master' was left open.
2020-10-20 18:39:19.581733 (MainThread): On master: Close
2020-10-20 18:39:19.581835 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:39:19.581906 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:39:19.581998 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:39:19.582068 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:39:19.587735 (MainThread): 
2020-10-20 18:39:19.587902 (MainThread): Completed successfully
2020-10-20 18:39:19.588009 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:39:19.588189 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e307fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e2f0070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e2f0be0>]}
2020-10-20 18:39:19.588438 (MainThread): Flushing usage events
2020-10-20 18:39:29.762630 (MainThread): Running with dbt=0.16.1
2020-10-20 18:39:29.832314 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:39:29.832946 (MainThread): Tracking: tracking
2020-10-20 18:39:29.848377 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f5e910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112327e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112327580>]}
2020-10-20 18:39:29.898035 (MainThread): Partial parsing not enabled
2020-10-20 18:39:29.899947 (MainThread): Parsing macros/core.sql
2020-10-20 18:39:29.909910 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:39:29.923578 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:39:29.925645 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:39:29.950730 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:39:29.990068 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:39:30.011902 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:39:30.013878 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:39:30.020260 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:39:30.033461 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:39:30.040461 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:39:30.048011 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:39:30.053530 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:39:30.054612 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:39:30.055734 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:39:30.057510 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-20 18:39:30.059713 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:39:30.069098 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:39:30.071139 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:39:30.072242 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:39:30.116486 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:39:30.117805 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:39:30.118754 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:39:30.119879 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:39:30.122169 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:39:30.124695 (MainThread): Parsing macros/relations.sql
2020-10-20 18:39:30.126425 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:39:30.144031 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-20 18:39:30.162734 (MainThread): Partial parsing not enabled
2020-10-20 18:39:30.190968 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.191102 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:30.205912 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:30.206036 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:30.237056 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-20 18:39:30.237194 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:30.248749 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-20 18:39:30.248867 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:30.567589 (MainThread): scipy not found, skipping conversion test.
2020-10-20 18:39:30.569863 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-20 18:39:30.572786 (MainThread): 
2020-10-20 18:39:30.573195 (MainThread): Acquiring new postgres connection "master".
2020-10-20 18:39:30.573292 (MainThread): Opening a new connection, currently in state init
2020-10-20 18:39:30.581053 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-20 18:39:30.581250 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:39:30.661651 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-20 18:39:30.661796 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-20 18:39:30.678081 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.02 seconds
2020-10-20 18:39:30.693869 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-20 18:39:30.694049 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-20 18:39:30.695467 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:39:30.695564 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-20 18:39:30.697190 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:30.697336 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-20 18:39:30.697426 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-20 18:39:30.704830 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.01 seconds
2020-10-20 18:39:30.706888 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-20 18:39:30.724712 (MainThread): Using postgres connection "master".
2020-10-20 18:39:30.724843 (MainThread): On master: BEGIN
2020-10-20 18:39:30.736923 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-20 18:39:30.737110 (MainThread): Using postgres connection "master".
2020-10-20 18:39:30.737208 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-20 18:39:30.753848 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-20 18:39:30.755586 (MainThread): On master: ROLLBACK
2020-10-20 18:39:30.756725 (MainThread): Using postgres connection "master".
2020-10-20 18:39:30.756849 (MainThread): On master: BEGIN
2020-10-20 18:39:30.758908 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:30.759199 (MainThread): On master: COMMIT
2020-10-20 18:39:30.759312 (MainThread): Using postgres connection "master".
2020-10-20 18:39:30.759395 (MainThread): On master: COMMIT
2020-10-20 18:39:30.760400 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:39:30.760714 (MainThread): 19:39:30 | Concurrency: 4 threads (target='dev')
2020-10-20 18:39:30.760847 (MainThread): 19:39:30 | 
2020-10-20 18:39:30.763560 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-20 18:39:30.763694 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:39:30.763855 (Thread-1): 19:39:30 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-20 18:39:30.763994 (Thread-2): 19:39:30 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-20 18:39:30.764307 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.764439 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-20 18:39:30.764697 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:30.764791 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-20 18:39:30.764893 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:39:30.776177 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-20 18:39:30.780501 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:39:30.786386 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:39:30.786764 (Thread-1): finished collecting timing info
2020-10-20 18:39:30.793329 (Thread-2): finished collecting timing info
2020-10-20 18:39:30.837921 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.843494 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-20 18:39:30.861732 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-20 18:39:30.866522 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-20 18:39:30.870205 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.870480 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:39:30.870857 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:30.871054 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-20 18:39:30.872617 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:39:30.876195 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-20 18:39:30.877250 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.877482 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-20 18:39:30.880283 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:30.881163 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.882277 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-20 18:39:30.893843 (Thread-2): SQL status: BEGIN in 0.02 seconds
2020-10-20 18:39:30.894314 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:30.894507 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

  create  table "ingestions"."public"."covid19_stats_incremental"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




GROUP BY country, day
  );
  
2020-10-20 18:39:30.898816 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2020-10-20 18:39:30.910211 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.910389 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-20 18:39:30.914541 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:39:30.921278 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.921611 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-20 18:39:30.923795 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-20 18:39:30.925654 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:39:30.925867 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.926017 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-20 18:39:30.931230 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-10-20 18:39:30.933384 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-20 18:39:30.933544 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-20 18:39:30.937089 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-20 18:39:30.940094 (Thread-1): finished collecting timing info
2020-10-20 18:39:30.941974 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de672434-ed7f-4b3a-9259-475272831d0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11428a640>]}
2020-10-20 18:39:30.942498 (Thread-1): 19:39:30 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.18s]
2020-10-20 18:39:30.942978 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-20 18:39:30.948173 (Thread-2): SQL status: SELECT 374 in 0.05 seconds
2020-10-20 18:39:30.951053 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:39:30.951226 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-20 18:39:30.951314 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-20 18:39:30.954583 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:39:30.959056 (Thread-2): finished collecting timing info
2020-10-20 18:39:30.960445 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de672434-ed7f-4b3a-9259-475272831d0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144de910>]}
2020-10-20 18:39:30.960777 (Thread-2): 19:39:30 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [SELECT 374 in 0.20s]
2020-10-20 18:39:30.961331 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-20 18:39:30.962459 (MainThread): Using postgres connection "master".
2020-10-20 18:39:30.962590 (MainThread): On master: BEGIN
2020-10-20 18:39:30.963815 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-20 18:39:30.964066 (MainThread): On master: COMMIT
2020-10-20 18:39:30.964177 (MainThread): Using postgres connection "master".
2020-10-20 18:39:30.964259 (MainThread): On master: COMMIT
2020-10-20 18:39:30.965733 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-20 18:39:30.966106 (MainThread): 19:39:30 | 
2020-10-20 18:39:30.966238 (MainThread): 19:39:30 | Finished running 1 view model, 1 incremental model in 0.39s.
2020-10-20 18:39:30.966336 (MainThread): Connection 'master' was left open.
2020-10-20 18:39:30.966414 (MainThread): On master: Close
2020-10-20 18:39:30.966563 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-20 18:39:30.966683 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-20 18:39:30.966781 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-20 18:39:30.966901 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-20 18:39:30.973174 (MainThread): 
2020-10-20 18:39:30.973424 (MainThread): Completed successfully
2020-10-20 18:39:30.973569 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-20 18:39:30.973748 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11415be80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11414b0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11414b5b0>]}
2020-10-20 18:39:30.973938 (MainThread): Flushing usage events
2020-10-21 07:38:46.533494 (MainThread): Running with dbt=0.16.1
2020-10-21 07:38:46.647859 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='./ci_profiles', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-21 07:38:46.657198 (MainThread): Tracking: tracking
2020-10-21 07:38:46.687096 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f422fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f034760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f42f880>]}
2020-10-21 07:38:46.707825 (MainThread): Partial parsing not enabled
2020-10-21 07:38:46.710355 (MainThread): Parsing macros/core.sql
2020-10-21 07:38:46.714878 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 07:38:46.723226 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 07:38:46.725343 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 07:38:46.743160 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 07:38:46.778981 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 07:38:46.800889 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 07:38:46.803075 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 07:38:46.809682 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 07:38:46.823287 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 07:38:46.830582 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 07:38:46.837300 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 07:38:46.842546 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 07:38:46.843707 (MainThread): Parsing macros/etc/query.sql
2020-10-21 07:38:46.844996 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 07:38:46.846923 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 07:38:46.849259 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 07:38:46.858883 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 07:38:46.861165 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 07:38:46.862444 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 07:38:46.907172 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 07:38:46.908699 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 07:38:46.909955 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 07:38:46.911256 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 07:38:46.913851 (MainThread): Parsing macros/catalog.sql
2020-10-21 07:38:46.916627 (MainThread): Parsing macros/relations.sql
2020-10-21 07:38:46.918694 (MainThread): Parsing macros/adapters.sql
2020-10-21 07:38:46.937092 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 07:38:46.956707 (MainThread): Partial parsing not enabled
2020-10-21 07:38:46.986227 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:38:46.986369 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:38:47.001420 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:38:47.001547 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:38:47.033506 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:38:47.033661 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:38:47.046653 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:38:47.046845 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:38:47.565016 (MainThread): scipy not found, skipping conversion test.
2020-10-21 07:38:47.568233 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 07:38:47.571460 (MainThread): 
2020-10-21 07:38:47.571827 (MainThread): Acquiring new postgres connection "master".
2020-10-21 07:38:47.571926 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:38:47.580184 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-21 07:38:47.580424 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-21 07:38:47.660367 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-21 07:38:47.660508 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-21 07:38:47.730380 (ThreadPoolExecutor-0_0): Got an error when attempting to open a postgres connection: 'could not translate host name "airflow_postgres" to address: nodename nor servname provided, or not known
'
2020-10-21 07:38:47.730538 (ThreadPoolExecutor-0_0): Error running SQL: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-21 07:38:47.730615 (ThreadPoolExecutor-0_0): Rolling back transaction.
2020-10-21 07:38:47.730707 (ThreadPoolExecutor-0_0): On list_ingestions: No close available on handle
2020-10-21 07:38:47.730817 (ThreadPoolExecutor-0_0): Error running SQL: macro list_schemas
2020-10-21 07:38:47.730885 (ThreadPoolExecutor-0_0): Rolling back transaction.
2020-10-21 07:38:47.731356 (MainThread): Connection 'master' was properly closed.
2020-10-21 07:38:47.731465 (MainThread): Connection 'list_ingestions' was properly closed.
2020-10-21 07:38:47.731565 (MainThread): ERROR: Database Error
  could not translate host name "airflow_postgres" to address: nodename nor servname provided, or not known
  
2020-10-21 07:38:47.731724 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f5ac250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f034760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12122f370>]}
2020-10-21 07:38:47.731905 (MainThread): Flushing usage events
2020-10-21 07:39:00.458137 (MainThread): Running with dbt=0.16.1
2020-10-21 07:39:00.537440 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='./ci_profiles', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-21 07:39:00.538959 (MainThread): Tracking: tracking
2020-10-21 07:39:00.558974 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d676f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d683a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d6837c0>]}
2020-10-21 07:39:00.580600 (MainThread): Partial parsing not enabled
2020-10-21 07:39:00.582795 (MainThread): Parsing macros/core.sql
2020-10-21 07:39:00.587561 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 07:39:00.596363 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 07:39:00.598640 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 07:39:00.621764 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 07:39:00.671034 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 07:39:00.694139 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 07:39:00.696619 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 07:39:00.703392 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 07:39:00.717993 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 07:39:00.725380 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 07:39:00.732534 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 07:39:00.738250 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 07:39:00.739473 (MainThread): Parsing macros/etc/query.sql
2020-10-21 07:39:00.740824 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 07:39:00.742808 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 07:39:00.745054 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 07:39:00.754822 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 07:39:00.757169 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 07:39:00.758617 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 07:39:00.805488 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 07:39:00.807012 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 07:39:00.808252 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 07:39:00.809623 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 07:39:00.812362 (MainThread): Parsing macros/catalog.sql
2020-10-21 07:39:00.815150 (MainThread): Parsing macros/relations.sql
2020-10-21 07:39:00.817294 (MainThread): Parsing macros/adapters.sql
2020-10-21 07:39:00.836097 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 07:39:00.855734 (MainThread): Partial parsing not enabled
2020-10-21 07:39:00.887125 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:39:00.887298 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:00.902750 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:39:00.902903 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:00.935347 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:39:00.935485 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:00.947858 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:39:00.947980 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:01.375527 (MainThread): scipy not found, skipping conversion test.
2020-10-21 07:39:01.377917 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 07:39:01.380797 (MainThread): 
2020-10-21 07:39:01.381131 (MainThread): Acquiring new postgres connection "master".
2020-10-21 07:39:01.381227 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:01.388856 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-21 07:39:01.389068 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-21 07:39:01.472447 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-21 07:39:01.472587 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-21 07:39:01.475400 (ThreadPoolExecutor-0_0): Got an error when attempting to open a postgres connection: 'could not translate host name "airflow_postgres" to address: nodename nor servname provided, or not known
'
2020-10-21 07:39:01.475520 (ThreadPoolExecutor-0_0): Error running SQL: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-21 07:39:01.475595 (ThreadPoolExecutor-0_0): Rolling back transaction.
2020-10-21 07:39:01.475681 (ThreadPoolExecutor-0_0): On list_ingestions: No close available on handle
2020-10-21 07:39:01.475783 (ThreadPoolExecutor-0_0): Error running SQL: macro list_schemas
2020-10-21 07:39:01.475847 (ThreadPoolExecutor-0_0): Rolling back transaction.
2020-10-21 07:39:01.476302 (MainThread): Connection 'master' was properly closed.
2020-10-21 07:39:01.476394 (MainThread): Connection 'list_ingestions' was properly closed.
2020-10-21 07:39:01.476490 (MainThread): ERROR: Database Error
  could not translate host name "airflow_postgres" to address: nodename nor servname provided, or not known
  
2020-10-21 07:39:01.476642 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d7ff190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d683a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f4822b0>]}
2020-10-21 07:39:01.476812 (MainThread): Flushing usage events
2020-10-21 07:39:16.923638 (MainThread): Running with dbt=0.16.1
2020-10-21 07:39:16.999524 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-21 07:39:17.000634 (MainThread): Tracking: tracking
2020-10-21 07:39:17.014344 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d2b8d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d680730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d680fa0>]}
2020-10-21 07:39:17.035329 (MainThread): Partial parsing not enabled
2020-10-21 07:39:17.037435 (MainThread): Parsing macros/core.sql
2020-10-21 07:39:17.043161 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 07:39:17.052523 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 07:39:17.054755 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 07:39:17.073930 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 07:39:17.121544 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 07:39:17.144651 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 07:39:17.146862 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 07:39:17.153628 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 07:39:17.169204 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 07:39:17.176644 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 07:39:17.183681 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 07:39:17.189173 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 07:39:17.190401 (MainThread): Parsing macros/etc/query.sql
2020-10-21 07:39:17.191749 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 07:39:17.193878 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 07:39:17.196188 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 07:39:17.206786 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 07:39:17.209115 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 07:39:17.210508 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 07:39:17.258782 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 07:39:17.260642 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 07:39:17.261816 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 07:39:17.263233 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 07:39:17.265835 (MainThread): Parsing macros/catalog.sql
2020-10-21 07:39:17.268577 (MainThread): Parsing macros/relations.sql
2020-10-21 07:39:17.270821 (MainThread): Parsing macros/adapters.sql
2020-10-21 07:39:17.290794 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 07:39:17.310022 (MainThread): Partial parsing not enabled
2020-10-21 07:39:17.339937 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:39:17.340074 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:17.355121 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:39:17.355243 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:17.387877 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:39:17.388074 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:17.400828 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:39:17.400949 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:17.815186 (MainThread): scipy not found, skipping conversion test.
2020-10-21 07:39:17.817562 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 07:39:17.820338 (MainThread): 
2020-10-21 07:39:17.820650 (MainThread): Acquiring new postgres connection "master".
2020-10-21 07:39:17.820744 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:39:17.837269 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-21 07:39:17.837482 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-21 07:39:17.916620 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:39:17.916764 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-21 07:39:18.002309 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.09 seconds
2020-10-21 07:39:18.002494 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:39:18.002585 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-21 07:39:18.116510 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.11 seconds
2020-10-21 07:39:18.121407 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-21 07:39:18.139428 (MainThread): Using postgres connection "master".
2020-10-21 07:39:18.139565 (MainThread): On master: BEGIN
2020-10-21 07:39:18.159354 (MainThread): SQL status: BEGIN in 0.02 seconds
2020-10-21 07:39:18.159543 (MainThread): Using postgres connection "master".
2020-10-21 07:39:18.159639 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-21 07:39:18.223905 (MainThread): SQL status: SELECT 1 in 0.06 seconds
2020-10-21 07:39:18.225618 (MainThread): On master: ROLLBACK
2020-10-21 07:39:18.227093 (MainThread): 08:39:18 | Concurrency: 4 threads (target='dev')
2020-10-21 07:39:18.227253 (MainThread): 08:39:18 | 
2020-10-21 07:39:18.231634 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:39:18.231795 (Thread-2): Began running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:39:18.231968 (Thread-1): 08:39:18 | 1 of 2 START test not_null_covid19_stats_country..................... [RUN]
2020-10-21 07:39:18.232102 (Thread-2): 08:39:18 | 2 of 2 START test not_null_covid19_stats_incremental_country......... [RUN]
2020-10-21 07:39:18.232463 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:39:18.232572 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-21 07:39:18.232802 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:39:18.232897 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:39:18.232995 (Thread-2): Opening a new connection, currently in state init
2020-10-21 07:39:18.245723 (Thread-2): Compiling test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:39:18.255618 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-21 07:39:18.256604 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_incremental_country"
2020-10-21 07:39:18.257376 (Thread-1): finished collecting timing info
2020-10-21 07:39:18.257657 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:39:18.257748 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-21 07:39:18.257954 (Thread-2): finished collecting timing info
2020-10-21 07:39:18.258309 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:39:18.258411 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: BEGIN
2020-10-21 07:39:18.261611 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:39:18.261787 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:39:18.261875 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "ingestions"."public"."covid19_stats"
where country is null


2020-10-21 07:39:18.276622 (Thread-2): SQL status: BEGIN in 0.02 seconds
2020-10-21 07:39:18.276806 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:39:18.276900 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_incremental_country"} */




select count(*)
from "ingestions"."public"."covid19_stats_incremental"
where country is null


2020-10-21 07:39:18.284069 (Thread-2): SQL status: SELECT 1 in 0.01 seconds
2020-10-21 07:39:18.284416 (Thread-2): finished collecting timing info
2020-10-21 07:39:18.284673 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: ROLLBACK
2020-10-21 07:39:18.286195 (Thread-2): 08:39:18 | 2 of 2 PASS not_null_covid19_stats_incremental_country............... [PASS in 0.05s]
2020-10-21 07:39:18.286362 (Thread-2): Finished running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:39:18.501440 (Thread-1): SQL status: SELECT 1 in 0.24 seconds
2020-10-21 07:39:18.501780 (Thread-1): finished collecting timing info
2020-10-21 07:39:18.502038 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-21 07:39:18.503422 (Thread-1): 08:39:18 | 1 of 2 PASS not_null_covid19_stats_country........................... [PASS in 0.27s]
2020-10-21 07:39:18.503578 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:39:18.504689 (MainThread): 08:39:18 | 
2020-10-21 07:39:18.504814 (MainThread): 08:39:18 | Finished running 2 tests in 0.68s.
2020-10-21 07:39:18.504910 (MainThread): Connection 'master' was left open.
2020-10-21 07:39:18.504985 (MainThread): On master: Close
2020-10-21 07:39:18.505093 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-21 07:39:18.505164 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-21 07:39:18.505256 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was left open.
2020-10-21 07:39:18.505327 (MainThread): On test.my_new_project.not_null_covid19_stats_incremental_country: Close
2020-10-21 07:39:18.511088 (MainThread): 
2020-10-21 07:39:18.511279 (MainThread): Completed successfully
2020-10-21 07:39:18.511468 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-21 07:39:18.511650 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f4e6d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f507fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f854160>]}
2020-10-21 07:39:18.511851 (MainThread): Flushing usage events
2020-10-21 07:41:36.853311 (MainThread): Running with dbt=0.16.1
2020-10-21 07:41:36.933704 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-21 07:41:36.944393 (MainThread): Tracking: tracking
2020-10-21 07:41:36.959832 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a8edc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a9d8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a9d670>]}
2020-10-21 07:41:36.979594 (MainThread): Partial parsing not enabled
2020-10-21 07:41:36.981959 (MainThread): Parsing macros/core.sql
2020-10-21 07:41:36.987463 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 07:41:36.996000 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 07:41:36.998224 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 07:41:37.015933 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 07:41:37.051619 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 07:41:37.073142 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 07:41:37.075322 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 07:41:37.081803 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 07:41:37.095135 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 07:41:37.102315 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 07:41:37.108828 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 07:41:37.114021 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 07:41:37.115306 (MainThread): Parsing macros/etc/query.sql
2020-10-21 07:41:37.116666 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 07:41:37.118523 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 07:41:37.120784 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 07:41:37.130124 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 07:41:37.132293 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 07:41:37.133628 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 07:41:37.176997 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 07:41:37.178568 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 07:41:37.179772 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 07:41:37.181150 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 07:41:37.183796 (MainThread): Parsing macros/catalog.sql
2020-10-21 07:41:37.186516 (MainThread): Parsing macros/relations.sql
2020-10-21 07:41:37.188577 (MainThread): Parsing macros/adapters.sql
2020-10-21 07:41:37.206026 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 07:41:37.225478 (MainThread): Partial parsing not enabled
2020-10-21 07:41:37.253986 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:41:37.254122 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:41:37.268565 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:41:37.268706 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:41:37.300127 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:41:37.300274 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:41:37.312481 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:41:37.312606 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:41:37.738919 (MainThread): scipy not found, skipping conversion test.
2020-10-21 07:41:37.741246 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 07:41:37.743997 (MainThread): 
2020-10-21 07:41:37.744345 (MainThread): Acquiring new postgres connection "master".
2020-10-21 07:41:37.744435 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:41:37.761158 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-21 07:41:37.761392 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-21 07:41:37.846769 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:41:37.846925 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-21 07:41:37.862011 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2020-10-21 07:41:37.862198 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:41:37.862296 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-21 07:41:37.873968 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-21 07:41:37.879462 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-21 07:41:37.898259 (MainThread): Using postgres connection "master".
2020-10-21 07:41:37.898603 (MainThread): On master: BEGIN
2020-10-21 07:41:37.915546 (MainThread): SQL status: BEGIN in 0.02 seconds
2020-10-21 07:41:37.915723 (MainThread): Using postgres connection "master".
2020-10-21 07:41:37.915815 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-21 07:41:37.930384 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-21 07:41:37.932043 (MainThread): On master: ROLLBACK
2020-10-21 07:41:37.933395 (MainThread): 08:41:37 | Concurrency: 4 threads (target='dev')
2020-10-21 07:41:37.933553 (MainThread): 08:41:37 | 
2020-10-21 07:41:37.937717 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:41:37.937857 (Thread-2): Began running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:41:37.938016 (Thread-1): 08:41:37 | 1 of 2 START test not_null_covid19_stats_country..................... [RUN]
2020-10-21 07:41:37.938135 (Thread-2): 08:41:37 | 2 of 2 START test not_null_covid19_stats_incremental_country......... [RUN]
2020-10-21 07:41:37.938528 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:41:37.938685 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-21 07:41:37.939018 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:41:37.939145 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:41:37.939260 (Thread-2): Opening a new connection, currently in state init
2020-10-21 07:41:37.955231 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-21 07:41:37.955348 (Thread-2): Compiling test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:41:37.962838 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_incremental_country"
2020-10-21 07:41:37.963201 (Thread-1): finished collecting timing info
2020-10-21 07:41:37.963482 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:41:37.963584 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-21 07:41:37.963770 (Thread-2): finished collecting timing info
2020-10-21 07:41:37.964085 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:41:37.964175 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: BEGIN
2020-10-21 07:41:37.966749 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:41:37.966942 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:41:37.967044 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "ingestions"."public"."covid19_stats"
where country is null


2020-10-21 07:41:37.975979 (Thread-1): SQL status: SELECT 1 in 0.01 seconds
2020-10-21 07:41:37.976329 (Thread-1): finished collecting timing info
2020-10-21 07:41:37.976591 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-21 07:41:37.978391 (Thread-1): 08:41:37 | 1 of 2 PASS not_null_covid19_stats_country........................... [PASS in 0.04s]
2020-10-21 07:41:37.978575 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:41:37.982530 (Thread-2): SQL status: BEGIN in 0.02 seconds
2020-10-21 07:41:37.982720 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:41:37.982813 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_incremental_country"} */




select count(*)
from "ingestions"."public"."covid19_stats_incremental"
where country is null


2020-10-21 07:41:37.986822 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2020-10-21 07:41:37.987175 (Thread-2): finished collecting timing info
2020-10-21 07:41:37.987429 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: ROLLBACK
2020-10-21 07:41:37.988653 (Thread-2): 08:41:37 | 2 of 2 PASS not_null_covid19_stats_incremental_country............... [PASS in 0.05s]
2020-10-21 07:41:37.988807 (Thread-2): Finished running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:41:37.989925 (MainThread): 08:41:37 | 
2020-10-21 07:41:37.990067 (MainThread): 08:41:37 | Finished running 2 tests in 0.25s.
2020-10-21 07:41:37.990165 (MainThread): Connection 'master' was left open.
2020-10-21 07:41:37.990243 (MainThread): On master: Close
2020-10-21 07:41:37.990354 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-21 07:41:37.990429 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-21 07:41:37.990520 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was left open.
2020-10-21 07:41:37.990591 (MainThread): On test.my_new_project.not_null_covid19_stats_incremental_country: Close
2020-10-21 07:41:37.996602 (MainThread): 
2020-10-21 07:41:37.996791 (MainThread): Completed successfully
2020-10-21 07:41:37.996899 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-21 07:41:37.997068 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a9d8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ad6e040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa1c610>]}
2020-10-21 07:41:37.997301 (MainThread): Flushing usage events
2020-10-21 07:45:29.502622 (MainThread): Running with dbt=0.16.1
2020-10-21 07:45:29.589551 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-21 07:45:29.695539 (MainThread): Tracking: tracking
2020-10-21 07:45:29.714813 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1189e3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118dab760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118dab6a0>]}
2020-10-21 07:45:29.754793 (MainThread): Partial parsing not enabled
2020-10-21 07:45:29.761828 (MainThread): Parsing macros/core.sql
2020-10-21 07:45:29.771650 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 07:45:29.781912 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 07:45:29.784153 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 07:45:29.803055 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 07:45:29.867532 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 07:45:29.890871 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 07:45:29.893211 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 07:45:29.900322 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 07:45:29.914674 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 07:45:29.922429 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 07:45:29.929486 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 07:45:29.935033 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 07:45:29.936289 (MainThread): Parsing macros/etc/query.sql
2020-10-21 07:45:29.937633 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 07:45:29.939825 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 07:45:29.942281 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 07:45:29.953645 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 07:45:29.956811 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 07:45:29.958416 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 07:45:30.052970 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 07:45:30.056351 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 07:45:30.058070 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 07:45:30.060128 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 07:45:30.063570 (MainThread): Parsing macros/catalog.sql
2020-10-21 07:45:30.068310 (MainThread): Parsing macros/relations.sql
2020-10-21 07:45:30.070967 (MainThread): Parsing macros/adapters.sql
2020-10-21 07:45:30.100883 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 07:45:30.120630 (MainThread): Partial parsing not enabled
2020-10-21 07:45:30.150846 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:45:30.151013 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:45:30.166338 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:45:30.166473 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:45:30.199142 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:45:30.199285 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:45:30.211504 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:45:30.211643 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:45:30.641000 (MainThread): scipy not found, skipping conversion test.
2020-10-21 07:45:30.643477 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 07:45:30.646405 (MainThread): 
2020-10-21 07:45:30.646775 (MainThread): Acquiring new postgres connection "master".
2020-10-21 07:45:30.646880 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:45:30.667776 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-21 07:45:30.667995 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-21 07:45:30.747894 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:45:30.748039 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-21 07:45:30.763644 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.02 seconds
2020-10-21 07:45:30.763815 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:45:30.763907 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-21 07:45:30.773951 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-21 07:45:30.778604 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-21 07:45:30.796834 (MainThread): Using postgres connection "master".
2020-10-21 07:45:30.796974 (MainThread): On master: BEGIN
2020-10-21 07:45:30.809566 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-21 07:45:30.809750 (MainThread): Using postgres connection "master".
2020-10-21 07:45:30.809842 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-21 07:45:30.823258 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-21 07:45:30.824909 (MainThread): On master: ROLLBACK
2020-10-21 07:45:30.826203 (MainThread): 08:45:30 | Concurrency: 4 threads (target='dev')
2020-10-21 07:45:30.826349 (MainThread): 08:45:30 | 
2020-10-21 07:45:30.830656 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:45:30.830800 (Thread-2): Began running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:45:30.830955 (Thread-1): 08:45:30 | 1 of 2 START test not_null_covid19_stats_country..................... [RUN]
2020-10-21 07:45:30.831081 (Thread-2): 08:45:30 | 2 of 2 START test not_null_covid19_stats_incremental_country......... [RUN]
2020-10-21 07:45:30.831431 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:45:30.831674 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:45:30.831746 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-21 07:45:30.831842 (Thread-2): Opening a new connection, currently in state init
2020-10-21 07:45:30.831943 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:45:30.832033 (Thread-2): Compiling test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:45:30.854208 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-21 07:45:30.855292 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_incremental_country"
2020-10-21 07:45:30.855669 (Thread-1): finished collecting timing info
2020-10-21 07:45:30.855928 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:45:30.856016 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-21 07:45:30.856156 (Thread-2): finished collecting timing info
2020-10-21 07:45:30.856420 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:45:30.856529 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: BEGIN
2020-10-21 07:45:30.858669 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:45:30.858841 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:45:30.858928 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "ingestions"."public"."covid19_stats"
where country is null


2020-10-21 07:45:30.867122 (Thread-1): SQL status: SELECT 1 in 0.01 seconds
2020-10-21 07:45:30.867483 (Thread-1): finished collecting timing info
2020-10-21 07:45:30.867774 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-21 07:45:30.869970 (Thread-1): 08:45:30 | 1 of 2 PASS not_null_covid19_stats_country........................... [PASS in 0.04s]
2020-10-21 07:45:30.870162 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-21 07:45:30.877822 (Thread-2): SQL status: BEGIN in 0.02 seconds
2020-10-21 07:45:30.877994 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:45:30.878078 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_incremental_country"} */




select count(*)
from "ingestions"."public"."covid19_stats_incremental"
where country is null


2020-10-21 07:45:30.881481 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2020-10-21 07:45:30.881798 (Thread-2): finished collecting timing info
2020-10-21 07:45:30.882049 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: ROLLBACK
2020-10-21 07:45:30.883340 (Thread-2): 08:45:30 | 2 of 2 PASS not_null_covid19_stats_incremental_country............... [PASS in 0.05s]
2020-10-21 07:45:30.883478 (Thread-2): Finished running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-21 07:45:30.884802 (MainThread): 08:45:30 | 
2020-10-21 07:45:30.884946 (MainThread): 08:45:30 | Finished running 2 tests in 0.24s.
2020-10-21 07:45:30.885056 (MainThread): Connection 'master' was left open.
2020-10-21 07:45:30.885211 (MainThread): On master: Close
2020-10-21 07:45:30.885351 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-21 07:45:30.885551 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-21 07:45:30.885849 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was left open.
2020-10-21 07:45:30.885984 (MainThread): On test.my_new_project.not_null_covid19_stats_incremental_country: Close
2020-10-21 07:45:30.902713 (MainThread): 
2020-10-21 07:45:30.902873 (MainThread): Completed successfully
2020-10-21 07:45:30.902979 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-21 07:45:30.903234 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11af6cd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f85370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11af68fd0>]}
2020-10-21 07:45:30.903535 (MainThread): Flushing usage events
2020-10-21 07:54:14.877084 (MainThread): Running with dbt=0.16.1
2020-10-21 07:54:14.955532 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-21 07:54:15.100010 (MainThread): Tracking: tracking
2020-10-21 07:54:15.114635 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e65dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e758b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e75670>]}
2020-10-21 07:54:15.134193 (MainThread): Partial parsing not enabled
2020-10-21 07:54:15.137519 (MainThread): Parsing macros/core.sql
2020-10-21 07:54:15.143517 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 07:54:15.151631 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 07:54:15.153689 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 07:54:15.170726 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 07:54:15.206235 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 07:54:15.227561 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 07:54:15.229733 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 07:54:15.236191 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 07:54:15.250365 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 07:54:15.257874 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 07:54:15.264753 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 07:54:15.269873 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 07:54:15.271110 (MainThread): Parsing macros/etc/query.sql
2020-10-21 07:54:15.272490 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 07:54:15.274439 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 07:54:15.276901 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 07:54:15.286433 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 07:54:15.288695 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 07:54:15.290039 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 07:54:15.334702 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 07:54:15.336497 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 07:54:15.338138 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 07:54:15.340031 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 07:54:15.343014 (MainThread): Parsing macros/catalog.sql
2020-10-21 07:54:15.346716 (MainThread): Parsing macros/relations.sql
2020-10-21 07:54:15.349371 (MainThread): Parsing macros/adapters.sql
2020-10-21 07:54:15.378815 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 07:54:15.408619 (MainThread): Partial parsing not enabled
2020-10-21 07:54:15.449838 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:15.449995 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:54:15.465423 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:15.465549 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:54:15.497397 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:54:15.497540 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:54:15.509697 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:54:15.509828 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:54:15.972569 (MainThread): scipy not found, skipping conversion test.
2020-10-21 07:54:15.975014 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 07:54:15.977794 (MainThread): 
2020-10-21 07:54:15.978112 (MainThread): Acquiring new postgres connection "master".
2020-10-21 07:54:15.978207 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:54:15.987232 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-21 07:54:15.987393 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-21 07:54:16.067442 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-21 07:54:16.067586 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-21 07:54:16.083463 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.02 seconds
2020-10-21 07:54:16.101967 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-21 07:54:16.102125 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-21 07:54:16.104055 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:54:16.104259 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-21 07:54:16.106463 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:54:16.106648 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:54:16.106748 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-21 07:54:16.117148 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-21 07:54:16.120004 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-21 07:54:16.139941 (MainThread): Using postgres connection "master".
2020-10-21 07:54:16.140156 (MainThread): On master: BEGIN
2020-10-21 07:54:16.155318 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-21 07:54:16.155577 (MainThread): Using postgres connection "master".
2020-10-21 07:54:16.155730 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-21 07:54:16.173110 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-21 07:54:16.174793 (MainThread): On master: ROLLBACK
2020-10-21 07:54:16.176060 (MainThread): Using postgres connection "master".
2020-10-21 07:54:16.176270 (MainThread): On master: BEGIN
2020-10-21 07:54:16.179170 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:54:16.179461 (MainThread): On master: COMMIT
2020-10-21 07:54:16.179629 (MainThread): Using postgres connection "master".
2020-10-21 07:54:16.179792 (MainThread): On master: COMMIT
2020-10-21 07:54:16.180930 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:54:16.181403 (MainThread): 08:54:16 | Concurrency: 4 threads (target='dev')
2020-10-21 07:54:16.181552 (MainThread): 08:54:16 | 
2020-10-21 07:54:16.187747 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-21 07:54:16.187950 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-21 07:54:16.188098 (Thread-1): 08:54:16 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-21 07:54:16.188295 (Thread-2): 08:54:16 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-21 07:54:16.188830 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.189162 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.189270 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-21 07:54:16.189360 (Thread-2): Opening a new connection, currently in state init
2020-10-21 07:54:16.189456 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-21 07:54:16.189542 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-21 07:54:16.205239 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-21 07:54:16.212352 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-21 07:54:16.212762 (Thread-1): finished collecting timing info
2020-10-21 07:54:16.229964 (Thread-2): finished collecting timing info
2020-10-21 07:54:16.261093 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.266629 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-21 07:54:16.278715 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-21 07:54:16.287274 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.292916 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-21 07:54:16.297363 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.297542 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201021085416292579"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-21 07:54:16.298864 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-21 07:54:16.300664 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-21 07:54:16.301307 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.301428 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-21 07:54:16.302680 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:54:16.302834 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.302928 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-21 07:54:16.381204 (Thread-1): SQL status: CREATE VIEW in 0.08 seconds
2020-10-21 07:54:16.384856 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.385004 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-21 07:54:16.387509 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-21 07:54:16.390048 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.390199 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-21 07:54:16.392183 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-21 07:54:16.393202 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-21 07:54:16.393320 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.393399 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-21 07:54:16.397088 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:54:16.399100 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:54:16.399242 (Thread-2): SQL status: SELECT 187 in 0.10 seconds
2020-10-21 07:54:16.399380 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-21 07:54:16.402887 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.403135 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-21 07:54:16.406186 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:54:16.406362 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.406452 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201021085416292579'
        
      order by ordinal_position

  
2020-10-21 07:54:16.421027 (Thread-1): SQL status: DROP VIEW in 0.02 seconds
2020-10-21 07:54:16.423668 (Thread-1): finished collecting timing info
2020-10-21 07:54:16.424421 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b092488-8fcf-4bbf-a5a9-73ce710f21ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114debdc0>]}
2020-10-21 07:54:16.424708 (Thread-1): 08:54:16 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.24s]
2020-10-21 07:54:16.424865 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-21 07:54:16.543319 (Thread-2): SQL status: SELECT 6 in 0.14 seconds
2020-10-21 07:54:16.546984 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.547099 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-21 07:54:16.551005 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-21 07:54:16.557918 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.558041 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-21 07:54:16.561943 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-21 07:54:16.563038 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-21 07:54:16.563591 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.563689 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201021085416292579"
    );
  
2020-10-21 07:54:16.568859 (Thread-2): SQL status: INSERT 0 187 in 0.01 seconds
2020-10-21 07:54:16.569812 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-21 07:54:16.569911 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:54:16.569986 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-21 07:54:16.572855 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:54:16.574447 (Thread-2): finished collecting timing info
2020-10-21 07:54:16.575103 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b092488-8fcf-4bbf-a5a9-73ce710f21ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115043970>]}
2020-10-21 07:54:16.575367 (Thread-2): 08:54:16 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 187 in 0.39s]
2020-10-21 07:54:16.575499 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-21 07:54:16.576774 (MainThread): Using postgres connection "master".
2020-10-21 07:54:16.576916 (MainThread): On master: BEGIN
2020-10-21 07:54:16.578072 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:54:16.578249 (MainThread): On master: COMMIT
2020-10-21 07:54:16.578340 (MainThread): Using postgres connection "master".
2020-10-21 07:54:16.578416 (MainThread): On master: COMMIT
2020-10-21 07:54:16.579717 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:54:16.580107 (MainThread): 08:54:16 | 
2020-10-21 07:54:16.580238 (MainThread): 08:54:16 | Finished running 1 view model, 1 incremental model in 0.60s.
2020-10-21 07:54:16.580339 (MainThread): Connection 'master' was left open.
2020-10-21 07:54:16.580417 (MainThread): On master: Close
2020-10-21 07:54:16.580527 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-21 07:54:16.580599 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-21 07:54:16.580703 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-21 07:54:16.580774 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-21 07:54:16.587004 (MainThread): 
2020-10-21 07:54:16.587545 (MainThread): Completed successfully
2020-10-21 07:54:16.587791 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-21 07:54:16.587999 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114cb6df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ccda30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ccd1f0>]}
2020-10-21 07:54:16.588206 (MainThread): Flushing usage events
2020-10-21 07:57:50.361056 (MainThread): Running with dbt=0.16.1
2020-10-21 07:57:50.438235 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-21 07:57:50.440515 (MainThread): Tracking: tracking
2020-10-21 07:57:50.456722 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bbba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fbbfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fbbc40>]}
2020-10-21 07:57:50.477273 (MainThread): Partial parsing not enabled
2020-10-21 07:57:50.479461 (MainThread): Parsing macros/core.sql
2020-10-21 07:57:50.485405 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 07:57:50.496099 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 07:57:50.498534 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 07:57:50.518411 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 07:57:50.556121 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 07:57:50.579801 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 07:57:50.582295 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 07:57:50.589414 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 07:57:50.604226 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 07:57:50.612312 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 07:57:50.620114 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 07:57:50.626224 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 07:57:50.627980 (MainThread): Parsing macros/etc/query.sql
2020-10-21 07:57:50.629750 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 07:57:50.632031 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 07:57:50.634444 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 07:57:50.644203 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 07:57:50.646555 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 07:57:50.647942 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 07:57:50.692822 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 07:57:50.694356 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 07:57:50.695604 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 07:57:50.697071 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 07:57:50.699708 (MainThread): Parsing macros/catalog.sql
2020-10-21 07:57:50.702960 (MainThread): Parsing macros/relations.sql
2020-10-21 07:57:50.705045 (MainThread): Parsing macros/adapters.sql
2020-10-21 07:57:50.723288 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 07:57:50.742595 (MainThread): Partial parsing not enabled
2020-10-21 07:57:50.772984 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:50.773119 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:57:50.788132 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:50.788256 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:57:50.820081 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 07:57:50.820214 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:57:50.832311 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 07:57:50.832432 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:57:51.249106 (MainThread): scipy not found, skipping conversion test.
2020-10-21 07:57:51.251500 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 07:57:51.253637 (MainThread): 
2020-10-21 07:57:51.253929 (MainThread): Acquiring new postgres connection "master".
2020-10-21 07:57:51.254024 (MainThread): Opening a new connection, currently in state init
2020-10-21 07:57:51.262977 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-21 07:57:51.263199 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-21 07:57:51.343063 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-21 07:57:51.343205 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-21 07:57:51.360846 (ThreadPoolExecutor-0_0): SQL status: SELECT 14 in 0.02 seconds
2020-10-21 07:57:51.377355 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-21 07:57:51.377536 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-21 07:57:51.379001 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:57:51.379095 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-21 07:57:51.380827 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:57:51.380990 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 07:57:51.381080 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-21 07:57:51.391112 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-21 07:57:51.393932 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-21 07:57:51.411730 (MainThread): Using postgres connection "master".
2020-10-21 07:57:51.411875 (MainThread): On master: BEGIN
2020-10-21 07:57:51.425318 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-21 07:57:51.425507 (MainThread): Using postgres connection "master".
2020-10-21 07:57:51.425598 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-21 07:57:51.443231 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-21 07:57:51.444918 (MainThread): On master: ROLLBACK
2020-10-21 07:57:51.446104 (MainThread): Using postgres connection "master".
2020-10-21 07:57:51.446216 (MainThread): On master: BEGIN
2020-10-21 07:57:51.448305 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:57:51.448471 (MainThread): On master: COMMIT
2020-10-21 07:57:51.448576 (MainThread): Using postgres connection "master".
2020-10-21 07:57:51.448656 (MainThread): On master: COMMIT
2020-10-21 07:57:51.449797 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:57:51.450098 (MainThread): 08:57:51 | Concurrency: 4 threads (target='dev')
2020-10-21 07:57:51.450219 (MainThread): 08:57:51 | 
2020-10-21 07:57:51.454512 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-21 07:57:51.454650 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-21 07:57:51.454810 (Thread-1): 08:57:51 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-21 07:57:51.454936 (Thread-2): 08:57:51 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-21 07:57:51.455240 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.455502 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.455579 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-21 07:57:51.455693 (Thread-2): Opening a new connection, currently in state init
2020-10-21 07:57:51.455804 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-21 07:57:51.455898 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-21 07:57:51.475567 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-21 07:57:51.477117 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-21 07:57:51.477543 (Thread-1): finished collecting timing info
2020-10-21 07:57:51.489027 (Thread-2): finished collecting timing info
2020-10-21 07:57:51.531058 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.536387 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-21 07:57:51.546430 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-21 07:57:51.554764 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.560016 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-21 07:57:51.565594 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.565842 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

    

  create temporary table "covid19_stats_incremental__dbt_tmp20201021085751561122"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




  where day >= (select max(day) from "ingestions"."public"."covid19_stats_incremental")



GROUP BY country, day
  );
  
2020-10-21 07:57:51.567596 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-21 07:57:51.569446 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-21 07:57:51.569958 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.570082 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-21 07:57:51.572110 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:57:51.572303 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.572403 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-21 07:57:51.595657 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2020-10-21 07:57:51.601007 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.601172 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-21 07:57:51.603685 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-21 07:57:51.606473 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.606638 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-21 07:57:51.609356 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-21 07:57:51.610468 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-21 07:57:51.610613 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.610701 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-21 07:57:51.614566 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:57:51.616699 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 07:57:51.616869 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-21 07:57:51.622462 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-21 07:57:51.624983 (Thread-1): finished collecting timing info
2020-10-21 07:57:51.625686 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5f79af2-5314-4fec-8a96-05f37e3e1741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ef016d0>]}
2020-10-21 07:57:51.625953 (Thread-1): 08:57:51 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.17s]
2020-10-21 07:57:51.626084 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-21 07:57:51.634171 (Thread-2): SQL status: SELECT 187 in 0.07 seconds
2020-10-21 07:57:51.638527 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.638691 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-21 07:57:51.643916 (Thread-2): SQL status: BEGIN in 0.01 seconds
2020-10-21 07:57:51.644120 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.644239 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental__dbt_tmp20201021085751561122'
        
      order by ordinal_position

  
2020-10-21 07:57:51.680707 (Thread-2): SQL status: SELECT 6 in 0.04 seconds
2020-10-21 07:57:51.684424 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.684533 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-21 07:57:51.690193 (Thread-2): SQL status: SELECT 6 in 0.01 seconds
2020-10-21 07:57:51.696944 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.697066 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "ingestions".INFORMATION_SCHEMA.columns
      where table_name = 'covid19_stats_incremental'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
2020-10-21 07:57:51.700814 (Thread-2): SQL status: SELECT 6 in 0.00 seconds
2020-10-21 07:57:51.701881 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-21 07:57:51.702276 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.702366 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      

    insert into "ingestions"."public"."covid19_stats_incremental" ("country", "day", "confirmed", "deaths", "recovered", "active")
    (
       select "country", "day", "confirmed", "deaths", "recovered", "active"
       from "covid19_stats_incremental__dbt_tmp20201021085751561122"
    );
  
2020-10-21 07:57:51.708230 (Thread-2): SQL status: INSERT 0 187 in 0.01 seconds
2020-10-21 07:57:51.709193 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-21 07:57:51.709295 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 07:57:51.709371 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-21 07:57:51.712073 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:57:51.714052 (Thread-2): finished collecting timing info
2020-10-21 07:57:51.714663 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5f79af2-5314-4fec-8a96-05f37e3e1741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ef1d550>]}
2020-10-21 07:57:51.714883 (Thread-2): 08:57:51 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [INSERT 0 187 in 0.26s]
2020-10-21 07:57:51.715000 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-21 07:57:51.716052 (MainThread): Using postgres connection "master".
2020-10-21 07:57:51.716175 (MainThread): On master: BEGIN
2020-10-21 07:57:51.717594 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-21 07:57:51.717748 (MainThread): On master: COMMIT
2020-10-21 07:57:51.717835 (MainThread): Using postgres connection "master".
2020-10-21 07:57:51.717910 (MainThread): On master: COMMIT
2020-10-21 07:57:51.718902 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-21 07:57:51.719214 (MainThread): 08:57:51 | 
2020-10-21 07:57:51.719331 (MainThread): 08:57:51 | Finished running 1 view model, 1 incremental model in 0.47s.
2020-10-21 07:57:51.719425 (MainThread): Connection 'master' was left open.
2020-10-21 07:57:51.719500 (MainThread): On master: Close
2020-10-21 07:57:51.719602 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-21 07:57:51.719673 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-21 07:57:51.719762 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-21 07:57:51.719831 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-21 07:57:51.725372 (MainThread): 
2020-10-21 07:57:51.725552 (MainThread): Completed successfully
2020-10-21 07:57:51.725667 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-21 07:57:51.725871 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ecab070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ec8c190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ec8c0d0>]}
2020-10-21 07:57:51.726087 (MainThread): Flushing usage events
2020-10-21 08:01:35.607662 (MainThread): Running with dbt=0.16.1
2020-10-21 08:01:35.686827 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['covid19_stats'], partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-21 08:01:35.698716 (MainThread): Tracking: tracking
2020-10-21 08:01:35.713995 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113016a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133eafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133dc670>]}
2020-10-21 08:01:35.733423 (MainThread): Partial parsing not enabled
2020-10-21 08:01:35.735822 (MainThread): Parsing macros/core.sql
2020-10-21 08:01:35.741632 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 08:01:35.750382 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 08:01:35.752562 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 08:01:35.770186 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 08:01:35.805104 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 08:01:35.828557 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 08:01:35.830940 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 08:01:35.838118 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 08:01:35.856180 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 08:01:35.865329 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 08:01:35.872471 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 08:01:35.877919 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 08:01:35.879158 (MainThread): Parsing macros/etc/query.sql
2020-10-21 08:01:35.880569 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 08:01:35.882567 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-21 08:01:35.885105 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 08:01:35.895210 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 08:01:35.897566 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 08:01:35.899011 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 08:01:35.944110 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 08:01:35.945531 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 08:01:35.946672 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 08:01:35.948098 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 08:01:35.950730 (MainThread): Parsing macros/catalog.sql
2020-10-21 08:01:35.953517 (MainThread): Parsing macros/relations.sql
2020-10-21 08:01:35.955581 (MainThread): Parsing macros/adapters.sql
2020-10-21 08:01:35.974239 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-21 08:01:35.995112 (MainThread): Partial parsing not enabled
2020-10-21 08:01:36.026645 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.026791 (MainThread): Opening a new connection, currently in state init
2020-10-21 08:01:36.041585 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-21 08:01:36.041715 (MainThread): Opening a new connection, currently in state init
2020-10-21 08:01:36.072710 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-21 08:01:36.072849 (MainThread): Opening a new connection, currently in state init
2020-10-21 08:01:36.085308 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-21 08:01:36.085464 (MainThread): Opening a new connection, currently in state init
2020-10-21 08:01:36.564419 (MainThread): scipy not found, skipping conversion test.
2020-10-21 08:01:36.566901 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2020-10-21 08:01:36.569837 (MainThread): 
2020-10-21 08:01:36.570179 (MainThread): Acquiring new postgres connection "master".
2020-10-21 08:01:36.570277 (MainThread): Opening a new connection, currently in state init
2020-10-21 08:01:36.575522 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_ingestions".
2020-10-21 08:01:36.575731 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-21 08:01:36.657001 (ThreadPoolExecutor-0_0): Using postgres connection "list_ingestions".
2020-10-21 08:01:36.657144 (ThreadPoolExecutor-0_0): On list_ingestions: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions"} */

    select distinct nspname from pg_namespace
  
2020-10-21 08:01:36.674364 (ThreadPoolExecutor-0_0): SQL status: SELECT 16 in 0.02 seconds
2020-10-21 08:01:36.690822 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_ingestions_public".
2020-10-21 08:01:36.691004 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_ingestions).
2020-10-21 08:01:36.692439 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 08:01:36.692538 (ThreadPoolExecutor-1_0): On list_ingestions_public: BEGIN
2020-10-21 08:01:36.694164 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2020-10-21 08:01:36.694323 (ThreadPoolExecutor-1_0): Using postgres connection "list_ingestions_public".
2020-10-21 08:01:36.694405 (ThreadPoolExecutor-1_0): On list_ingestions_public: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "list_ingestions_public"} */
select
      'ingestions' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ingestions' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-21 08:01:36.702822 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2020-10-21 08:01:36.705586 (ThreadPoolExecutor-1_0): On list_ingestions_public: ROLLBACK
2020-10-21 08:01:36.723592 (MainThread): Using postgres connection "master".
2020-10-21 08:01:36.723724 (MainThread): On master: BEGIN
2020-10-21 08:01:36.735981 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-21 08:01:36.736160 (MainThread): Using postgres connection "master".
2020-10-21 08:01:36.736253 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-21 08:01:36.752386 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2020-10-21 08:01:36.754182 (MainThread): On master: ROLLBACK
2020-10-21 08:01:36.755625 (MainThread): Using postgres connection "master".
2020-10-21 08:01:36.755778 (MainThread): On master: BEGIN
2020-10-21 08:01:36.757897 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-21 08:01:36.758070 (MainThread): On master: COMMIT
2020-10-21 08:01:36.758169 (MainThread): Using postgres connection "master".
2020-10-21 08:01:36.758250 (MainThread): On master: COMMIT
2020-10-21 08:01:36.759149 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-21 08:01:36.759468 (MainThread): 09:01:36 | Concurrency: 4 threads (target='dev')
2020-10-21 08:01:36.759592 (MainThread): 09:01:36 | 
2020-10-21 08:01:36.763516 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-21 08:01:36.763703 (Thread-1): 09:01:36 | 1 of 1 START view model public.covid19_stats......................... [RUN]
2020-10-21 08:01:36.763977 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.764062 (Thread-1): Re-using an available connection from the pool (formerly list_ingestions_public).
2020-10-21 08:01:36.764144 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-21 08:01:36.778786 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-21 08:01:36.779438 (Thread-1): finished collecting timing info
2020-10-21 08:01:36.808942 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.809091 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_tmp" cascade
2020-10-21 08:01:36.811027 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-21 08:01:36.813309 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.813423 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-21 08:01:36.814551 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-21 08:01:36.816054 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-21 08:01:36.816632 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.816732 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-21 08:01:36.817843 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-21 08:01:36.817984 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.818074 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */

  create view "ingestions"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-21 08:01:36.825947 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-21 08:01:36.829915 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.830068 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-21 08:01:36.831433 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-21 08:01:36.833955 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.834104 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "ingestions"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-21 08:01:36.836341 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-21 08:01:36.837355 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-21 08:01:36.837470 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.837551 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-21 08:01:36.840851 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-21 08:01:36.843478 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-21 08:01:36.843600 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "ingestions"."public"."covid19_stats__dbt_backup" cascade
2020-10-21 08:01:36.847095 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-21 08:01:36.849378 (Thread-1): finished collecting timing info
2020-10-21 08:01:36.849959 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '324a6563-3a9f-4916-93cd-c0ae45ae3038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1176b65b0>]}
2020-10-21 08:01:36.850182 (Thread-1): 09:01:36 | 1 of 1 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.09s]
2020-10-21 08:01:36.850298 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-21 08:01:36.851239 (MainThread): Using postgres connection "master".
2020-10-21 08:01:36.851346 (MainThread): On master: BEGIN
2020-10-21 08:01:36.852515 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-21 08:01:36.852653 (MainThread): On master: COMMIT
2020-10-21 08:01:36.852740 (MainThread): Using postgres connection "master".
2020-10-21 08:01:36.852817 (MainThread): On master: COMMIT
2020-10-21 08:01:36.853846 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-21 08:01:36.854263 (MainThread): 09:01:36 | 
2020-10-21 08:01:36.854486 (MainThread): 09:01:36 | Finished running 1 view model in 0.28s.
2020-10-21 08:01:36.854592 (MainThread): Connection 'master' was left open.
2020-10-21 08:01:36.854671 (MainThread): On master: Close
2020-10-21 08:01:36.854782 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-21 08:01:36.854856 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-21 08:01:36.858119 (MainThread): 
2020-10-21 08:01:36.858314 (MainThread): Completed successfully
2020-10-21 08:01:36.858613 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-21 08:01:36.858841 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117386430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11735f670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11735f5e0>]}
2020-10-21 08:01:36.859089 (MainThread): Flushing usage events
2020-10-24 19:06:42,718213 (MainThread): Running with dbt=0.15.0
2020-10-24 19:06:44,2311 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 19:06:44,21340 (MainThread): Tracking: tracking
2020-10-24 19:06:44,78474 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d02b32e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d02b329d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d02b328d0>]}
2020-10-24 19:06:45,511259 (MainThread): Partial parsing not enabled
2020-10-24 19:06:45,529920 (MainThread): Parsing macros/core.sql
2020-10-24 19:06:45,538484 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 19:06:45,553962 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 19:06:45,558950 (MainThread): Parsing macros/etc/query.sql
2020-10-24 19:06:45,562480 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 19:06:45,566562 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 19:06:45,575300 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 19:06:45,581321 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 19:06:45,584976 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 19:06:45,588647 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 19:06:45,594761 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 19:06:45,600135 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 19:06:45,650861 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 19:06:45,661563 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 19:06:45,674145 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 19:06:45,681928 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 19:06:45,686782 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 19:06:45,715138 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 19:06:45,793002 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 19:06:45,843985 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 19:06:45,864047 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 19:06:45,884686 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 19:06:45,905651 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 19:06:45,923124 (MainThread): Parsing macros/relations.sql
2020-10-24 19:06:45,928744 (MainThread): Parsing macros/catalog.sql
2020-10-24 19:06:45,934293 (MainThread): Parsing macros/adapters.sql
2020-10-24 19:06:45,958750 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 19:06:46,14303 (MainThread): Partial parsing not enabled
2020-10-24 19:06:46,69889 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 19:06:46,71634 (MainThread): Opening a new connection, currently in state init
2020-10-24 19:06:46,74305 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 19:06:46,79870 (MainThread): On None: No close available on handle
2020-10-24 19:06:46,83759 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 19:06:46,85694 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d02b03590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d02a9cd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d02ac87d0>]}
2020-10-24 19:06:46,615272 (MainThread): Flushing usage events
2020-10-24 19:06:46,622308 (MainThread): Connection 'None' was properly closed.
2020-10-24 20:08:16,789278 (MainThread): Running with dbt=0.15.0
2020-10-24 20:08:17,340126 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 20:08:17,344571 (MainThread): Tracking: tracking
2020-10-24 20:08:17,364972 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65aa622c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65aa668050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65af1b6e90>]}
2020-10-24 20:08:18,180455 (MainThread): Partial parsing not enabled
2020-10-24 20:08:18,231856 (MainThread): Parsing macros/core.sql
2020-10-24 20:08:18,299519 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 20:08:18,315184 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 20:08:18,320553 (MainThread): Parsing macros/etc/query.sql
2020-10-24 20:08:18,338211 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 20:08:18,341820 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 20:08:18,347625 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 20:08:18,353432 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 20:08:18,362512 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 20:08:18,365797 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 20:08:18,368906 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 20:08:18,373504 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 20:08:18,475671 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 20:08:18,487160 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 20:08:18,506272 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 20:08:18,521265 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 20:08:18,537688 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 20:08:18,556754 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 20:08:18,592703 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 20:08:18,625309 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 20:08:18,637491 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 20:08:18,646957 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 20:08:18,657800 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 20:08:18,716626 (MainThread): Parsing macros/relations.sql
2020-10-24 20:08:18,741652 (MainThread): Parsing macros/catalog.sql
2020-10-24 20:08:18,745204 (MainThread): Parsing macros/adapters.sql
2020-10-24 20:08:18,763013 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 20:08:18,816794 (MainThread): Partial parsing not enabled
2020-10-24 20:08:18,851825 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 20:08:18,855317 (MainThread): Opening a new connection, currently in state init
2020-10-24 20:08:18,857303 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 20:08:18,859262 (MainThread): On None: No close available on handle
2020-10-24 20:08:18,863332 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 20:08:18,864767 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65bc151b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65aa5f7d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65aa5b5890>]}
2020-10-24 20:08:19,370491 (MainThread): Flushing usage events
2020-10-24 20:08:19,372249 (MainThread): Connection 'None' was properly closed.
2020-10-24 20:18:53,850443 (MainThread): Running with dbt=0.15.0
2020-10-24 20:18:54,7183 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 20:18:54,11994 (MainThread): Tracking: tracking
2020-10-24 20:18:54,18778 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa71bb18850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa71e2a4890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa71bb5ab90>]}
2020-10-24 20:18:54,771160 (MainThread): Partial parsing not enabled
2020-10-24 20:18:54,774582 (MainThread): Parsing macros/core.sql
2020-10-24 20:18:54,780240 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 20:18:54,790017 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 20:18:54,793424 (MainThread): Parsing macros/etc/query.sql
2020-10-24 20:18:54,795771 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 20:18:54,798179 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 20:18:54,801379 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 20:18:54,804762 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 20:18:54,806974 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 20:18:54,809247 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 20:18:54,811533 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 20:18:54,814543 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 20:18:54,842732 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 20:18:54,850918 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 20:18:54,858594 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 20:18:54,861705 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 20:18:54,864474 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 20:18:54,876761 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 20:18:54,896904 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 20:18:54,915949 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 20:18:54,922447 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 20:18:54,929688 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 20:18:54,937982 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 20:18:54,946279 (MainThread): Parsing macros/relations.sql
2020-10-24 20:18:54,949265 (MainThread): Parsing macros/catalog.sql
2020-10-24 20:18:54,952158 (MainThread): Parsing macros/adapters.sql
2020-10-24 20:18:54,963164 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 20:18:54,988735 (MainThread): Partial parsing not enabled
2020-10-24 20:18:55,18368 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 20:18:55,19557 (MainThread): Opening a new connection, currently in state init
2020-10-24 20:18:55,21091 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 20:18:55,22358 (MainThread): On None: No close available on handle
2020-10-24 20:18:55,23643 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 20:18:55,24749 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa71baa6b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa71baa6ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa71bb3c6d0>]}
2020-10-24 20:18:55,531419 (MainThread): Flushing usage events
2020-10-24 20:18:55,533464 (MainThread): Connection 'None' was properly closed.
2020-10-24 20:23:09,194841 (MainThread): Running with dbt=0.15.0
2020-10-24 20:23:09,453238 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 20:23:09,458729 (MainThread): Tracking: tracking
2020-10-24 20:23:09,467941 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ae9c06a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aea0cb150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ae9b74290>]}
2020-10-24 20:23:10,154267 (MainThread): Partial parsing not enabled
2020-10-24 20:23:10,158861 (MainThread): Parsing macros/core.sql
2020-10-24 20:23:10,167068 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 20:23:10,180600 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 20:23:10,185258 (MainThread): Parsing macros/etc/query.sql
2020-10-24 20:23:10,188679 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 20:23:10,191964 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 20:23:10,196947 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 20:23:10,201448 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 20:23:10,207301 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 20:23:10,211072 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 20:23:10,214525 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 20:23:10,218952 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 20:23:10,249975 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 20:23:10,261193 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 20:23:10,268867 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 20:23:10,271927 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 20:23:10,274831 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 20:23:10,288078 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 20:23:10,308605 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 20:23:10,328193 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 20:23:10,334879 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 20:23:10,342548 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 20:23:10,351469 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 20:23:10,359694 (MainThread): Parsing macros/relations.sql
2020-10-24 20:23:10,362518 (MainThread): Parsing macros/catalog.sql
2020-10-24 20:23:10,365414 (MainThread): Parsing macros/adapters.sql
2020-10-24 20:23:10,376580 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 20:23:10,403251 (MainThread): Partial parsing not enabled
2020-10-24 20:23:10,429697 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 20:23:10,430918 (MainThread): Opening a new connection, currently in state init
2020-10-24 20:23:10,432239 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 20:23:10,433161 (MainThread): On None: No close available on handle
2020-10-24 20:23:10,434358 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 20:23:10,435555 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ae9bfce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ae9bd2150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ae9bef190>]}
2020-10-24 20:23:10,943124 (MainThread): Flushing usage events
2020-10-24 20:23:10,944876 (MainThread): Connection 'None' was properly closed.
2020-10-24 20:31:10,894494 (MainThread): Running with dbt=0.15.0
2020-10-24 20:31:11,38930 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 20:31:11,43064 (MainThread): Tracking: tracking
2020-10-24 20:31:11,49433 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7b7d7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7b820090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7b7d7950>]}
2020-10-24 20:31:11,690223 (MainThread): Partial parsing not enabled
2020-10-24 20:31:11,693922 (MainThread): Parsing macros/core.sql
2020-10-24 20:31:11,699880 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 20:31:11,710099 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 20:31:11,713221 (MainThread): Parsing macros/etc/query.sql
2020-10-24 20:31:11,715751 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 20:31:11,717986 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 20:31:11,721299 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 20:31:11,724580 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 20:31:11,726532 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 20:31:11,728774 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 20:31:11,730868 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 20:31:11,733945 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 20:31:11,762633 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 20:31:11,772092 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 20:31:11,780390 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 20:31:11,784144 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 20:31:11,787479 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 20:31:11,800160 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 20:31:11,820571 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 20:31:11,841132 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 20:31:11,847831 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 20:31:11,855236 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 20:31:11,864364 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 20:31:11,872430 (MainThread): Parsing macros/relations.sql
2020-10-24 20:31:11,875083 (MainThread): Parsing macros/catalog.sql
2020-10-24 20:31:11,878072 (MainThread): Parsing macros/adapters.sql
2020-10-24 20:31:11,888724 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 20:31:11,915163 (MainThread): Partial parsing not enabled
2020-10-24 20:31:11,941167 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 20:31:11,942510 (MainThread): Opening a new connection, currently in state init
2020-10-24 20:31:11,944114 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 20:31:11,945341 (MainThread): On None: No close available on handle
2020-10-24 20:31:11,946736 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 20:31:11,948064 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7b7c6510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7b75b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7b75b710>]}
2020-10-24 20:31:12,455564 (MainThread): Flushing usage events
2020-10-24 20:31:12,457708 (MainThread): Connection 'None' was properly closed.
2020-10-24 20:54:41,528799 (MainThread): Running with dbt=0.15.0
2020-10-24 20:54:41,680450 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 20:54:41,753162 (MainThread): Tracking: tracking
2020-10-24 20:54:41,759304 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3fbc3ec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3fbc7ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3fbc7fa50>]}
2020-10-24 20:54:42,385046 (MainThread): Partial parsing not enabled
2020-10-24 20:54:42,388540 (MainThread): Parsing macros/core.sql
2020-10-24 20:54:42,394572 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 20:54:42,404205 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 20:54:42,408336 (MainThread): Parsing macros/etc/query.sql
2020-10-24 20:54:42,411032 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 20:54:42,413110 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 20:54:42,416278 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 20:54:42,419393 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 20:54:42,421507 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 20:54:42,423807 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 20:54:42,425893 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 20:54:42,429048 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 20:54:42,457351 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 20:54:42,465262 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 20:54:42,473404 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 20:54:42,476529 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 20:54:42,479185 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 20:54:42,491872 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 20:54:42,512110 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 20:54:42,531318 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 20:54:42,537693 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 20:54:42,545095 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 20:54:42,553445 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 20:54:42,561131 (MainThread): Parsing macros/relations.sql
2020-10-24 20:54:42,563621 (MainThread): Parsing macros/catalog.sql
2020-10-24 20:54:42,566392 (MainThread): Parsing macros/adapters.sql
2020-10-24 20:54:42,577046 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 20:54:42,602545 (MainThread): Partial parsing not enabled
2020-10-24 20:54:42,628227 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 20:54:42,629581 (MainThread): Opening a new connection, currently in state init
2020-10-24 20:54:42,631224 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 20:54:42,632404 (MainThread): On None: No close available on handle
2020-10-24 20:54:42,633678 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 20:54:42,635217 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3fbc3ead0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3fbbb0c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3fbc13f50>]}
2020-10-24 20:54:44,146929 (MainThread): Flushing usage events
2020-10-24 20:54:44,149087 (MainThread): Connection 'None' was properly closed.
2020-10-24 20:59:29,547362 (MainThread): Running with dbt=0.15.0
2020-10-24 20:59:29,694142 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 20:59:29,699786 (MainThread): Tracking: tracking
2020-10-24 20:59:29,706305 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0a3b2eedd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0a3b345110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0a3b2ee9d0>]}
2020-10-24 20:59:30,316204 (MainThread): Partial parsing not enabled
2020-10-24 20:59:30,319494 (MainThread): Parsing macros/core.sql
2020-10-24 20:59:30,325362 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 20:59:30,335408 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 20:59:30,338649 (MainThread): Parsing macros/etc/query.sql
2020-10-24 20:59:30,340869 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 20:59:30,343336 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 20:59:30,346669 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 20:59:30,349728 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 20:59:30,351915 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 20:59:30,354110 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 20:59:30,356335 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 20:59:30,359270 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 20:59:30,387554 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 20:59:30,395708 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 20:59:30,403460 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 20:59:30,406451 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 20:59:30,408993 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 20:59:30,421433 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 20:59:30,441717 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 20:59:30,460619 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 20:59:30,467297 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 20:59:30,474681 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 20:59:30,483138 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 20:59:30,490630 (MainThread): Parsing macros/relations.sql
2020-10-24 20:59:30,493169 (MainThread): Parsing macros/catalog.sql
2020-10-24 20:59:30,496067 (MainThread): Parsing macros/adapters.sql
2020-10-24 20:59:30,506823 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 20:59:30,532342 (MainThread): Partial parsing not enabled
2020-10-24 20:59:30,557467 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 20:59:30,558596 (MainThread): Opening a new connection, currently in state init
2020-10-24 20:59:30,560048 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 20:59:30,560981 (MainThread): On None: No close available on handle
2020-10-24 20:59:30,562012 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 20:59:30,563071 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0a3b2693d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0a3b277310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0a3b277350>]}
2020-10-24 20:59:31,63716 (MainThread): Flushing usage events
2020-10-24 20:59:31,65336 (MainThread): Connection 'None' was properly closed.
2020-10-24 21:06:47,468550 (MainThread): Running with dbt=0.15.0
2020-10-24 21:06:47,625773 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 21:06:47,647644 (MainThread): Tracking: tracking
2020-10-24 21:06:47,654682 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9e3f0e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9e431d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9e3df610>]}
2020-10-24 21:06:48,289958 (MainThread): Partial parsing not enabled
2020-10-24 21:06:48,293986 (MainThread): Parsing macros/core.sql
2020-10-24 21:06:48,303939 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 21:06:48,317560 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 21:06:48,322465 (MainThread): Parsing macros/etc/query.sql
2020-10-24 21:06:48,326065 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 21:06:48,329181 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 21:06:48,334437 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 21:06:48,339415 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 21:06:48,342840 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 21:06:48,346315 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 21:06:48,349571 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 21:06:48,354852 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 21:06:48,385821 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 21:06:48,394952 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 21:06:48,402991 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 21:06:48,406364 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 21:06:48,409373 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 21:06:48,422651 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 21:06:48,444254 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 21:06:48,464777 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 21:06:48,477235 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 21:06:48,485074 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 21:06:48,497544 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 21:06:48,505467 (MainThread): Parsing macros/relations.sql
2020-10-24 21:06:48,508128 (MainThread): Parsing macros/catalog.sql
2020-10-24 21:06:48,510858 (MainThread): Parsing macros/adapters.sql
2020-10-24 21:06:48,521624 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 21:06:48,546659 (MainThread): Partial parsing not enabled
2020-10-24 21:06:48,570285 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 21:06:48,571350 (MainThread): Opening a new connection, currently in state init
2020-10-24 21:06:48,572634 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 21:06:48,573759 (MainThread): On None: No close available on handle
2020-10-24 21:06:48,574836 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 21:06:48,576091 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9e363b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9e37ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9e371750>]}
2020-10-24 21:06:49,125826 (MainThread): Flushing usage events
2020-10-24 21:06:49,127662 (MainThread): Connection 'None' was properly closed.
2020-10-24 21:11:49,285658 (MainThread): Running with dbt=0.15.0
2020-10-24 21:11:49,441400 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 21:11:49,452466 (MainThread): Tracking: tracking
2020-10-24 21:11:49,458645 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4825f7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff482639c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4825f78d0>]}
2020-10-24 21:11:50,74698 (MainThread): Partial parsing not enabled
2020-10-24 21:11:50,78608 (MainThread): Parsing macros/core.sql
2020-10-24 21:11:50,84300 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 21:11:50,94210 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 21:11:50,97418 (MainThread): Parsing macros/etc/query.sql
2020-10-24 21:11:50,100321 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 21:11:50,102500 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 21:11:50,106382 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 21:11:50,110120 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 21:11:50,112629 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 21:11:50,115021 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 21:11:50,117209 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 21:11:50,120231 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 21:11:50,148874 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 21:11:50,157576 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 21:11:50,165388 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 21:11:50,168718 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 21:11:50,171466 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 21:11:50,184338 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 21:11:50,204666 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 21:11:50,223874 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 21:11:50,230476 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 21:11:50,237654 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 21:11:50,246446 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 21:11:50,254351 (MainThread): Parsing macros/relations.sql
2020-10-24 21:11:50,256734 (MainThread): Parsing macros/catalog.sql
2020-10-24 21:11:50,259441 (MainThread): Parsing macros/adapters.sql
2020-10-24 21:11:50,272436 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 21:11:50,298360 (MainThread): Partial parsing not enabled
2020-10-24 21:11:50,323070 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 21:11:50,324270 (MainThread): Opening a new connection, currently in state init
2020-10-24 21:11:50,325695 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 21:11:50,326964 (MainThread): On None: No close available on handle
2020-10-24 21:11:50,328110 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 21:11:50,329286 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4825783d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff48256f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff48256f650>]}
2020-10-24 21:11:50,830732 (MainThread): Flushing usage events
2020-10-24 21:11:50,832503 (MainThread): Connection 'None' was properly closed.
2020-10-24 21:13:05,647478 (MainThread): Running with dbt=0.15.0
2020-10-24 21:13:05,796670 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 21:13:05,816507 (MainThread): Tracking: tracking
2020-10-24 21:13:05,824743 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f287053df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28704e2250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28704e2c50>]}
2020-10-24 21:13:06,352971 (MainThread): Partial parsing not enabled
2020-10-24 21:13:06,357936 (MainThread): Parsing macros/core.sql
2020-10-24 21:13:06,366547 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 21:13:06,380420 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 21:13:06,385556 (MainThread): Parsing macros/etc/query.sql
2020-10-24 21:13:06,389274 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 21:13:06,392320 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 21:13:06,397404 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 21:13:06,402410 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 21:13:06,405706 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 21:13:06,409272 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 21:13:06,412799 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 21:13:06,417688 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 21:13:06,451140 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 21:13:06,459327 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 21:13:06,467243 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 21:13:06,470330 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 21:13:06,473006 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 21:13:06,487161 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 21:13:06,509352 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 21:13:06,530459 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 21:13:06,537017 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 21:13:06,544873 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 21:13:06,554034 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 21:13:06,562389 (MainThread): Parsing macros/relations.sql
2020-10-24 21:13:06,567312 (MainThread): Parsing macros/catalog.sql
2020-10-24 21:13:06,570711 (MainThread): Parsing macros/adapters.sql
2020-10-24 21:13:06,582105 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 21:13:06,607394 (MainThread): Partial parsing not enabled
2020-10-24 21:13:06,637397 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 21:13:06,639160 (MainThread): Opening a new connection, currently in state init
2020-10-24 21:13:06,641067 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 21:13:06,643050 (MainThread): On None: No close available on handle
2020-10-24 21:13:06,646424 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 21:13:06,653088 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28704f9c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f287063ae90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f287052f450>]}
2020-10-24 21:13:07,199573 (MainThread): Flushing usage events
2020-10-24 21:13:07,201887 (MainThread): Connection 'None' was properly closed.
2020-10-24 21:20:50,343296 (MainThread): Running with dbt=0.15.0
2020-10-24 21:20:50,493165 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-24 21:20:50,509229 (MainThread): Tracking: tracking
2020-10-24 21:20:50,516228 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58bf01a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59afda590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59afdaad0>]}
2020-10-24 21:20:51,166495 (MainThread): Partial parsing not enabled
2020-10-24 21:20:51,169497 (MainThread): Parsing macros/core.sql
2020-10-24 21:20:51,175400 (MainThread): Parsing macros/etc/datetime.sql
2020-10-24 21:20:51,186584 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-24 21:20:51,190415 (MainThread): Parsing macros/etc/query.sql
2020-10-24 21:20:51,193369 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-24 21:20:51,196431 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-24 21:20:51,200312 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-24 21:20:51,203876 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-24 21:20:51,206485 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-24 21:20:51,208857 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-24 21:20:51,211196 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-24 21:20:51,214900 (MainThread): Parsing macros/adapters/common.sql
2020-10-24 21:20:51,245597 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-24 21:20:51,254961 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-24 21:20:51,264144 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-24 21:20:51,267949 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-24 21:20:51,271123 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-24 21:20:51,285026 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-24 21:20:51,307497 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-24 21:20:51,328531 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-24 21:20:51,336136 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-24 21:20:51,344969 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-24 21:20:51,360262 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-24 21:20:51,368876 (MainThread): Parsing macros/relations.sql
2020-10-24 21:20:51,371849 (MainThread): Parsing macros/catalog.sql
2020-10-24 21:20:51,375113 (MainThread): Parsing macros/adapters.sql
2020-10-24 21:20:51,386922 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-24 21:20:51,417303 (MainThread): Partial parsing not enabled
2020-10-24 21:20:51,451381 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-24 21:20:51,452911 (MainThread): Opening a new connection, currently in state init
2020-10-24 21:20:51,454700 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-24 21:20:51,455955 (MainThread): On None: No close available on handle
2020-10-24 21:20:51,457332 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-24 21:20:51,458537 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58bf35ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58bf44a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58bf49450>]}
2020-10-24 21:20:51,964723 (MainThread): Flushing usage events
2020-10-24 21:20:51,966406 (MainThread): Connection 'None' was properly closed.
2020-10-25 07:28:29,438145 (MainThread): Running with dbt=0.15.0
2020-10-25 07:28:29,724219 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 07:28:29,744633 (MainThread): Tracking: tracking
2020-10-25 07:28:29,780999 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e2ca07210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e2c9f7ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e2c9f7590>]}
2020-10-25 07:28:30,597768 (MainThread): Partial parsing not enabled
2020-10-25 07:28:30,606737 (MainThread): Parsing macros/core.sql
2020-10-25 07:28:30,616231 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 07:28:30,634355 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 07:28:30,639649 (MainThread): Parsing macros/etc/query.sql
2020-10-25 07:28:30,642908 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 07:28:30,646240 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 07:28:30,651495 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 07:28:30,657304 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 07:28:30,660967 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 07:28:30,664684 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 07:28:30,668557 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 07:28:30,673655 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 07:28:30,733199 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 07:28:30,750077 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 07:28:30,766789 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 07:28:30,772365 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 07:28:30,777332 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 07:28:30,802281 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 07:28:30,850606 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 07:28:30,897500 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 07:28:30,910518 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 07:28:30,926132 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 07:28:30,943417 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 07:28:30,960584 (MainThread): Parsing macros/relations.sql
2020-10-25 07:28:30,965077 (MainThread): Parsing macros/catalog.sql
2020-10-25 07:28:30,969796 (MainThread): Parsing macros/adapters.sql
2020-10-25 07:28:30,997550 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 07:28:31,52491 (MainThread): Partial parsing not enabled
2020-10-25 07:28:31,99226 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 07:28:31,101270 (MainThread): Opening a new connection, currently in state init
2020-10-25 07:28:31,103578 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 07:28:31,105484 (MainThread): On None: No close available on handle
2020-10-25 07:28:31,107632 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 07:28:31,109373 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3d1e45d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e2c994510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e2c9894d0>]}
2020-10-25 07:28:31,620613 (MainThread): Flushing usage events
2020-10-25 07:28:31,622623 (MainThread): Connection 'None' was properly closed.
2020-10-25 07:35:10,222754 (MainThread): Running with dbt=0.15.0
2020-10-25 07:35:10,386940 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 07:35:10,390927 (MainThread): Tracking: tracking
2020-10-25 07:35:10,397513 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dbe9cf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dbe77c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dbe77e90>]}
2020-10-25 07:35:10,956944 (MainThread): Partial parsing not enabled
2020-10-25 07:35:10,960470 (MainThread): Parsing macros/core.sql
2020-10-25 07:35:10,965974 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 07:35:10,975643 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 07:35:10,978641 (MainThread): Parsing macros/etc/query.sql
2020-10-25 07:35:10,981063 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 07:35:10,983154 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 07:35:10,986287 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 07:35:10,989424 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 07:35:10,991733 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 07:35:10,993892 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 07:35:10,995956 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 07:35:10,998930 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 07:35:11,27809 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 07:35:11,36780 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 07:35:11,44672 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 07:35:11,47938 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 07:35:11,51268 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 07:35:11,64724 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 07:35:11,85136 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 07:35:11,104274 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 07:35:11,110626 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 07:35:11,118140 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 07:35:11,126948 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 07:35:11,134713 (MainThread): Parsing macros/relations.sql
2020-10-25 07:35:11,137070 (MainThread): Parsing macros/catalog.sql
2020-10-25 07:35:11,139838 (MainThread): Parsing macros/adapters.sql
2020-10-25 07:35:11,150492 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 07:35:11,176014 (MainThread): Partial parsing not enabled
2020-10-25 07:35:11,202160 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 07:35:11,203417 (MainThread): Opening a new connection, currently in state init
2020-10-25 07:35:11,204903 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 07:35:11,205755 (MainThread): On None: No close available on handle
2020-10-25 07:35:11,206935 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 07:35:11,208245 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dbe1d7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dbf03e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dbe2eed0>]}
2020-10-25 07:35:11,716188 (MainThread): Flushing usage events
2020-10-25 07:35:11,718121 (MainThread): Connection 'None' was properly closed.
2020-10-25 07:36:18,38190 (MainThread): Running with dbt=0.15.0
2020-10-25 07:36:18,275354 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 07:36:18,279718 (MainThread): Tracking: tracking
2020-10-25 07:36:18,288889 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f577ced59d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f577ce3f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f577ce1cfd0>]}
2020-10-25 07:36:19,474006 (MainThread): Partial parsing not enabled
2020-10-25 07:36:19,477222 (MainThread): Parsing macros/core.sql
2020-10-25 07:36:19,486340 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 07:36:19,503687 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 07:36:19,509501 (MainThread): Parsing macros/etc/query.sql
2020-10-25 07:36:19,513551 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 07:36:19,518993 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 07:36:19,525062 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 07:36:19,531085 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 07:36:19,536333 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 07:36:19,539884 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 07:36:19,543969 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 07:36:19,552239 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 07:36:19,604302 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 07:36:19,621454 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 07:36:19,642962 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 07:36:19,652917 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 07:36:19,659977 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 07:36:19,685942 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 07:36:19,745956 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 07:36:19,783994 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 07:36:19,793597 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 07:36:19,812564 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 07:36:19,832288 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 07:36:19,846220 (MainThread): Parsing macros/relations.sql
2020-10-25 07:36:19,854183 (MainThread): Parsing macros/catalog.sql
2020-10-25 07:36:19,859147 (MainThread): Parsing macros/adapters.sql
2020-10-25 07:36:19,888660 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 07:36:19,935771 (MainThread): Partial parsing not enabled
2020-10-25 07:36:19,979360 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 07:36:19,982600 (MainThread): Opening a new connection, currently in state init
2020-10-25 07:36:19,985610 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 07:36:19,989595 (MainThread): On None: No close available on handle
2020-10-25 07:36:19,992936 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 07:36:19,996884 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f577ceabd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f577cf29c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f577ceca310>]}
2020-10-25 07:36:21,505258 (MainThread): Flushing usage events
2020-10-25 07:36:21,508134 (MainThread): Connection 'None' was properly closed.
2020-10-25 07:50:37,794178 (MainThread): Running with dbt=0.15.0
2020-10-25 07:50:38,48239 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 07:50:38,53739 (MainThread): Tracking: tracking
2020-10-25 07:50:38,64444 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea58d21b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea58d63fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea58c8b5d0>]}
2020-10-25 07:50:38,805181 (MainThread): Partial parsing not enabled
2020-10-25 07:50:38,809090 (MainThread): Parsing macros/core.sql
2020-10-25 07:50:38,816370 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 07:50:38,831250 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 07:50:38,835360 (MainThread): Parsing macros/etc/query.sql
2020-10-25 07:50:38,838310 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 07:50:38,841009 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 07:50:38,845384 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 07:50:38,850229 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 07:50:38,855821 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 07:50:38,858746 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 07:50:38,861917 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 07:50:38,866052 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 07:50:38,900687 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 07:50:38,910719 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 07:50:38,921054 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 07:50:38,924737 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 07:50:38,929209 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 07:50:38,947133 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 07:50:38,972213 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 07:50:38,995422 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 07:50:39,3917 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 07:50:39,12950 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 07:50:39,23182 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 07:50:39,36402 (MainThread): Parsing macros/relations.sql
2020-10-25 07:50:39,39398 (MainThread): Parsing macros/catalog.sql
2020-10-25 07:50:39,43101 (MainThread): Parsing macros/adapters.sql
2020-10-25 07:50:39,57039 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 07:50:39,92183 (MainThread): Partial parsing not enabled
2020-10-25 07:50:39,125205 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 07:50:39,126955 (MainThread): Opening a new connection, currently in state init
2020-10-25 07:50:39,128975 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 07:50:39,132862 (MainThread): On None: No close available on handle
2020-10-25 07:50:39,134409 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 07:50:39,135980 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea58d90a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea58d90250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea58cf8bd0>]}
2020-10-25 07:50:40,646294 (MainThread): Flushing usage events
2020-10-25 07:50:40,648575 (MainThread): Connection 'None' was properly closed.
2020-10-25 07:55:03,448686 (MainThread): Running with dbt=0.15.0
2020-10-25 07:55:03,756358 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 07:55:03,761460 (MainThread): Tracking: tracking
2020-10-25 07:55:03,768220 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccaada7a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccaada7090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccaada9fd0>]}
2020-10-25 07:55:04,401785 (MainThread): Partial parsing not enabled
2020-10-25 07:55:04,405171 (MainThread): Parsing macros/core.sql
2020-10-25 07:55:04,410758 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 07:55:04,421059 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 07:55:04,424508 (MainThread): Parsing macros/etc/query.sql
2020-10-25 07:55:04,427217 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 07:55:04,429634 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 07:55:04,432956 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 07:55:04,436345 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 07:55:04,438535 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 07:55:04,440747 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 07:55:04,442998 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 07:55:04,445982 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 07:55:04,474524 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 07:55:04,482626 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 07:55:04,490561 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 07:55:04,493587 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 07:55:04,496357 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 07:55:04,509536 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 07:55:04,529971 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 07:55:04,549334 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 07:55:04,556003 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 07:55:04,563253 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 07:55:04,571734 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 07:55:04,579683 (MainThread): Parsing macros/relations.sql
2020-10-25 07:55:04,582499 (MainThread): Parsing macros/catalog.sql
2020-10-25 07:55:04,585575 (MainThread): Parsing macros/adapters.sql
2020-10-25 07:55:04,596343 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 07:55:04,622415 (MainThread): Partial parsing not enabled
2020-10-25 07:55:04,649316 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 07:55:04,650467 (MainThread): Opening a new connection, currently in state init
2020-10-25 07:55:04,651686 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 07:55:04,652650 (MainThread): On None: No close available on handle
2020-10-25 07:55:04,653997 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 07:55:04,655260 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccaadbac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccaad925d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccaad92390>]}
2020-10-25 07:55:05,163905 (MainThread): Flushing usage events
2020-10-25 07:55:05,165776 (MainThread): Connection 'None' was properly closed.
2020-10-25 08:35:51,268974 (MainThread): Running with dbt=0.15.0
2020-10-25 08:35:51,440868 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 08:35:51,446155 (MainThread): Tracking: tracking
2020-10-25 08:35:51,450712 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb43f2330a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb43f1ad9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb43f25e5b0>]}
2020-10-25 08:35:52,90576 (MainThread): Partial parsing not enabled
2020-10-25 08:35:52,94239 (MainThread): Parsing macros/core.sql
2020-10-25 08:35:52,100604 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 08:35:52,111506 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 08:35:52,114843 (MainThread): Parsing macros/etc/query.sql
2020-10-25 08:35:52,117814 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 08:35:52,120395 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 08:35:52,124104 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 08:35:52,127905 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 08:35:52,130679 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 08:35:52,133906 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 08:35:52,136735 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 08:35:52,140257 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 08:35:52,170844 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 08:35:52,179991 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 08:35:52,192026 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 08:35:52,197030 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 08:35:52,201501 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 08:35:52,216441 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 08:35:52,238619 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 08:35:52,257874 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 08:35:52,264454 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 08:35:52,273169 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 08:35:52,283629 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 08:35:52,292507 (MainThread): Parsing macros/relations.sql
2020-10-25 08:35:52,295566 (MainThread): Parsing macros/catalog.sql
2020-10-25 08:35:52,298775 (MainThread): Parsing macros/adapters.sql
2020-10-25 08:35:52,311008 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 08:35:52,340714 (MainThread): Partial parsing not enabled
2020-10-25 08:35:52,370468 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 08:35:52,372626 (MainThread): Opening a new connection, currently in state init
2020-10-25 08:35:52,374800 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 08:35:52,376142 (MainThread): On None: No close available on handle
2020-10-25 08:35:52,377724 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 08:35:52,379257 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb43f248580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb43f15e9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb43f15efd0>]}
2020-10-25 08:35:52,930961 (MainThread): Flushing usage events
2020-10-25 08:35:52,933368 (MainThread): Connection 'None' was properly closed.
2020-10-25 08:43:38,217642 (MainThread): Running with dbt=0.15.0
2020-10-25 08:43:38,451100 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 08:43:38,458179 (MainThread): Tracking: tracking
2020-10-25 08:43:38,463772 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f969724ef40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9697176550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96972655b0>]}
2020-10-25 08:43:40,109127 (MainThread): Partial parsing not enabled
2020-10-25 08:43:40,115002 (MainThread): Parsing macros/core.sql
2020-10-25 08:43:40,125010 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 08:43:40,150975 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 08:43:40,157552 (MainThread): Parsing macros/etc/query.sql
2020-10-25 08:43:40,164207 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 08:43:40,167487 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 08:43:40,172881 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 08:43:40,177170 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 08:43:40,182484 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 08:43:40,186384 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 08:43:40,189580 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 08:43:40,196518 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 08:43:40,245218 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 08:43:40,259994 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 08:43:40,278444 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 08:43:40,285663 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 08:43:40,290806 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 08:43:40,317804 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 08:43:40,379292 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 08:43:40,428679 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 08:43:40,436504 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 08:43:40,445644 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 08:43:40,455620 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 08:43:40,465732 (MainThread): Parsing macros/relations.sql
2020-10-25 08:43:40,469342 (MainThread): Parsing macros/catalog.sql
2020-10-25 08:43:40,476959 (MainThread): Parsing macros/adapters.sql
2020-10-25 08:43:40,492624 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 08:43:40,542770 (MainThread): Partial parsing not enabled
2020-10-25 08:43:40,604062 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 08:43:40,609419 (MainThread): Opening a new connection, currently in state init
2020-10-25 08:43:40,612445 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 08:43:40,614566 (MainThread): On None: No close available on handle
2020-10-25 08:43:40,617492 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 08:43:40,625277 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9697237df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96949e3a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96949e35e0>]}
2020-10-25 08:43:41,158278 (MainThread): Flushing usage events
2020-10-25 08:43:41,174072 (MainThread): Connection 'None' was properly closed.
2020-10-25 08:45:47,375900 (MainThread): Running with dbt=0.15.0
2020-10-25 08:45:47,642124 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 08:45:47,662322 (MainThread): Tracking: tracking
2020-10-25 08:45:47,667259 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1bb60edc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1bb5feb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1bb61d1c0>]}
2020-10-25 08:45:48,848178 (MainThread): Partial parsing not enabled
2020-10-25 08:45:48,852342 (MainThread): Parsing macros/core.sql
2020-10-25 08:45:48,859052 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 08:45:48,870708 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 08:45:48,874463 (MainThread): Parsing macros/etc/query.sql
2020-10-25 08:45:48,877736 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 08:45:48,880393 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 08:45:48,884314 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 08:45:48,888369 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 08:45:48,891656 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 08:45:48,897689 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 08:45:48,900924 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 08:45:48,905643 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 08:45:48,950031 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 08:45:48,960677 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 08:45:48,969446 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 08:45:48,973127 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 08:45:48,977580 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 08:45:49,7336 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 08:45:49,38587 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 08:45:49,76963 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 08:45:49,92919 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 08:45:49,113197 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 08:45:49,140271 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 08:45:49,155198 (MainThread): Parsing macros/relations.sql
2020-10-25 08:45:49,158405 (MainThread): Parsing macros/catalog.sql
2020-10-25 08:45:49,164099 (MainThread): Parsing macros/adapters.sql
2020-10-25 08:45:49,192993 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 08:45:49,231934 (MainThread): Partial parsing not enabled
2020-10-25 08:45:49,271098 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 08:45:49,272801 (MainThread): Opening a new connection, currently in state init
2020-10-25 08:45:49,274855 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 08:45:49,276252 (MainThread): On None: No close available on handle
2020-10-25 08:45:49,277855 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 08:45:49,279538 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1bb5feb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1bb571e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1bb571790>]}
2020-10-25 08:45:50,239350 (MainThread): Flushing usage events
2020-10-25 08:45:50,241779 (MainThread): Connection 'None' was properly closed.
2020-10-25 08:51:04,828329 (MainThread): Running with dbt=0.15.0
2020-10-25 08:51:05,152163 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 08:51:05,278193 (MainThread): Tracking: tracking
2020-10-25 08:51:05,285533 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b49969fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b5696c9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4997a430>]}
2020-10-25 08:51:05,997338 (MainThread): Partial parsing not enabled
2020-10-25 08:51:06,4852 (MainThread): Parsing macros/core.sql
2020-10-25 08:51:06,19682 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 08:51:06,45806 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 08:51:06,51285 (MainThread): Parsing macros/etc/query.sql
2020-10-25 08:51:06,55962 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 08:51:06,61121 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 08:51:06,68537 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 08:51:06,74050 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 08:51:06,79899 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 08:51:06,84063 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 08:51:06,87982 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 08:51:06,93659 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 08:51:06,185181 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 08:51:06,200212 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 08:51:06,209979 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 08:51:06,215252 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 08:51:06,220078 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 08:51:06,240978 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 08:51:06,273227 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 08:51:06,321864 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 08:51:06,333897 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 08:51:06,352891 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 08:51:06,375249 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 08:51:06,399657 (MainThread): Parsing macros/relations.sql
2020-10-25 08:51:06,404990 (MainThread): Parsing macros/catalog.sql
2020-10-25 08:51:06,409457 (MainThread): Parsing macros/adapters.sql
2020-10-25 08:51:06,429205 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 08:51:06,486457 (MainThread): Partial parsing not enabled
2020-10-25 08:51:06,550912 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 08:51:06,553056 (MainThread): Opening a new connection, currently in state init
2020-10-25 08:51:06,560555 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 08:51:06,563675 (MainThread): On None: No close available on handle
2020-10-25 08:51:06,568469 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 08:51:06,574522 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4994cd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4984b160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4984bc10>]}
2020-10-25 08:51:07,83596 (MainThread): Flushing usage events
2020-10-25 08:51:07,85488 (MainThread): Connection 'None' was properly closed.
2020-10-25 08:52:34,740947 (MainThread): Running with dbt=0.15.0
2020-10-25 08:52:34,999481 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-10-25 08:52:35,3531 (MainThread): Tracking: tracking
2020-10-25 08:52:35,7992 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec21eeeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec21e29a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec22022b0>]}
2020-10-25 08:52:35,738724 (MainThread): Partial parsing not enabled
2020-10-25 08:52:35,757678 (MainThread): Parsing macros/core.sql
2020-10-25 08:52:35,804860 (MainThread): Parsing macros/etc/datetime.sql
2020-10-25 08:52:35,846569 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-25 08:52:35,856238 (MainThread): Parsing macros/etc/query.sql
2020-10-25 08:52:35,864435 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-25 08:52:35,870367 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-25 08:52:35,877939 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-25 08:52:35,885034 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-25 08:52:35,888653 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-25 08:52:35,907852 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-25 08:52:35,920435 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-25 08:52:35,929717 (MainThread): Parsing macros/adapters/common.sql
2020-10-25 08:52:36,95765 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-25 08:52:36,117571 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-25 08:52:36,128128 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-25 08:52:36,132807 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-25 08:52:36,136508 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-25 08:52:36,160348 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-25 08:52:36,214577 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-25 08:52:36,252003 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-25 08:52:36,262727 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-25 08:52:36,275895 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-25 08:52:36,287262 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-25 08:52:36,302809 (MainThread): Parsing macros/relations.sql
2020-10-25 08:52:36,306386 (MainThread): Parsing macros/catalog.sql
2020-10-25 08:52:36,311250 (MainThread): Parsing macros/adapters.sql
2020-10-25 08:52:36,337800 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-25 08:52:36,394346 (MainThread): Partial parsing not enabled
2020-10-25 08:52:36,424957 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-25 08:52:36,426589 (MainThread): Opening a new connection, currently in state init
2020-10-25 08:52:36,428997 (MainThread): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2020-10-25 08:52:36,431028 (MainThread): On None: No close available on handle
2020-10-25 08:52:36,433928 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2020-10-25 08:52:36,435634 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec21e2d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec2179760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec21799a0>]}
2020-10-25 08:52:36,951868 (MainThread): Flushing usage events
2020-10-25 08:52:37,38235 (MainThread): Connection 'None' was properly closed.
2020-10-26 18:30:48,848419 (MainThread): Running with dbt=0.15.0
2020-10-26 18:30:48,940676 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-26 18:30:48,945443 (MainThread): Tracking: tracking
2020-10-26 18:30:48,960737 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116415fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116447f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116447550>]}
2020-10-26 18:30:49,759995 (MainThread): Partial parsing not enabled
2020-10-26 18:30:49,762395 (MainThread): Parsing macros/core.sql
2020-10-26 18:30:49,766144 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-26 18:30:49,772190 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-26 18:30:49,773875 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-26 18:30:49,783716 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-26 18:30:49,799772 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-26 18:30:49,814739 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-26 18:30:49,816634 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-26 18:30:49,822456 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-26 18:30:49,828972 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-26 18:30:49,834430 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-26 18:30:49,839845 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-26 18:30:49,844457 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-26 18:30:49,845552 (MainThread): Parsing macros/etc/query.sql
2020-10-26 18:30:49,846960 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-26 18:30:49,848929 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-26 18:30:49,851186 (MainThread): Parsing macros/etc/datetime.sql
2020-10-26 18:30:49,858506 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-26 18:30:49,860687 (MainThread): Parsing macros/adapters/common.sql
2020-10-26 18:30:49,883505 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-26 18:30:49,885115 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-26 18:30:49,886282 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-26 18:30:49,887689 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-26 18:30:49,890529 (MainThread): Parsing macros/catalog.sql
2020-10-26 18:30:49,892299 (MainThread): Parsing macros/relations.sql
2020-10-26 18:30:49,894513 (MainThread): Parsing macros/adapters.sql
2020-10-26 18:30:49,902754 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-26 18:30:49,921824 (MainThread): Partial parsing not enabled
2020-10-26 18:30:49,935732 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:30:49,935883 (MainThread): Opening a new connection, currently in state init
2020-10-26 18:30:49,945033 (MainThread): Got an error when attempting to open a postgres connection: 'FATAL:  password authentication failed for user "airflow"
'
2020-10-26 18:30:49,945265 (MainThread): On None: No close available on handle
2020-10-26 18:30:49,945555 (MainThread): ERROR: Database Error
  FATAL:  password authentication failed for user "airflow"
  
2020-10-26 18:30:49,945777 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1164297c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1164f1f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1164f1340>]}
2020-10-26 18:30:50,528808 (MainThread): Flushing usage events
2020-10-26 18:30:50,529075 (MainThread): Connection 'None' was properly closed.
2020-10-26 18:32:28,494401 (MainThread): Running with dbt=0.15.0
2020-10-26 18:32:28,589693 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-26 18:32:28,596911 (MainThread): Tracking: tracking
2020-10-26 18:32:28,609741 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10884c850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10888a580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10888aa00>]}
2020-10-26 18:32:29,439241 (MainThread): Partial parsing not enabled
2020-10-26 18:32:29,441273 (MainThread): Parsing macros/core.sql
2020-10-26 18:32:29,445125 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-26 18:32:29,451256 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-26 18:32:29,457804 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-26 18:32:29,469272 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-26 18:32:29,485362 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-26 18:32:29,500955 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-26 18:32:29,502855 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-26 18:32:29,508846 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-26 18:32:29,515301 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-26 18:32:29,520720 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-26 18:32:29,526127 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-26 18:32:29,530812 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-26 18:32:29,532077 (MainThread): Parsing macros/etc/query.sql
2020-10-26 18:32:29,533404 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-26 18:32:29,535211 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-26 18:32:29,537483 (MainThread): Parsing macros/etc/datetime.sql
2020-10-26 18:32:29,545158 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-26 18:32:29,547443 (MainThread): Parsing macros/adapters/common.sql
2020-10-26 18:32:29,570326 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-26 18:32:29,571689 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-26 18:32:29,573007 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-26 18:32:29,574389 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-26 18:32:29,576751 (MainThread): Parsing macros/catalog.sql
2020-10-26 18:32:29,579319 (MainThread): Parsing macros/relations.sql
2020-10-26 18:32:29,581386 (MainThread): Parsing macros/adapters.sql
2020-10-26 18:32:29,595991 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-26 18:32:29,643299 (MainThread): Partial parsing not enabled
2020-10-26 18:32:29,661951 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:32:29,662139 (MainThread): Opening a new connection, currently in state init
2020-10-26 18:32:29,696592 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-26 18:32:29,697066 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-26 18:32:29,743816 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:32:29,743999 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_incremental).
2020-10-26 18:32:29,758834 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:32:29,758964 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-26 18:32:37,641967 (MainThread): scipy not found, skipping conversion test.
2020-10-26 18:32:37,644308 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-26 18:32:37,646679 (MainThread): 
2020-10-26 18:32:37,647160 (MainThread): Acquiring new postgres connection "master".
2020-10-26 18:32:37,647303 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_incremental_country).
2020-10-26 18:32:37,775661 (MainThread): Using postgres connection "master".
2020-10-26 18:32:37,775901 (MainThread): On master: BEGIN
2020-10-26 18:32:37,778817 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:32:37,779149 (MainThread): Using postgres connection "master".
2020-10-26 18:32:37,779336 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-26 18:32:37,814853 (MainThread): SQL status: SELECT 2 in 0.04 seconds
2020-10-26 18:32:37,842082 (MainThread): Using postgres connection "master".
2020-10-26 18:32:37,842224 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-26 18:32:37,875921 (MainThread): SQL status: SELECT 0 in 0.03 seconds
2020-10-26 18:32:37,876848 (MainThread): On master: ROLLBACK
2020-10-26 18:32:37,878248 (MainThread): 18:32:37 | Concurrency: 4 threads (target='dev')
2020-10-26 18:32:37,878407 (MainThread): 18:32:37 | 
2020-10-26 18:32:37,881915 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-26 18:32:37,882053 (Thread-2): Began running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-26 18:32:37,882209 (Thread-1): 18:32:37 | 1 of 2 START test not_null_covid19_stats_country..................... [RUN]
2020-10-26 18:32:37,882324 (Thread-2): 18:32:37 | 2 of 2 START test not_null_covid19_stats_incremental_country......... [RUN]
2020-10-26 18:32:37,882648 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:32:37,882919 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:32:37,883029 (Thread-1): Opening a new connection, currently in state init
2020-10-26 18:32:37,883135 (Thread-2): Opening a new connection, currently in state init
2020-10-26 18:32:37,900630 (Thread-2): Compiling test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-26 18:32:37,909027 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-26 18:32:37,915305 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_incremental_country"
2020-10-26 18:32:37,922424 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-26 18:32:37,923782 (Thread-1): finished collecting timing info
2020-10-26 18:32:37,924066 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:32:37,924178 (Thread-2): finished collecting timing info
2020-10-26 18:32:37,924376 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-26 18:32:37,924503 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:32:37,924672 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: BEGIN
2020-10-26 18:32:37,927383 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:32:37,927532 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:32:37,927673 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:32:37,927776 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:32:37,927889 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_incremental_country"} */




select count(*)
from "covid19"."public"."covid19_stats_incremental"
where country is null

2020-10-26 18:32:37,927992 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "covid19"."public"."covid19_stats"
where country is null

2020-10-26 18:32:37,930763 (Thread-2): Postgres error: relation "public.covid19_stats_incremental" does not exist
LINE 7: from "covid19"."public"."covid19_stats_incremental"
             ^

2020-10-26 18:32:37,930951 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: ROLLBACK
2020-10-26 18:32:37,932886 (Thread-2): finished collecting timing info
2020-10-26 18:32:37,933577 (Thread-1): SQL status: SELECT 1 in 0.01 seconds
2020-10-26 18:32:37,933881 (Thread-1): finished collecting timing info
2020-10-26 18:32:37,934212 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-26 18:32:37,936219 (Thread-1): 18:32:37 | 1 of 2 PASS not_null_covid19_stats_country........................... [PASS in 0.05s]
2020-10-26 18:32:37,936402 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-26 18:32:37,933392 (Thread-2): Database Error in test not_null_covid19_stats_incremental_country (models/incremental/schema.yml)
  relation "public.covid19_stats_incremental" does not exist
  LINE 7: from "covid19"."public"."covid19_stats_incremental"
               ^
  compiled SQL at target/compiled/my_new_project/schema_test/not_null_covid19_stats_incremental_country.sql
Traceback (most recent call last):
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "public.covid19_stats_incremental" does not exist
LINE 7: from "covid19"."public"."covid19_stats_incremental"
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/node_runners.py", line 562, in execute
    failed_rows = self.execute_test(test)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/node_runners.py", line 543, in execute_test
    res, table = self.adapter.execute(
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 267, in execute
    return self.connections.execute(
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/cdiniz/Projects/data-engineering/airflow-poc/.venv/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test not_null_covid19_stats_incremental_country (models/incremental/schema.yml)
  relation "public.covid19_stats_incremental" does not exist
  LINE 7: from "covid19"."public"."covid19_stats_incremental"
               ^
  compiled SQL at target/compiled/my_new_project/schema_test/not_null_covid19_stats_incremental_country.sql
2020-10-26 18:32:37,961234 (Thread-2): 18:32:37 | 2 of 2 ERROR not_null_covid19_stats_incremental_country.............. [ERROR in 0.08s]
2020-10-26 18:32:37,961369 (Thread-2): Finished running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-26 18:32:37,962398 (MainThread): 18:32:37 | 
2020-10-26 18:32:37,962526 (MainThread): 18:32:37 | Finished running 2 tests in 0.32s.
2020-10-26 18:32:37,962622 (MainThread): Connection 'master' was left open.
2020-10-26 18:32:37,962700 (MainThread): On master: Close
2020-10-26 18:32:37,962814 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-26 18:32:37,962926 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-26 18:32:37,963112 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was left open.
2020-10-26 18:32:37,963207 (MainThread): On test.my_new_project.not_null_covid19_stats_incremental_country: Close
2020-10-26 18:32:37,970327 (MainThread): 
2020-10-26 18:32:37,970519 (MainThread): Completed with 1 error and 0 warnings:
2020-10-26 18:32:37,970671 (MainThread): 
2020-10-26 18:32:37,970896 (MainThread): Database Error in test not_null_covid19_stats_incremental_country (models/incremental/schema.yml)
2020-10-26 18:32:37,971152 (MainThread):   relation "public.covid19_stats_incremental" does not exist
2020-10-26 18:32:37,971305 (MainThread):   LINE 7: from "covid19"."public"."covid19_stats_incremental"
2020-10-26 18:32:37,971462 (MainThread):                ^
2020-10-26 18:32:37,971582 (MainThread):   compiled SQL at target/compiled/my_new_project/schema_test/not_null_covid19_stats_incremental_country.sql
2020-10-26 18:32:37,971731 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2020-10-26 18:32:37,971987 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116cdeeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116cdb430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116cdb490>]}
2020-10-26 18:32:39,481436 (MainThread): Flushing usage events
2020-10-26 18:33:29,490661 (MainThread): Running with dbt=0.15.0
2020-10-26 18:33:29,572052 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-26 18:33:29,572569 (MainThread): Tracking: tracking
2020-10-26 18:33:29,585756 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115412ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115447f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115447550>]}
2020-10-26 18:33:30,121866 (MainThread): Partial parsing not enabled
2020-10-26 18:33:30,124489 (MainThread): Parsing macros/core.sql
2020-10-26 18:33:30,128213 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-26 18:33:30,134253 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-26 18:33:30,203768 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-26 18:33:30,218797 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-26 18:33:30,234836 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-26 18:33:30,251435 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-26 18:33:30,253622 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-26 18:33:30,259824 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-26 18:33:30,267028 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-26 18:33:30,272982 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-26 18:33:30,278834 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-26 18:33:30,283902 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-26 18:33:30,285196 (MainThread): Parsing macros/etc/query.sql
2020-10-26 18:33:30,286972 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-26 18:33:30,289071 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-26 18:33:30,291340 (MainThread): Parsing macros/etc/datetime.sql
2020-10-26 18:33:30,299670 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-26 18:33:30,302016 (MainThread): Parsing macros/adapters/common.sql
2020-10-26 18:33:30,326434 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-26 18:33:30,327960 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-26 18:33:30,329228 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-26 18:33:30,330590 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-26 18:33:30,332932 (MainThread): Parsing macros/catalog.sql
2020-10-26 18:33:30,334666 (MainThread): Parsing macros/relations.sql
2020-10-26 18:33:30,337002 (MainThread): Parsing macros/adapters.sql
2020-10-26 18:33:30,345518 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-26 18:33:30,365679 (MainThread): Partial parsing not enabled
2020-10-26 18:33:30,380608 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:30,380792 (MainThread): Opening a new connection, currently in state init
2020-10-26 18:33:30,407501 (MainThread): Got an error when attempting to open a postgres connection: 'FATAL:  password authentication failed for user "airflow"
'
2020-10-26 18:33:30,407754 (MainThread): On None: No close available on handle
2020-10-26 18:33:30,408057 (MainThread): ERROR: Database Error
  FATAL:  password authentication failed for user "airflow"
  
2020-10-26 18:33:30,408291 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1154297c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115568310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115568280>]}
2020-10-26 18:33:30,914532 (MainThread): Flushing usage events
2020-10-26 18:33:30,914751 (MainThread): Connection 'None' was properly closed.
2020-10-26 18:33:38,928214 (MainThread): Running with dbt=0.15.0
2020-10-26 18:33:39,1769 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='ci_profiles', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-26 18:33:39,2247 (MainThread): Tracking: tracking
2020-10-26 18:33:39,14486 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11863a850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1186785e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118678a60>]}
2020-10-26 18:33:39,546460 (MainThread): Partial parsing not enabled
2020-10-26 18:33:39,548349 (MainThread): Parsing macros/core.sql
2020-10-26 18:33:39,551976 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-26 18:33:39,558185 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-26 18:33:39,559633 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-26 18:33:39,569775 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-26 18:33:39,585671 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-26 18:33:39,600662 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-26 18:33:39,602482 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-26 18:33:39,608041 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-26 18:33:39,614060 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-26 18:33:39,619301 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-26 18:33:39,624561 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-26 18:33:39,628877 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-26 18:33:39,629786 (MainThread): Parsing macros/etc/query.sql
2020-10-26 18:33:39,630802 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-26 18:33:39,632406 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-26 18:33:39,634380 (MainThread): Parsing macros/etc/datetime.sql
2020-10-26 18:33:39,641601 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-26 18:33:39,643586 (MainThread): Parsing macros/adapters/common.sql
2020-10-26 18:33:39,666776 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-26 18:33:39,667939 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-26 18:33:39,668837 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-26 18:33:39,669828 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-26 18:33:39,671755 (MainThread): Parsing macros/catalog.sql
2020-10-26 18:33:39,673123 (MainThread): Parsing macros/relations.sql
2020-10-26 18:33:39,674256 (MainThread): Parsing macros/adapters.sql
2020-10-26 18:33:39,682241 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-26 18:33:39,700959 (MainThread): Partial parsing not enabled
2020-10-26 18:33:39,714876 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:39,715021 (MainThread): Opening a new connection, currently in state init
2020-10-26 18:33:39,742537 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-26 18:33:39,742701 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-26 18:33:39,770342 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:33:39,770483 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_incremental).
2020-10-26 18:33:39,784460 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:33:39,784592 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-26 18:33:40,141163 (MainThread): scipy not found, skipping conversion test.
2020-10-26 18:33:40,143288 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-26 18:33:40,145235 (MainThread): 
2020-10-26 18:33:40,145532 (MainThread): Acquiring new postgres connection "master".
2020-10-26 18:33:40,145620 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_incremental_country).
2020-10-26 18:33:40,226055 (MainThread): Using postgres connection "master".
2020-10-26 18:33:40,226202 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-10-26 18:33:40,232168 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-10-26 18:33:40,256011 (MainThread): Using postgres connection "master".
2020-10-26 18:33:40,256144 (MainThread): On master: BEGIN
2020-10-26 18:33:40,257871 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:40,258059 (MainThread): Using postgres connection "master".
2020-10-26 18:33:40,258144 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-26 18:33:40,268480 (MainThread): SQL status: SELECT 2 in 0.01 seconds
2020-10-26 18:33:40,286692 (MainThread): Using postgres connection "master".
2020-10-26 18:33:40,286835 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-26 18:33:40,295373 (MainThread): SQL status: SELECT 0 in 0.01 seconds
2020-10-26 18:33:40,296342 (MainThread): On master: ROLLBACK
2020-10-26 18:33:40,297601 (MainThread): Using postgres connection "master".
2020-10-26 18:33:40,297731 (MainThread): On master: BEGIN
2020-10-26 18:33:40,299731 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:40,299892 (MainThread): On master: COMMIT
2020-10-26 18:33:40,299988 (MainThread): Using postgres connection "master".
2020-10-26 18:33:40,300066 (MainThread): On master: COMMIT
2020-10-26 18:33:40,301039 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-26 18:33:40,301327 (MainThread): 18:33:40 | Concurrency: 4 threads (target='dev')
2020-10-26 18:33:40,301448 (MainThread): 18:33:40 | 
2020-10-26 18:33:40,305440 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-26 18:33:40,305735 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-26 18:33:40,305913 (Thread-1): 18:33:40 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-26 18:33:40,306047 (Thread-2): 18:33:40 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-26 18:33:40,306358 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,306603 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-26 18:33:40,306682 (Thread-1): Opening a new connection, currently in state init
2020-10-26 18:33:40,306774 (Thread-2): Opening a new connection, currently in state init
2020-10-26 18:33:40,318661 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-26 18:33:40,326274 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-26 18:33:40,336574 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-26 18:33:40,337782 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-26 18:33:40,338761 (Thread-1): finished collecting timing info
2020-10-26 18:33:40,344808 (Thread-2): finished collecting timing info
2020-10-26 18:33:40,401320 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,401511 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "covid19"."public"."covid19_stats__dbt_tmp" cascade
2020-10-26 18:33:40,421869 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-26 18:33:40,422382 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-26 18:33:40,422487 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-26 18:33:40,425367 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:40,425560 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-26 18:33:40,425658 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      create  table "covid19"."public"."covid19_stats_incremental"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




GROUP BY country, day
  );
  
2020-10-26 18:33:40,433781 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2020-10-26 18:33:40,436491 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,436656 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop table if exists "covid19"."public"."covid19_stats__dbt_backup" cascade
2020-10-26 18:33:40,438558 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-10-26 18:33:40,440247 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-26 18:33:40,440771 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,440914 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-26 18:33:40,443233 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:40,443412 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,443546 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
create view "covid19"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-26 18:33:40,552395 (Thread-1): SQL status: CREATE VIEW in 0.11 seconds
2020-10-26 18:33:40,556319 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,556475 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "covid19"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-26 18:33:40,560108 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-26 18:33:40,562693 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,562854 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "covid19"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-26 18:33:40,564880 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-26 18:33:40,565889 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-26 18:33:40,566016 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,566100 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-26 18:33:40,575092 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-10-26 18:33:40,577020 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:40,577167 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop table if exists "covid19"."public"."covid19_stats__dbt_backup" cascade
2020-10-26 18:33:40,577399 (Thread-2): SQL status: SELECT 121 in 0.15 seconds
2020-10-26 18:33:40,578402 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-26 18:33:40,578557 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-26 18:33:40,578641 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-26 18:33:40,581618 (Thread-2): SQL status: COMMIT in 0.00 seconds
2020-10-26 18:33:40,583322 (Thread-2): finished collecting timing info
2020-10-26 18:33:40,584009 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b47276b-997f-463c-ad76-0fc4e1400db8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b05cdc0>]}
2020-10-26 18:33:40,663372 (Thread-1): SQL status: DROP TABLE in 0.09 seconds
2020-10-26 18:33:40,665636 (Thread-1): finished collecting timing info
2020-10-26 18:33:40,666220 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b47276b-997f-463c-ad76-0fc4e1400db8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b02b220>]}
2020-10-26 18:33:42,86905 (Thread-2): 18:33:42 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [SELECT 121 in 0.28s]
2020-10-26 18:33:42,87306 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-26 18:33:42,591043 (Thread-1): 18:33:42 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.36s]
2020-10-26 18:33:42,591262 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-26 18:33:42,592540 (MainThread): Using postgres connection "master".
2020-10-26 18:33:42,592687 (MainThread): On master: BEGIN
2020-10-26 18:33:42,594021 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:42,594203 (MainThread): On master: COMMIT
2020-10-26 18:33:42,594294 (MainThread): Using postgres connection "master".
2020-10-26 18:33:42,594373 (MainThread): On master: COMMIT
2020-10-26 18:33:42,595662 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-26 18:33:42,596046 (MainThread): 18:33:42 | 
2020-10-26 18:33:42,596173 (MainThread): 18:33:42 | Finished running 1 incremental model, 1 view model in 2.45s.
2020-10-26 18:33:42,596268 (MainThread): Connection 'master' was left open.
2020-10-26 18:33:42,596347 (MainThread): On master: Close
2020-10-26 18:33:42,596456 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-26 18:33:42,596529 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-26 18:33:42,596624 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-26 18:33:42,596695 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-26 18:33:42,602489 (MainThread): 
2020-10-26 18:33:42,602684 (MainThread): Completed successfully
2020-10-26 18:33:42,602845 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-26 18:33:42,603047 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b32a9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b32aac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b32a610>]}
2020-10-26 18:33:43,103412 (MainThread): Flushing usage events
2020-10-26 18:33:49,609336 (MainThread): Running with dbt=0.15.0
2020-10-26 18:33:49,693423 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-26 18:33:49,693941 (MainThread): Tracking: tracking
2020-10-26 18:33:49,705818 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1159367f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115974610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115974a90>]}
2020-10-26 18:33:50,341082 (MainThread): Partial parsing not enabled
2020-10-26 18:33:50,342763 (MainThread): Parsing macros/core.sql
2020-10-26 18:33:50,346356 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-26 18:33:50,352283 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-26 18:33:50,353748 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-26 18:33:50,362883 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-26 18:33:50,377881 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-26 18:33:50,391886 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-26 18:33:50,393487 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-26 18:33:50,398844 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-26 18:33:50,404838 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-26 18:33:50,409836 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-26 18:33:50,414758 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-26 18:33:50,418823 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-26 18:33:50,419665 (MainThread): Parsing macros/etc/query.sql
2020-10-26 18:33:50,420625 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-26 18:33:50,422113 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-26 18:33:50,423823 (MainThread): Parsing macros/etc/datetime.sql
2020-10-26 18:33:50,430536 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-26 18:33:50,432235 (MainThread): Parsing macros/adapters/common.sql
2020-10-26 18:33:50,454014 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-26 18:33:50,455075 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-26 18:33:50,455912 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-26 18:33:50,456852 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-26 18:33:50,458773 (MainThread): Parsing macros/catalog.sql
2020-10-26 18:33:50,460277 (MainThread): Parsing macros/relations.sql
2020-10-26 18:33:50,461531 (MainThread): Parsing macros/adapters.sql
2020-10-26 18:33:50,470421 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-26 18:33:50,491453 (MainThread): Partial parsing not enabled
2020-10-26 18:33:50,506896 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-26 18:33:50,507053 (MainThread): Opening a new connection, currently in state init
2020-10-26 18:33:50,539158 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-26 18:33:50,539319 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-26 18:33:50,570067 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:33:50,570218 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_incremental).
2020-10-26 18:33:50,585737 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:33:50,585934 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-26 18:33:50,817398 (MainThread): scipy not found, skipping conversion test.
2020-10-26 18:33:50,819558 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-26 18:33:50,821557 (MainThread): 
2020-10-26 18:33:50,821871 (MainThread): Acquiring new postgres connection "master".
2020-10-26 18:33:50,821959 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_incremental_country).
2020-10-26 18:33:50,917872 (MainThread): Using postgres connection "master".
2020-10-26 18:33:50,918018 (MainThread): On master: BEGIN
2020-10-26 18:33:50,920393 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:50,920557 (MainThread): Using postgres connection "master".
2020-10-26 18:33:50,920647 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-26 18:33:50,929611 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-26 18:33:50,955029 (MainThread): Using postgres connection "master".
2020-10-26 18:33:50,955168 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-26 18:33:50,964380 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-26 18:33:50,966204 (MainThread): On master: ROLLBACK
2020-10-26 18:33:50,967532 (MainThread): 18:33:50 | Concurrency: 4 threads (target='dev')
2020-10-26 18:33:50,967682 (MainThread): 18:33:50 | 
2020-10-26 18:33:50,970500 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-26 18:33:50,970644 (Thread-2): Began running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-26 18:33:50,970816 (Thread-1): 18:33:50 | 1 of 2 START test not_null_covid19_stats_country..................... [RUN]
2020-10-26 18:33:50,970957 (Thread-2): 18:33:50 | 2 of 2 START test not_null_covid19_stats_incremental_country......... [RUN]
2020-10-26 18:33:50,971281 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:33:50,971565 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:33:50,971657 (Thread-1): Opening a new connection, currently in state init
2020-10-26 18:33:50,971761 (Thread-2): Opening a new connection, currently in state init
2020-10-26 18:33:50,986251 (Thread-2): Compiling test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-26 18:33:50,986417 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-26 18:33:51,9800 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-26 18:33:51,12850 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_incremental_country"
2020-10-26 18:33:51,13316 (Thread-2): finished collecting timing info
2020-10-26 18:33:51,13593 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:33:51,13684 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: BEGIN
2020-10-26 18:33:51,13786 (Thread-1): finished collecting timing info
2020-10-26 18:33:51,14091 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:33:51,14181 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-26 18:33:51,16612 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:51,16765 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-26 18:33:51,16852 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "covid19"."public"."covid19_stats"
where country is null

2020-10-26 18:33:51,16952 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-26 18:33:51,17120 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-26 18:33:51,17223 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_incremental_country"} */




select count(*)
from "covid19"."public"."covid19_stats_incremental"
where country is null

2020-10-26 18:33:51,20822 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2020-10-26 18:33:51,21163 (Thread-2): finished collecting timing info
2020-10-26 18:33:51,21396 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-26 18:33:51,21517 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: ROLLBACK
2020-10-26 18:33:51,21739 (Thread-1): finished collecting timing info
2020-10-26 18:33:51,22012 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-26 18:33:51,23462 (Thread-1): 18:33:51 | 1 of 2 PASS not_null_covid19_stats_country........................... [PASS in 0.05s]
2020-10-26 18:33:51,23761 (Thread-2): 18:33:51 | 2 of 2 PASS not_null_covid19_stats_incremental_country............... [PASS in 0.05s]
2020-10-26 18:33:51,23904 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-26 18:33:51,24078 (Thread-2): Finished running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-26 18:33:51,25389 (MainThread): 18:33:51 | 
2020-10-26 18:33:51,25551 (MainThread): 18:33:51 | Finished running 2 tests in 0.20s.
2020-10-26 18:33:51,25654 (MainThread): Connection 'master' was left open.
2020-10-26 18:33:51,25736 (MainThread): On master: Close
2020-10-26 18:33:51,25861 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-26 18:33:51,25939 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-26 18:33:51,26035 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was left open.
2020-10-26 18:33:51,26106 (MainThread): On test.my_new_project.not_null_covid19_stats_incremental_country: Close
2020-10-26 18:33:51,31978 (MainThread): 
2020-10-26 18:33:51,32161 (MainThread): Completed successfully
2020-10-26 18:33:51,32279 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-26 18:33:51,32486 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e14c8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e14c940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e14ca60>]}
2020-10-26 18:33:51,537433 (MainThread): Flushing usage events
2020-10-27 18:40:16,154096 (MainThread): Running with dbt=0.15.0
2020-10-27 18:40:16,238232 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-27 18:40:16,254162 (MainThread): Tracking: tracking
2020-10-27 18:40:16,268474 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134ea040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113518820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11352b310>]}
2020-10-27 18:40:17,941068 (MainThread): Partial parsing not enabled
2020-10-27 18:40:17,943091 (MainThread): Parsing macros/core.sql
2020-10-27 18:40:17,946994 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 18:40:17,953561 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 18:40:17,955352 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 18:40:17,966128 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 18:40:17,984959 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 18:40:18,3900 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 18:40:18,6199 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 18:40:18,14332 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 18:40:18,21196 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 18:40:18,26883 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 18:40:18,32184 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 18:40:18,36608 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 18:40:18,37816 (MainThread): Parsing macros/etc/query.sql
2020-10-27 18:40:18,39027 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 18:40:18,40682 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 18:40:18,42728 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 18:40:18,50102 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 18:40:18,52088 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 18:40:18,75308 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 18:40:18,76740 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 18:40:18,77957 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 18:40:18,79148 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 18:40:18,81452 (MainThread): Parsing macros/catalog.sql
2020-10-27 18:40:18,83048 (MainThread): Parsing macros/relations.sql
2020-10-27 18:40:18,84418 (MainThread): Parsing macros/adapters.sql
2020-10-27 18:40:18,92620 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 18:40:18,110838 (MainThread): Partial parsing not enabled
2020-10-27 18:40:18,124701 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:40:18,124839 (MainThread): Opening a new connection, currently in state init
2020-10-27 18:40:18,132662 (MainThread): Got an error when attempting to open a postgres connection: 'FATAL:  password authentication failed for user "airflow"
'
2020-10-27 18:40:18,133077 (MainThread): On None: No close available on handle
2020-10-27 18:40:18,133391 (MainThread): ERROR: Database Error
  FATAL:  password authentication failed for user "airflow"
  
2020-10-27 18:40:18,133609 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113500a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135eec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11997a040>]}
2020-10-27 18:40:18,630440 (MainThread): Flushing usage events
2020-10-27 18:40:18,630650 (MainThread): Connection 'None' was properly closed.
2020-10-27 18:41:33,158166 (MainThread): Running with dbt=0.15.0
2020-10-27 18:41:33,240804 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-27 18:41:33,241254 (MainThread): Tracking: tracking
2020-10-27 18:41:33,254193 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11913a160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11916cd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11916c6a0>]}
2020-10-27 18:41:33,803845 (MainThread): Partial parsing not enabled
2020-10-27 18:41:33,805978 (MainThread): Parsing macros/core.sql
2020-10-27 18:41:33,809913 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 18:41:33,816095 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 18:41:33,817883 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 18:41:33,827767 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 18:41:33,846438 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 18:41:33,866284 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 18:41:33,869152 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 18:41:33,876838 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 18:41:33,884540 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 18:41:33,890485 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 18:41:33,896108 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 18:41:33,901074 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 18:41:33,902237 (MainThread): Parsing macros/etc/query.sql
2020-10-27 18:41:33,903614 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 18:41:33,905689 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 18:41:33,908196 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 18:41:33,916419 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 18:41:33,918760 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 18:41:33,943964 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 18:41:33,945381 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 18:41:33,946649 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 18:41:33,947905 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 18:41:33,950110 (MainThread): Parsing macros/catalog.sql
2020-10-27 18:41:33,951777 (MainThread): Parsing macros/relations.sql
2020-10-27 18:41:33,953155 (MainThread): Parsing macros/adapters.sql
2020-10-27 18:41:33,961243 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 18:41:33,979028 (MainThread): Partial parsing not enabled
2020-10-27 18:41:33,992515 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:41:33,992656 (MainThread): Opening a new connection, currently in state init
2020-10-27 18:41:34,2754 (MainThread): Got an error when attempting to open a postgres connection: 'FATAL:  password authentication failed for user "airflow"
'
2020-10-27 18:41:34,3048 (MainThread): On None: No close available on handle
2020-10-27 18:41:34,3348 (MainThread): ERROR: Database Error
  FATAL:  password authentication failed for user "airflow"
  
2020-10-27 18:41:34,3573 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11914e910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a73e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a733d0>]}
2020-10-27 18:41:34,539502 (MainThread): Flushing usage events
2020-10-27 18:41:34,539719 (MainThread): Connection 'None' was properly closed.
2020-10-27 18:42:27,97966 (MainThread): Running with dbt=0.15.0
2020-10-27 18:42:27,169118 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-27 18:42:27,169554 (MainThread): Tracking: tracking
2020-10-27 18:42:27,180871 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1156ec640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11571e9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11571eac0>]}
2020-10-27 18:42:27,967312 (MainThread): Partial parsing not enabled
2020-10-27 18:42:27,968973 (MainThread): Parsing macros/core.sql
2020-10-27 18:42:27,972414 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 18:42:27,978022 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 18:42:27,979423 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 18:42:27,988467 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 18:42:28,3477 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 18:42:28,17123 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 18:42:28,18669 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 18:42:28,23848 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 18:42:28,29775 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 18:42:28,34720 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 18:42:28,39409 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 18:42:28,43388 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 18:42:28,44230 (MainThread): Parsing macros/etc/query.sql
2020-10-27 18:42:28,45183 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 18:42:28,46592 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 18:42:28,48403 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 18:42:28,55271 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 18:42:28,57066 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 18:42:28,78466 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 18:42:28,79491 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 18:42:28,80307 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 18:42:28,81238 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 18:42:28,83223 (MainThread): Parsing macros/catalog.sql
2020-10-27 18:42:28,84521 (MainThread): Parsing macros/relations.sql
2020-10-27 18:42:28,85520 (MainThread): Parsing macros/adapters.sql
2020-10-27 18:42:28,92790 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 18:42:28,109955 (MainThread): Partial parsing not enabled
2020-10-27 18:42:28,123007 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:28,123150 (MainThread): Opening a new connection, currently in state init
2020-10-27 18:42:28,132061 (MainThread): Got an error when attempting to open a postgres connection: 'FATAL:  password authentication failed for user "airflow"
'
2020-10-27 18:42:28,132293 (MainThread): On None: No close available on handle
2020-10-27 18:42:28,132586 (MainThread): ERROR: Database Error
  FATAL:  password authentication failed for user "airflow"
  
2020-10-27 18:42:28,132811 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115700700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11580a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11580ad30>]}
2020-10-27 18:42:28,637294 (MainThread): Flushing usage events
2020-10-27 18:42:28,637504 (MainThread): Connection 'None' was properly closed.
2020-10-27 18:42:35,397474 (MainThread): Running with dbt=0.15.0
2020-10-27 18:42:35,557285 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-27 18:42:35,557996 (MainThread): Tracking: tracking
2020-10-27 18:42:35,570152 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab6fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aba7dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abe6310>]}
2020-10-27 18:42:36,97420 (MainThread): Partial parsing not enabled
2020-10-27 18:42:36,99108 (MainThread): Parsing macros/core.sql
2020-10-27 18:42:36,102552 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 18:42:36,108235 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 18:42:36,109693 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 18:42:36,119120 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 18:42:36,134177 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 18:42:36,148367 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 18:42:36,149970 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 18:42:36,155296 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 18:42:36,161118 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 18:42:36,166445 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 18:42:36,171277 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 18:42:36,175329 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 18:42:36,176189 (MainThread): Parsing macros/etc/query.sql
2020-10-27 18:42:36,177166 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 18:42:36,178625 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 18:42:36,180394 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 18:42:36,187179 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 18:42:36,188884 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 18:42:36,210756 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 18:42:36,211832 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 18:42:36,212685 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 18:42:36,213645 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 18:42:36,215538 (MainThread): Parsing macros/catalog.sql
2020-10-27 18:42:36,216911 (MainThread): Parsing macros/relations.sql
2020-10-27 18:42:36,217947 (MainThread): Parsing macros/adapters.sql
2020-10-27 18:42:36,225661 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 18:42:36,242742 (MainThread): Partial parsing not enabled
2020-10-27 18:42:36,255229 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:36,255350 (MainThread): Opening a new connection, currently in state init
2020-10-27 18:42:36,285344 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-27 18:42:36,285477 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-27 18:42:36,312190 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:42:36,312322 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_incremental).
2020-10-27 18:42:36,325386 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:42:36,325506 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-27 18:42:37,37582 (MainThread): scipy not found, skipping conversion test.
2020-10-27 18:42:37,39726 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 18:42:37,41589 (MainThread): 
2020-10-27 18:42:37,41879 (MainThread): Acquiring new postgres connection "master".
2020-10-27 18:42:37,41963 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_incremental_country).
2020-10-27 18:42:37,123803 (MainThread): Using postgres connection "master".
2020-10-27 18:42:37,123943 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-10-27 18:42:37,130434 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-10-27 18:42:37,153479 (MainThread): Using postgres connection "master".
2020-10-27 18:42:37,153613 (MainThread): On master: BEGIN
2020-10-27 18:42:37,155402 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:42:37,155586 (MainThread): Using postgres connection "master".
2020-10-27 18:42:37,155672 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 18:42:37,199730 (MainThread): SQL status: SELECT 2 in 0.04 seconds
2020-10-27 18:42:37,218118 (MainThread): Using postgres connection "master".
2020-10-27 18:42:37,218248 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 18:42:37,269598 (MainThread): SQL status: SELECT 0 in 0.05 seconds
2020-10-27 18:42:37,270557 (MainThread): On master: ROLLBACK
2020-10-27 18:42:37,271887 (MainThread): Using postgres connection "master".
2020-10-27 18:42:37,271994 (MainThread): On master: BEGIN
2020-10-27 18:42:37,274309 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:42:37,274475 (MainThread): On master: COMMIT
2020-10-27 18:42:37,274579 (MainThread): Using postgres connection "master".
2020-10-27 18:42:37,274660 (MainThread): On master: COMMIT
2020-10-27 18:42:37,275780 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 18:42:37,276114 (MainThread): 18:42:37 | Concurrency: 4 threads (target='dev')
2020-10-27 18:42:37,276237 (MainThread): 18:42:37 | 
2020-10-27 18:42:37,279568 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-27 18:42:37,279867 (Thread-2): Began running node model.my_new_project.covid19_stats_incremental
2020-10-27 18:42:37,280034 (Thread-1): 18:42:37 | 1 of 2 START view model public.covid19_stats......................... [RUN]
2020-10-27 18:42:37,280179 (Thread-2): 18:42:37 | 2 of 2 START incremental model public.covid19_stats_incremental...... [RUN]
2020-10-27 18:42:37,280492 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,280624 (Thread-1): Opening a new connection, currently in state init
2020-10-27 18:42:37,280857 (Thread-2): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-27 18:42:37,281061 (Thread-2): Opening a new connection, currently in state init
2020-10-27 18:42:37,294759 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-27 18:42:37,302011 (Thread-2): Compiling model.my_new_project.covid19_stats_incremental
2020-10-27 18:42:37,308366 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-27 18:42:37,314115 (Thread-2): Writing injected SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-27 18:42:37,314793 (Thread-1): finished collecting timing info
2020-10-27 18:42:37,320499 (Thread-2): finished collecting timing info
2020-10-27 18:42:37,372508 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,378057 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "covid19"."public"."covid19_stats__dbt_tmp" cascade
2020-10-27 18:42:37,385961 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-27 18:42:37,393852 (Thread-2): Writing runtime SQL for node "model.my_new_project.covid19_stats_incremental"
2020-10-27 18:42:37,396093 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,396391 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop table if exists "covid19"."public"."covid19_stats__dbt_backup" cascade
2020-10-27 18:42:37,396764 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-27 18:42:37,396862 (Thread-2): On model.my_new_project.covid19_stats_incremental: BEGIN
2020-10-27 18:42:37,401628 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2020-10-27 18:42:37,403317 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-27 18:42:37,403875 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,404001 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-27 18:42:37,404350 (Thread-2): SQL status: BEGIN in 0.01 seconds
2020-10-27 18:42:37,404464 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-27 18:42:37,404542 (Thread-2): On model.my_new_project.covid19_stats_incremental: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_incremental"} */

      create  table "covid19"."public"."covid19_stats_incremental"
  as (
    SELECT data #>> '{Country}' as country,
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19




GROUP BY country, day
  );
  
2020-10-27 18:42:37,406348 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:42:37,406540 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,406673 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
create view "covid19"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-27 18:42:37,439792 (Thread-2): SQL status: SELECT 0 in 0.04 seconds
2020-10-27 18:42:37,441014 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-27 18:42:37,441176 (Thread-2): Using postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-27 18:42:37,441266 (Thread-2): On model.my_new_project.covid19_stats_incremental: COMMIT
2020-10-27 18:42:37,450263 (Thread-2): SQL status: COMMIT in 0.01 seconds
2020-10-27 18:42:37,451986 (Thread-2): finished collecting timing info
2020-10-27 18:42:37,452706 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18dc3c5f-e9ca-4a81-9817-83f57fae95e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11541c4f0>]}
2020-10-27 18:42:37,453137 (Thread-1): SQL status: CREATE VIEW in 0.05 seconds
2020-10-27 18:42:37,457780 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,458054 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "covid19"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-27 18:42:37,460810 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-27 18:42:37,463339 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,463533 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "covid19"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-27 18:42:37,465547 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-27 18:42:37,466526 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-27 18:42:37,466653 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,466736 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-27 18:42:37,469794 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-27 18:42:37,471619 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:42:37,471780 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop table if exists "covid19"."public"."covid19_stats__dbt_backup" cascade
2020-10-27 18:42:37,529213 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2020-10-27 18:42:37,531651 (Thread-1): finished collecting timing info
2020-10-27 18:42:37,532302 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18dc3c5f-e9ca-4a81-9817-83f57fae95e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11536c160>]}
2020-10-27 18:42:37,965162 (Thread-2): 18:42:37 | 2 of 2 OK created incremental model public.covid19_stats_incremental. [SELECT 0 in 0.17s]
2020-10-27 18:42:37,966059 (Thread-2): Finished running node model.my_new_project.covid19_stats_incremental
2020-10-27 18:42:38,465943 (Thread-1): 18:42:38 | 1 of 2 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.25s]
2020-10-27 18:42:38,466133 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-27 18:42:38,467610 (MainThread): Using postgres connection "master".
2020-10-27 18:42:38,467766 (MainThread): On master: BEGIN
2020-10-27 18:42:38,469639 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:42:38,469828 (MainThread): On master: COMMIT
2020-10-27 18:42:38,469920 (MainThread): Using postgres connection "master".
2020-10-27 18:42:38,469996 (MainThread): On master: COMMIT
2020-10-27 18:42:38,471993 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 18:42:38,472394 (MainThread): 18:42:38 | 
2020-10-27 18:42:38,472522 (MainThread): 18:42:38 | Finished running 1 incremental model, 1 view model in 1.43s.
2020-10-27 18:42:38,472619 (MainThread): Connection 'master' was left open.
2020-10-27 18:42:38,472698 (MainThread): On master: Close
2020-10-27 18:42:38,472814 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-27 18:42:38,472887 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-27 18:42:38,472979 (MainThread): Connection 'model.my_new_project.covid19_stats_incremental' was left open.
2020-10-27 18:42:38,473051 (MainThread): On model.my_new_project.covid19_stats_incremental: Close
2020-10-27 18:42:38,480006 (MainThread): 
2020-10-27 18:42:38,480232 (MainThread): Completed successfully
2020-10-27 18:42:38,480389 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-27 18:42:38,480594 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11563caf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11563cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11563cc70>]}
2020-10-27 18:42:38,995768 (MainThread): Flushing usage events
2020-10-27 18:43:02,600352 (MainThread): Running with dbt=0.15.0
2020-10-27 18:43:02,677386 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 18:43:02,677944 (MainThread): Tracking: tracking
2020-10-27 18:43:02,694556 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11828f9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1182c7d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1183042b0>]}
2020-10-27 18:43:03,231841 (MainThread): Partial parsing not enabled
2020-10-27 18:43:03,233565 (MainThread): Parsing macros/core.sql
2020-10-27 18:43:03,237067 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 18:43:03,243010 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 18:43:03,244448 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 18:43:03,253858 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 18:43:03,269269 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 18:43:03,283712 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 18:43:03,285385 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 18:43:03,290777 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 18:43:03,296709 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 18:43:03,301858 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 18:43:03,306777 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 18:43:03,310906 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 18:43:03,311795 (MainThread): Parsing macros/etc/query.sql
2020-10-27 18:43:03,312808 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 18:43:03,314293 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 18:43:03,316095 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 18:43:03,322869 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 18:43:03,324610 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 18:43:03,346731 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 18:43:03,347844 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 18:43:03,348728 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 18:43:03,349714 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 18:43:03,351641 (MainThread): Parsing macros/catalog.sql
2020-10-27 18:43:03,353010 (MainThread): Parsing macros/relations.sql
2020-10-27 18:43:03,354072 (MainThread): Parsing macros/adapters.sql
2020-10-27 18:43:03,361824 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 18:43:03,379856 (MainThread): Partial parsing not enabled
2020-10-27 18:43:03,392922 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:43:03,393058 (MainThread): Opening a new connection, currently in state init
2020-10-27 18:43:03,419156 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-27 18:43:03,419294 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-27 18:43:03,445601 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:43:03,445739 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_incremental).
2020-10-27 18:43:03,458750 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:43:03,458877 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-27 18:43:03,684733 (MainThread): scipy not found, skipping conversion test.
2020-10-27 18:43:03,687174 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 18:43:03,689499 (MainThread): 
2020-10-27 18:43:03,689895 (MainThread): Acquiring new postgres connection "master".
2020-10-27 18:43:03,689997 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_incremental_country).
2020-10-27 18:43:03,794399 (MainThread): Using postgres connection "master".
2020-10-27 18:43:03,794636 (MainThread): On master: BEGIN
2020-10-27 18:43:03,805243 (MainThread): SQL status: BEGIN in 0.01 seconds
2020-10-27 18:43:03,805586 (MainThread): Using postgres connection "master".
2020-10-27 18:43:03,805702 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 18:43:03,818405 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-27 18:43:03,843572 (MainThread): Using postgres connection "master".
2020-10-27 18:43:03,843708 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 18:43:03,855509 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 18:43:03,857302 (MainThread): On master: ROLLBACK
2020-10-27 18:43:03,858592 (MainThread): 18:43:03 | Concurrency: 4 threads (target='dev')
2020-10-27 18:43:03,858736 (MainThread): 18:43:03 | 
2020-10-27 18:43:03,861577 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:43:03,861718 (Thread-2): Began running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-27 18:43:03,861893 (Thread-1): 18:43:03 | 1 of 2 START test not_null_covid19_stats_country..................... [RUN]
2020-10-27 18:43:03,862028 (Thread-2): 18:43:03 | 2 of 2 START test not_null_covid19_stats_incremental_country......... [RUN]
2020-10-27 18:43:03,862339 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:43:03,862588 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:43:03,862688 (Thread-1): Opening a new connection, currently in state init
2020-10-27 18:43:03,862783 (Thread-2): Opening a new connection, currently in state init
2020-10-27 18:43:03,875597 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:43:03,875764 (Thread-2): Compiling test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-27 18:43:03,890356 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-27 18:43:03,897189 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_incremental_country"
2020-10-27 18:43:03,897678 (Thread-1): finished collecting timing info
2020-10-27 18:43:03,897944 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:43:03,898044 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-27 18:43:03,898186 (Thread-2): finished collecting timing info
2020-10-27 18:43:03,898489 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:43:03,898584 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: BEGIN
2020-10-27 18:43:03,901145 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:43:03,901289 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:43:03,901386 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:43:03,901519 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:43:03,901639 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_incremental_country"} */




select count(*)
from "covid19"."public"."covid19_stats_incremental"
where country is null

2020-10-27 18:43:03,901737 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "covid19"."public"."covid19_stats"
where country is null

2020-10-27 18:43:03,912951 (Thread-2): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 18:43:03,913301 (Thread-2): finished collecting timing info
2020-10-27 18:43:03,913582 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: ROLLBACK
2020-10-27 18:43:03,914425 (Thread-1): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 18:43:03,914747 (Thread-1): finished collecting timing info
2020-10-27 18:43:03,915025 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-27 18:43:03,915413 (Thread-2): 18:43:03 | 2 of 2 PASS not_null_covid19_stats_incremental_country............... [PASS in 0.05s]
2020-10-27 18:43:03,915564 (Thread-2): Finished running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-27 18:43:03,916760 (Thread-1): 18:43:03 | 1 of 2 PASS not_null_covid19_stats_country........................... [PASS in 0.05s]
2020-10-27 18:43:03,916930 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:43:03,918225 (MainThread): 18:43:03 | 
2020-10-27 18:43:03,918367 (MainThread): 18:43:03 | Finished running 2 tests in 0.23s.
2020-10-27 18:43:03,918462 (MainThread): Connection 'master' was left open.
2020-10-27 18:43:03,918608 (MainThread): On master: Close
2020-10-27 18:43:03,918745 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-27 18:43:03,918905 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-27 18:43:03,919221 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was left open.
2020-10-27 18:43:03,919403 (MainThread): On test.my_new_project.not_null_covid19_stats_incremental_country: Close
2020-10-27 18:43:03,931300 (MainThread): 
2020-10-27 18:43:03,931463 (MainThread): Completed successfully
2020-10-27 18:43:03,931585 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-27 18:43:03,931788 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a99ce20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a99ceb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a99cf10>]}
2020-10-27 18:43:04,433832 (MainThread): Flushing usage events
2020-10-27 18:50:46,106083 (MainThread): Running with dbt=0.15.0
2020-10-27 18:50:46,189348 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 18:50:46,190003 (MainThread): Tracking: tracking
2020-10-27 18:50:46,201776 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f13cf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f175e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1b23a0>]}
2020-10-27 18:50:47,80070 (MainThread): Partial parsing not enabled
2020-10-27 18:50:47,81985 (MainThread): Parsing macros/core.sql
2020-10-27 18:50:47,85857 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 18:50:47,92276 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 18:50:47,93938 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 18:50:47,103462 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 18:50:47,118659 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 18:50:47,133567 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 18:50:47,135573 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 18:50:47,141215 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 18:50:47,147831 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 18:50:47,153383 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 18:50:47,158815 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 18:50:47,163358 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 18:50:47,164418 (MainThread): Parsing macros/etc/query.sql
2020-10-27 18:50:47,165862 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 18:50:47,167601 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 18:50:47,169661 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 18:50:47,176772 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 18:50:47,178714 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 18:50:47,201253 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 18:50:47,202602 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 18:50:47,203705 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 18:50:47,204862 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 18:50:47,207077 (MainThread): Parsing macros/catalog.sql
2020-10-27 18:50:47,208741 (MainThread): Parsing macros/relations.sql
2020-10-27 18:50:47,210070 (MainThread): Parsing macros/adapters.sql
2020-10-27 18:50:47,218157 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 18:50:47,236036 (MainThread): Partial parsing not enabled
2020-10-27 18:50:47,249616 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:50:47,249741 (MainThread): Opening a new connection, currently in state init
2020-10-27 18:50:47,276332 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_incremental".
2020-10-27 18:50:47,276460 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-27 18:50:47,303224 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:50:47,303359 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_incremental).
2020-10-27 18:50:47,316655 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:50:47,316776 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-27 18:50:48,2350 (MainThread): scipy not found, skipping conversion test.
2020-10-27 18:50:48,4420 (MainThread): Found 2 models, 2 tests, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 18:50:48,6464 (MainThread): 
2020-10-27 18:50:48,6776 (MainThread): Acquiring new postgres connection "master".
2020-10-27 18:50:48,6862 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_incremental_country).
2020-10-27 18:50:48,104315 (MainThread): Using postgres connection "master".
2020-10-27 18:50:48,104453 (MainThread): On master: BEGIN
2020-10-27 18:50:48,108153 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:50:48,108325 (MainThread): Using postgres connection "master".
2020-10-27 18:50:48,108413 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 18:50:48,119245 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-27 18:50:48,144711 (MainThread): Using postgres connection "master".
2020-10-27 18:50:48,144843 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 18:50:48,157672 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 18:50:48,159466 (MainThread): On master: ROLLBACK
2020-10-27 18:50:48,160810 (MainThread): 18:50:48 | Concurrency: 4 threads (target='dev')
2020-10-27 18:50:48,160953 (MainThread): 18:50:48 | 
2020-10-27 18:50:48,164409 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:50:48,164552 (Thread-2): Began running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-27 18:50:48,164712 (Thread-1): 18:50:48 | 1 of 2 START test not_null_covid19_stats_country..................... [RUN]
2020-10-27 18:50:48,164843 (Thread-2): 18:50:48 | 2 of 2 START test not_null_covid19_stats_incremental_country......... [RUN]
2020-10-27 18:50:48,165134 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:50:48,165421 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:50:48,165549 (Thread-1): Opening a new connection, currently in state init
2020-10-27 18:50:48,165652 (Thread-2): Opening a new connection, currently in state init
2020-10-27 18:50:48,178135 (Thread-2): Compiling test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-27 18:50:48,185364 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:50:48,192984 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_incremental_country"
2020-10-27 18:50:48,199928 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-27 18:50:48,200339 (Thread-2): finished collecting timing info
2020-10-27 18:50:48,200607 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:50:48,200693 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: BEGIN
2020-10-27 18:50:48,200817 (Thread-1): finished collecting timing info
2020-10-27 18:50:48,201088 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:50:48,201172 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-27 18:50:48,203974 (Thread-2): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:50:48,204149 (Thread-2): Using postgres connection "test.my_new_project.not_null_covid19_stats_incremental_country".
2020-10-27 18:50:48,204236 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_incremental_country"} */




select count(*)
from "covid19"."public"."covid19_stats_incremental"
where country is null

2020-10-27 18:50:48,204545 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:50:48,204692 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:50:48,204789 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "covid19"."public"."covid19_stats"
where country is null

2020-10-27 18:50:48,207255 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2020-10-27 18:50:48,207600 (Thread-2): finished collecting timing info
2020-10-27 18:50:48,207870 (Thread-2): On test.my_new_project.not_null_covid19_stats_incremental_country: ROLLBACK
2020-10-27 18:50:48,209337 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-27 18:50:48,209691 (Thread-2): 18:50:48 | 2 of 2 PASS not_null_covid19_stats_incremental_country............... [PASS in 0.04s]
2020-10-27 18:50:48,209965 (Thread-1): finished collecting timing info
2020-10-27 18:50:48,210237 (Thread-2): Finished running node test.my_new_project.not_null_covid19_stats_incremental_country
2020-10-27 18:50:48,210355 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-27 18:50:48,212074 (Thread-1): 18:50:48 | 1 of 2 PASS not_null_covid19_stats_country........................... [PASS in 0.05s]
2020-10-27 18:50:48,212243 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:50:48,213461 (MainThread): 18:50:48 | 
2020-10-27 18:50:48,213606 (MainThread): 18:50:48 | Finished running 2 tests in 0.21s.
2020-10-27 18:50:48,213700 (MainThread): Connection 'master' was left open.
2020-10-27 18:50:48,213774 (MainThread): On master: Close
2020-10-27 18:50:48,213888 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-27 18:50:48,213962 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-27 18:50:48,214088 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_incremental_country' was left open.
2020-10-27 18:50:48,214194 (MainThread): On test.my_new_project.not_null_covid19_stats_incremental_country: Close
2020-10-27 18:50:48,221129 (MainThread): 
2020-10-27 18:50:48,221293 (MainThread): Completed successfully
2020-10-27 18:50:48,221397 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-10-27 18:50:48,221650 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bb06f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b802eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b802be0>]}
2020-10-27 18:50:49,108672 (MainThread): Flushing usage events
2020-10-27 18:55:58,562676 (MainThread): Running with dbt=0.15.0
2020-10-27 18:55:58,642936 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 18:55:58,643657 (MainThread): Tracking: tracking
2020-10-27 18:55:58,656090 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1153bdca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1153f9dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115407220>]}
2020-10-27 18:56:00,393475 (MainThread): Partial parsing not enabled
2020-10-27 18:56:00,396012 (MainThread): Parsing macros/core.sql
2020-10-27 18:56:00,399948 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 18:56:00,406454 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 18:56:00,408166 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 18:56:00,418875 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 18:56:00,435976 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 18:56:00,451405 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 18:56:00,453275 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 18:56:00,459366 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 18:56:00,465998 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 18:56:00,472064 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 18:56:00,477421 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 18:56:00,482335 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 18:56:00,483486 (MainThread): Parsing macros/etc/query.sql
2020-10-27 18:56:00,484691 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 18:56:00,486486 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 18:56:00,488738 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 18:56:00,496697 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 18:56:00,498736 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 18:56:00,522347 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 18:56:00,523872 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 18:56:00,524993 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 18:56:00,526184 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 18:56:00,529072 (MainThread): Parsing macros/catalog.sql
2020-10-27 18:56:00,530892 (MainThread): Parsing macros/relations.sql
2020-10-27 18:56:00,532299 (MainThread): Parsing macros/adapters.sql
2020-10-27 18:56:00,540628 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 18:56:00,559568 (MainThread): Partial parsing not enabled
2020-10-27 18:56:00,573413 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 18:56:00,573567 (MainThread): Opening a new connection, currently in state init
2020-10-27 18:56:00,618505 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:56:00,618651 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-27 18:56:01,324897 (MainThread): scipy not found, skipping conversion test.
2020-10-27 18:56:01,326384 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 18:56:01,328615 (MainThread): 
2020-10-27 18:56:01,328977 (MainThread): Acquiring new postgres connection "master".
2020-10-27 18:56:01,329080 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-27 18:56:01,422501 (MainThread): Using postgres connection "master".
2020-10-27 18:56:01,422691 (MainThread): On master: BEGIN
2020-10-27 18:56:01,425385 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:56:01,425565 (MainThread): Using postgres connection "master".
2020-10-27 18:56:01,425657 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 18:56:01,434098 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-27 18:56:01,454075 (MainThread): Using postgres connection "master".
2020-10-27 18:56:01,454224 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 18:56:01,462891 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 18:56:01,464822 (MainThread): On master: ROLLBACK
2020-10-27 18:56:01,466271 (MainThread): 18:56:01 | Concurrency: 4 threads (target='dev')
2020-10-27 18:56:01,466421 (MainThread): 18:56:01 | 
2020-10-27 18:56:01,470866 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:56:01,471065 (Thread-1): 18:56:01 | 1 of 1 START test not_null_covid19_stats_country..................... [RUN]
2020-10-27 18:56:01,471349 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:56:01,471444 (Thread-1): Opening a new connection, currently in state init
2020-10-27 18:56:01,483851 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:56:01,499592 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-27 18:56:01,500005 (Thread-1): finished collecting timing info
2020-10-27 18:56:01,500287 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:56:01,500397 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-27 18:56:01,503498 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 18:56:01,503681 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 18:56:01,503773 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "covid19"."public"."covid19_stats"
where country is null

2020-10-27 18:56:01,508344 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-27 18:56:01,508687 (Thread-1): finished collecting timing info
2020-10-27 18:56:01,508957 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-27 18:56:01,510296 (Thread-1): 18:56:01 | 1 of 1 PASS not_null_covid19_stats_country........................... [PASS in 0.04s]
2020-10-27 18:56:01,510476 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 18:56:01,512140 (MainThread): 18:56:01 | 
2020-10-27 18:56:01,512400 (MainThread): 18:56:01 | Finished running 1 test in 0.18s.
2020-10-27 18:56:01,512568 (MainThread): Connection 'master' was left open.
2020-10-27 18:56:01,512667 (MainThread): On master: Close
2020-10-27 18:56:01,512792 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-27 18:56:01,512870 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-27 18:56:01,516139 (MainThread): 
2020-10-27 18:56:01,516327 (MainThread): Completed successfully
2020-10-27 18:56:01,516491 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-27 18:56:01,516676 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117db82b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117db8310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117db82e0>]}
2020-10-27 18:56:02,25538 (MainThread): Flushing usage events
2020-10-27 19:09:04,794948 (MainThread): Running with dbt=0.15.0
2020-10-27 19:09:04,880085 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-27 19:09:04,888142 (MainThread): Tracking: tracking
2020-10-27 19:09:04,909858 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d570f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d9697c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d977130>]}
2020-10-27 19:09:05,605887 (MainThread): Partial parsing not enabled
2020-10-27 19:09:05,608186 (MainThread): Parsing macros/core.sql
2020-10-27 19:09:05,611924 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 19:09:05,618073 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 19:09:05,619748 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 19:09:05,629526 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 19:09:05,644984 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 19:09:05,660567 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 19:09:05,662874 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 19:09:05,669246 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 19:09:05,675490 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 19:09:05,680930 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 19:09:05,685961 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 19:09:05,690371 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 19:09:05,691635 (MainThread): Parsing macros/etc/query.sql
2020-10-27 19:09:05,692883 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 19:09:05,694489 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 19:09:05,696664 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 19:09:05,703850 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 19:09:05,705816 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 19:09:05,728192 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 19:09:05,729554 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 19:09:05,730698 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 19:09:05,731983 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 19:09:05,734299 (MainThread): Parsing macros/catalog.sql
2020-10-27 19:09:05,735916 (MainThread): Parsing macros/relations.sql
2020-10-27 19:09:05,737330 (MainThread): Parsing macros/adapters.sql
2020-10-27 19:09:05,745287 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 19:09:05,763897 (MainThread): Partial parsing not enabled
2020-10-27 19:09:05,778111 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:05,778250 (MainThread): Opening a new connection, currently in state init
2020-10-27 19:09:05,822502 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 19:09:05,822644 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-27 19:09:06,438255 (MainThread): scipy not found, skipping conversion test.
2020-10-27 19:09:06,439840 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 19:09:06,441787 (MainThread): 
2020-10-27 19:09:06,442114 (MainThread): Acquiring new postgres connection "master".
2020-10-27 19:09:06,442210 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-27 19:09:06,523793 (MainThread): Using postgres connection "master".
2020-10-27 19:09:06,523951 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-10-27 19:09:06,529522 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-10-27 19:09:06,547773 (MainThread): Using postgres connection "master".
2020-10-27 19:09:06,547915 (MainThread): On master: BEGIN
2020-10-27 19:09:06,549606 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 19:09:06,549758 (MainThread): Using postgres connection "master".
2020-10-27 19:09:06,549843 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 19:09:06,564935 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-27 19:09:06,578204 (MainThread): Using postgres connection "master".
2020-10-27 19:09:06,578341 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 19:09:06,644124 (MainThread): SQL status: SELECT 1 in 0.07 seconds
2020-10-27 19:09:06,646159 (MainThread): On master: ROLLBACK
2020-10-27 19:09:06,647620 (MainThread): Using postgres connection "master".
2020-10-27 19:09:06,647807 (MainThread): On master: BEGIN
2020-10-27 19:09:06,650134 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 19:09:06,650319 (MainThread): On master: COMMIT
2020-10-27 19:09:06,650419 (MainThread): Using postgres connection "master".
2020-10-27 19:09:06,650500 (MainThread): On master: COMMIT
2020-10-27 19:09:06,651602 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 19:09:06,651915 (MainThread): 19:09:06 | Concurrency: 4 threads (target='dev')
2020-10-27 19:09:06,652041 (MainThread): 19:09:06 | 
2020-10-27 19:09:06,655087 (Thread-1): Began running node model.my_new_project.covid19_stats
2020-10-27 19:09:06,655266 (Thread-1): 19:09:06 | 1 of 1 START view model public.covid19_stats......................... [RUN]
2020-10-27 19:09:06,656023 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,656128 (Thread-1): Opening a new connection, currently in state init
2020-10-27 19:09:06,666462 (Thread-1): Compiling model.my_new_project.covid19_stats
2020-10-27 19:09:06,679228 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats"
2020-10-27 19:09:06,679912 (Thread-1): finished collecting timing info
2020-10-27 19:09:06,710228 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,710378 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "covid19"."public"."covid19_stats__dbt_tmp" cascade
2020-10-27 19:09:06,719356 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-10-27 19:09:06,721601 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,721711 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "covid19"."public"."covid19_stats__dbt_backup" cascade
2020-10-27 19:09:06,722929 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-27 19:09:06,724392 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats"
2020-10-27 19:09:06,724842 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,724932 (Thread-1): On model.my_new_project.covid19_stats: BEGIN
2020-10-27 19:09:06,726111 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 19:09:06,726260 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,726351 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
create view "covid19"."public"."covid19_stats__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-27 19:09:06,817028 (Thread-1): SQL status: CREATE VIEW in 0.09 seconds
2020-10-27 19:09:06,820569 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,820685 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "covid19"."public"."covid19_stats" rename to "covid19_stats__dbt_backup"
2020-10-27 19:09:06,822311 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-27 19:09:06,824532 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,824638 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
alter table "covid19"."public"."covid19_stats__dbt_tmp" rename to "covid19_stats"
2020-10-27 19:09:06,825909 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-27 19:09:06,826829 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-27 19:09:06,826947 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,827028 (Thread-1): On model.my_new_project.covid19_stats: COMMIT
2020-10-27 19:09:06,830445 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-27 19:09:06,832183 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:06,832283 (Thread-1): On model.my_new_project.covid19_stats: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats"} */
drop view if exists "covid19"."public"."covid19_stats__dbt_backup" cascade
2020-10-27 19:09:06,902376 (Thread-1): SQL status: DROP VIEW in 0.07 seconds
2020-10-27 19:09:06,904774 (Thread-1): finished collecting timing info
2020-10-27 19:09:06,905479 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e18e6f5-7ef7-4ec0-bf8a-d1b1375290d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1200fd160>]}
2020-10-27 19:09:07,414702 (Thread-1): 19:09:07 | 1 of 1 OK created view model public.covid19_stats.................... [CREATE VIEW in 0.25s]
2020-10-27 19:09:07,414875 (Thread-1): Finished running node model.my_new_project.covid19_stats
2020-10-27 19:09:07,416026 (MainThread): Using postgres connection "master".
2020-10-27 19:09:07,416124 (MainThread): On master: BEGIN
2020-10-27 19:09:07,417605 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 19:09:07,417802 (MainThread): On master: COMMIT
2020-10-27 19:09:07,417896 (MainThread): Using postgres connection "master".
2020-10-27 19:09:07,417971 (MainThread): On master: COMMIT
2020-10-27 19:09:07,419233 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 19:09:07,419640 (MainThread): 19:09:07 | 
2020-10-27 19:09:07,419837 (MainThread): 19:09:07 | Finished running 1 view model in 0.98s.
2020-10-27 19:09:07,419953 (MainThread): Connection 'master' was left open.
2020-10-27 19:09:07,420053 (MainThread): On master: Close
2020-10-27 19:09:07,420152 (MainThread): Connection 'model.my_new_project.covid19_stats' was left open.
2020-10-27 19:09:07,420225 (MainThread): On model.my_new_project.covid19_stats: Close
2020-10-27 19:09:07,424597 (MainThread): 
2020-10-27 19:09:07,424790 (MainThread): Completed successfully
2020-10-27 19:09:07,425592 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-27 19:09:07,425847 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120409550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1204092b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1204090a0>]}
2020-10-27 19:09:07,930204 (MainThread): Flushing usage events
2020-10-27 19:09:48,192325 (MainThread): Running with dbt=0.15.0
2020-10-27 19:09:48,264259 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 19:09:48,264694 (MainThread): Tracking: tracking
2020-10-27 19:09:48,276591 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c810d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc0c700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc18220>]}
2020-10-27 19:09:48,815215 (MainThread): Partial parsing not enabled
2020-10-27 19:09:48,817244 (MainThread): Parsing macros/core.sql
2020-10-27 19:09:48,820823 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 19:09:48,826887 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 19:09:48,828301 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 19:09:48,837716 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 19:09:48,852694 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 19:09:48,866819 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 19:09:48,868506 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 19:09:48,873764 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 19:09:48,879727 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 19:09:48,884731 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 19:09:48,889682 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 19:09:48,893731 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 19:09:48,894588 (MainThread): Parsing macros/etc/query.sql
2020-10-27 19:09:48,895722 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 19:09:48,897409 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 19:09:48,899229 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 19:09:48,906062 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 19:09:48,907874 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 19:09:48,930001 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 19:09:48,931155 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 19:09:48,932118 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 19:09:48,933236 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 19:09:48,935153 (MainThread): Parsing macros/catalog.sql
2020-10-27 19:09:48,936492 (MainThread): Parsing macros/relations.sql
2020-10-27 19:09:48,937574 (MainThread): Parsing macros/adapters.sql
2020-10-27 19:09:48,945204 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 19:09:48,962804 (MainThread): Partial parsing not enabled
2020-10-27 19:09:48,975642 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats".
2020-10-27 19:09:48,975781 (MainThread): Opening a new connection, currently in state init
2020-10-27 19:09:49,23827 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 19:09:49,24004 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats).
2020-10-27 19:09:49,245346 (MainThread): scipy not found, skipping conversion test.
2020-10-27 19:09:49,246695 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 19:09:49,248557 (MainThread): 
2020-10-27 19:09:49,248858 (MainThread): Acquiring new postgres connection "master".
2020-10-27 19:09:49,248949 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_country).
2020-10-27 19:09:49,337775 (MainThread): Using postgres connection "master".
2020-10-27 19:09:49,337925 (MainThread): On master: BEGIN
2020-10-27 19:09:49,340839 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 19:09:49,341000 (MainThread): Using postgres connection "master".
2020-10-27 19:09:49,341119 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 19:09:49,352040 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-27 19:09:49,372896 (MainThread): Using postgres connection "master".
2020-10-27 19:09:49,373062 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 19:09:49,382867 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 19:09:49,384954 (MainThread): On master: ROLLBACK
2020-10-27 19:09:49,386809 (MainThread): 19:09:49 | Concurrency: 4 threads (target='dev')
2020-10-27 19:09:49,386999 (MainThread): 19:09:49 | 
2020-10-27 19:09:49,390482 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 19:09:49,390710 (Thread-1): 19:09:49 | 1 of 1 START test not_null_covid19_stats_country..................... [RUN]
2020-10-27 19:09:49,391032 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 19:09:49,391155 (Thread-1): Opening a new connection, currently in state init
2020-10-27 19:09:49,403089 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_country
2020-10-27 19:09:49,418954 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_country"
2020-10-27 19:09:49,419472 (Thread-1): finished collecting timing info
2020-10-27 19:09:49,419819 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 19:09:49,419918 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: BEGIN
2020-10-27 19:09:49,422912 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 19:09:49,423100 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_country".
2020-10-27 19:09:49,423195 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_country"} */




select count(*)
from "covid19"."public"."covid19_stats"
where country is null

2020-10-27 19:09:49,428305 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-27 19:09:49,428679 (Thread-1): finished collecting timing info
2020-10-27 19:09:49,429035 (Thread-1): On test.my_new_project.not_null_covid19_stats_country: ROLLBACK
2020-10-27 19:09:49,430856 (Thread-1): 19:09:49 | 1 of 1 PASS not_null_covid19_stats_country........................... [PASS in 0.04s]
2020-10-27 19:09:49,431055 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_country
2020-10-27 19:09:49,433022 (MainThread): 19:09:49 | 
2020-10-27 19:09:49,433192 (MainThread): 19:09:49 | Finished running 1 test in 0.18s.
2020-10-27 19:09:49,433298 (MainThread): Connection 'master' was left open.
2020-10-27 19:09:49,433378 (MainThread): On master: Close
2020-10-27 19:09:49,433537 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_country' was left open.
2020-10-27 19:09:49,433619 (MainThread): On test.my_new_project.not_null_covid19_stats_country: Close
2020-10-27 19:09:49,437012 (MainThread): 
2020-10-27 19:09:49,437193 (MainThread): Completed successfully
2020-10-27 19:09:49,437308 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-27 19:09:49,437493 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b35b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b35b520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b35b280>]}
2020-10-27 19:09:49,946293 (MainThread): Flushing usage events
2020-10-27 21:30:51,546642 (MainThread): Running with dbt=0.15.0
2020-10-27 21:30:51,623531 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-27 21:30:51,636323 (MainThread): Tracking: tracking
2020-10-27 21:30:51,649843 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b169ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b564760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b5702e0>]}
2020-10-27 21:30:53,346418 (MainThread): Partial parsing not enabled
2020-10-27 21:30:53,349036 (MainThread): Parsing macros/core.sql
2020-10-27 21:30:53,354924 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 21:30:53,361183 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 21:30:53,363036 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 21:30:53,372824 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 21:30:53,388102 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 21:30:53,402342 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 21:30:53,404232 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 21:30:53,409695 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 21:30:53,416804 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 21:30:53,422564 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 21:30:53,427797 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 21:30:53,432262 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 21:30:53,433434 (MainThread): Parsing macros/etc/query.sql
2020-10-27 21:30:53,434617 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 21:30:53,436370 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 21:30:53,438488 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 21:30:53,445508 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 21:30:53,447571 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 21:30:53,470441 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 21:30:53,471881 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 21:30:53,473145 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 21:30:53,474470 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 21:30:53,476874 (MainThread): Parsing macros/catalog.sql
2020-10-27 21:30:53,478724 (MainThread): Parsing macros/relations.sql
2020-10-27 21:30:53,480253 (MainThread): Parsing macros/adapters.sql
2020-10-27 21:30:53,488901 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 21:30:53,507601 (MainThread): Partial parsing not enabled
2020-10-27 21:30:53,521332 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:53,521472 (MainThread): Opening a new connection, currently in state init
2020-10-27 21:30:53,579404 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:30:53,579541 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_materialized).
2020-10-27 21:30:53,912678 (MainThread): scipy not found, skipping conversion test.
2020-10-27 21:30:53,914541 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 21:30:53,916826 (MainThread): 
2020-10-27 21:30:53,917196 (MainThread): Acquiring new postgres connection "master".
2020-10-27 21:30:53,917303 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_materialized_country).
2020-10-27 21:30:54,2805 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,2977 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-10-27 21:30:54,13073 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-10-27 21:30:54,41926 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,42108 (MainThread): On master: BEGIN
2020-10-27 21:30:54,44428 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:30:54,44637 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,44729 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 21:30:54,57822 (MainThread): SQL status: SELECT 2 in 0.01 seconds
2020-10-27 21:30:54,70206 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,70336 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 21:30:54,84827 (MainThread): SQL status: SELECT 0 in 0.01 seconds
2020-10-27 21:30:54,85798 (MainThread): On master: ROLLBACK
2020-10-27 21:30:54,86933 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,87040 (MainThread): On master: BEGIN
2020-10-27 21:30:54,89548 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:30:54,89713 (MainThread): On master: COMMIT
2020-10-27 21:30:54,89806 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,89883 (MainThread): On master: COMMIT
2020-10-27 21:30:54,91030 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 21:30:54,91314 (MainThread): 21:30:54 | Concurrency: 4 threads (target='dev')
2020-10-27 21:30:54,91506 (MainThread): 21:30:54 | 
2020-10-27 21:30:54,94968 (Thread-1): Began running node model.my_new_project.covid19_stats_materialized
2020-10-27 21:30:54,95172 (Thread-1): 21:30:54 | 1 of 1 START view model public.covid19_stats_materialized............ [RUN]
2020-10-27 21:30:54,95498 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,95598 (Thread-1): Opening a new connection, currently in state init
2020-10-27 21:30:54,106294 (Thread-1): Compiling model.my_new_project.covid19_stats_materialized
2020-10-27 21:30:54,120088 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats_materialized"
2020-10-27 21:30:54,120731 (Thread-1): finished collecting timing info
2020-10-27 21:30:54,152261 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,152414 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
drop view if exists "covid19"."public"."covid19_stats_materialized__dbt_tmp" cascade
2020-10-27 21:30:54,155035 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-27 21:30:54,157155 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,157258 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
drop view if exists "covid19"."public"."covid19_stats_materialized__dbt_backup" cascade
2020-10-27 21:30:54,158381 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-27 21:30:54,159816 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats_materialized"
2020-10-27 21:30:54,160214 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,160302 (Thread-1): On model.my_new_project.covid19_stats_materialized: BEGIN
2020-10-27 21:30:54,161474 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:30:54,161611 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,161849 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
create view "covid19"."public"."covid19_stats_materialized__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-27 21:30:54,176288 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-27 21:30:54,179536 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,179668 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
alter table "covid19"."public"."covid19_stats_materialized__dbt_tmp" rename to "covid19_stats_materialized"
2020-10-27 21:30:54,181049 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-27 21:30:54,181913 (Thread-1): On model.my_new_project.covid19_stats_materialized: COMMIT
2020-10-27 21:30:54,182011 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,182088 (Thread-1): On model.my_new_project.covid19_stats_materialized: COMMIT
2020-10-27 21:30:54,184936 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-27 21:30:54,186584 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:30:54,186687 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
drop view if exists "covid19"."public"."covid19_stats_materialized__dbt_backup" cascade
2020-10-27 21:30:54,187866 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-27 21:30:54,190168 (Thread-1): finished collecting timing info
2020-10-27 21:30:54,190746 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaf9174e-01c8-41f8-97d8-1dd994a054ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dba9820>]}
2020-10-27 21:30:54,688973 (Thread-1): 21:30:54 | 1 of 1 OK created view model public.covid19_stats_materialized....... [CREATE VIEW in 0.10s]
2020-10-27 21:30:54,689157 (Thread-1): Finished running node model.my_new_project.covid19_stats_materialized
2020-10-27 21:30:54,690344 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,690444 (MainThread): On master: BEGIN
2020-10-27 21:30:54,692125 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:30:54,692287 (MainThread): On master: COMMIT
2020-10-27 21:30:54,692367 (MainThread): Using postgres connection "master".
2020-10-27 21:30:54,692437 (MainThread): On master: COMMIT
2020-10-27 21:30:54,694027 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 21:30:54,694518 (MainThread): 21:30:54 | 
2020-10-27 21:30:54,694677 (MainThread): 21:30:54 | Finished running 1 view model in 0.78s.
2020-10-27 21:30:54,694796 (MainThread): Connection 'master' was left open.
2020-10-27 21:30:54,694869 (MainThread): On master: Close
2020-10-27 21:30:54,694973 (MainThread): Connection 'model.my_new_project.covid19_stats_materialized' was left open.
2020-10-27 21:30:54,695044 (MainThread): On model.my_new_project.covid19_stats_materialized: Close
2020-10-27 21:30:54,698668 (MainThread): 
2020-10-27 21:30:54,698845 (MainThread): Completed successfully
2020-10-27 21:30:54,698949 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-27 21:30:54,699123 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc199d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11deef220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11deef160>]}
2020-10-27 21:30:55,206647 (MainThread): Flushing usage events
2020-10-27 21:31:01,408115 (MainThread): Running with dbt=0.15.0
2020-10-27 21:31:01,482801 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 21:31:01,483280 (MainThread): Tracking: tracking
2020-10-27 21:31:01,495380 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d312dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d70d760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d7192e0>]}
2020-10-27 21:31:02,557379 (MainThread): Partial parsing not enabled
2020-10-27 21:31:02,559082 (MainThread): Parsing macros/core.sql
2020-10-27 21:31:02,562571 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 21:31:02,568379 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 21:31:02,569843 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 21:31:02,579184 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 21:31:02,594474 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 21:31:02,608840 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 21:31:02,610474 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 21:31:02,615858 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 21:31:02,621794 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 21:31:02,626970 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 21:31:02,631895 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 21:31:02,636047 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 21:31:02,636942 (MainThread): Parsing macros/etc/query.sql
2020-10-27 21:31:02,637963 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 21:31:02,639418 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 21:31:02,641168 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 21:31:02,647816 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 21:31:02,649483 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 21:31:02,671419 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 21:31:02,672484 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 21:31:02,673391 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 21:31:02,674349 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 21:31:02,676262 (MainThread): Parsing macros/catalog.sql
2020-10-27 21:31:02,677592 (MainThread): Parsing macros/relations.sql
2020-10-27 21:31:02,678621 (MainThread): Parsing macros/adapters.sql
2020-10-27 21:31:02,686179 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 21:31:02,703488 (MainThread): Partial parsing not enabled
2020-10-27 21:31:02,715970 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:31:02,716089 (MainThread): Opening a new connection, currently in state init
2020-10-27 21:31:02,760780 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:31:02,760913 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_materialized).
2020-10-27 21:31:02,977652 (MainThread): scipy not found, skipping conversion test.
2020-10-27 21:31:02,978969 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 21:31:02,980841 (MainThread): 
2020-10-27 21:31:02,981163 (MainThread): Acquiring new postgres connection "master".
2020-10-27 21:31:02,981345 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_materialized_country).
2020-10-27 21:31:03,79929 (MainThread): Using postgres connection "master".
2020-10-27 21:31:03,80096 (MainThread): On master: BEGIN
2020-10-27 21:31:03,83010 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:31:03,83195 (MainThread): Using postgres connection "master".
2020-10-27 21:31:03,83283 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 21:31:03,94671 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-27 21:31:03,115891 (MainThread): Using postgres connection "master".
2020-10-27 21:31:03,116055 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 21:31:03,129359 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 21:31:03,131547 (MainThread): On master: ROLLBACK
2020-10-27 21:31:03,133947 (MainThread): 21:31:03 | Concurrency: 4 threads (target='dev')
2020-10-27 21:31:03,134135 (MainThread): 21:31:03 | 
2020-10-27 21:31:03,137582 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_materialized_country
2020-10-27 21:31:03,137810 (Thread-1): 21:31:03 | 1 of 1 START test not_null_covid19_stats_materialized_country........ [RUN]
2020-10-27 21:31:03,138183 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:31:03,138320 (Thread-1): Opening a new connection, currently in state init
2020-10-27 21:31:03,161654 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_materialized_country
2020-10-27 21:31:03,178243 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_materialized_country"
2020-10-27 21:31:03,178702 (Thread-1): finished collecting timing info
2020-10-27 21:31:03,178972 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:31:03,179056 (Thread-1): On test.my_new_project.not_null_covid19_stats_materialized_country: BEGIN
2020-10-27 21:31:03,182267 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:31:03,182463 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:31:03,182560 (Thread-1): On test.my_new_project.not_null_covid19_stats_materialized_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_materialized_country"} */




select count(*)
from "covid19"."public"."covid19_stats_materialized"
where country is null

2020-10-27 21:31:03,187451 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-27 21:31:03,187790 (Thread-1): finished collecting timing info
2020-10-27 21:31:03,188045 (Thread-1): On test.my_new_project.not_null_covid19_stats_materialized_country: ROLLBACK
2020-10-27 21:31:03,189437 (Thread-1): 21:31:03 | 1 of 1 PASS not_null_covid19_stats_materialized_country.............. [PASS in 0.05s]
2020-10-27 21:31:03,189599 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_materialized_country
2020-10-27 21:31:03,190665 (MainThread): 21:31:03 | 
2020-10-27 21:31:03,190817 (MainThread): 21:31:03 | Finished running 1 test in 0.21s.
2020-10-27 21:31:03,190916 (MainThread): Connection 'master' was left open.
2020-10-27 21:31:03,190995 (MainThread): On master: Close
2020-10-27 21:31:03,191120 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_materialized_country' was left open.
2020-10-27 21:31:03,191195 (MainThread): On test.my_new_project.not_null_covid19_stats_materialized_country: Close
2020-10-27 21:31:03,194350 (MainThread): 
2020-10-27 21:31:03,194516 (MainThread): Completed successfully
2020-10-27 21:31:03,194628 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-27 21:31:03,194806 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fe4a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fe4a520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fe4a280>]}
2020-10-27 21:31:03,695092 (MainThread): Flushing usage events
2020-10-27 21:35:46,723324 (MainThread): Running with dbt=0.15.0
2020-10-27 21:35:46,802047 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-27 21:35:46,823179 (MainThread): Tracking: tracking
2020-10-27 21:35:46,837573 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11806bfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118467790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1184730a0>]}
2020-10-27 21:35:47,628559 (MainThread): Partial parsing not enabled
2020-10-27 21:35:47,630442 (MainThread): Parsing macros/core.sql
2020-10-27 21:35:47,634028 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 21:35:47,640344 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 21:35:47,642072 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 21:35:47,651681 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 21:35:47,666973 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 21:35:47,681230 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 21:35:47,683117 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 21:35:47,688585 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 21:35:47,694695 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 21:35:47,699930 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 21:35:47,705034 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 21:35:47,709357 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 21:35:47,710475 (MainThread): Parsing macros/etc/query.sql
2020-10-27 21:35:47,711712 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 21:35:47,713603 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 21:35:47,715808 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 21:35:47,722762 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 21:35:47,724880 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 21:35:47,747559 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 21:35:47,748977 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 21:35:47,750110 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 21:35:47,751330 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 21:35:47,753492 (MainThread): Parsing macros/catalog.sql
2020-10-27 21:35:47,755197 (MainThread): Parsing macros/relations.sql
2020-10-27 21:35:47,756496 (MainThread): Parsing macros/adapters.sql
2020-10-27 21:35:47,764746 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 21:35:47,783973 (MainThread): Partial parsing not enabled
2020-10-27 21:35:47,797528 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:47,797674 (MainThread): Opening a new connection, currently in state init
2020-10-27 21:35:47,845560 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:35:47,845701 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_materialized).
2020-10-27 21:35:48,166193 (MainThread): scipy not found, skipping conversion test.
2020-10-27 21:35:48,167624 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 21:35:48,169770 (MainThread): 
2020-10-27 21:35:48,170176 (MainThread): Acquiring new postgres connection "master".
2020-10-27 21:35:48,170292 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_materialized_country).
2020-10-27 21:35:48,267644 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,267812 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-10-27 21:35:48,273677 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-10-27 21:35:48,299169 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,299373 (MainThread): On master: BEGIN
2020-10-27 21:35:48,301682 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:35:48,301901 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,302037 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 21:35:48,317830 (MainThread): SQL status: SELECT 3 in 0.02 seconds
2020-10-27 21:35:48,337127 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,337308 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 21:35:48,351494 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 21:35:48,353477 (MainThread): On master: ROLLBACK
2020-10-27 21:35:48,354788 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,354926 (MainThread): On master: BEGIN
2020-10-27 21:35:48,357201 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:35:48,357357 (MainThread): On master: COMMIT
2020-10-27 21:35:48,357448 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,357524 (MainThread): On master: COMMIT
2020-10-27 21:35:48,358503 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 21:35:48,358817 (MainThread): 21:35:48 | Concurrency: 4 threads (target='dev')
2020-10-27 21:35:48,358945 (MainThread): 21:35:48 | 
2020-10-27 21:35:48,362678 (Thread-1): Began running node model.my_new_project.covid19_stats_materialized
2020-10-27 21:35:48,362847 (Thread-1): 21:35:48 | 1 of 1 START view model public.covid19_stats_materialized............ [RUN]
2020-10-27 21:35:48,363598 (Thread-1): Acquiring new postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,363701 (Thread-1): Opening a new connection, currently in state init
2020-10-27 21:35:48,373371 (Thread-1): Compiling model.my_new_project.covid19_stats_materialized
2020-10-27 21:35:48,386033 (Thread-1): Writing injected SQL for node "model.my_new_project.covid19_stats_materialized"
2020-10-27 21:35:48,386468 (Thread-1): finished collecting timing info
2020-10-27 21:35:48,416753 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,416906 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
drop view if exists "covid19"."public"."covid19_stats_materialized__dbt_tmp" cascade
2020-10-27 21:35:48,419463 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-27 21:35:48,421669 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,421781 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
drop view if exists "covid19"."public"."covid19_stats_materialized__dbt_backup" cascade
2020-10-27 21:35:48,424461 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-27 21:35:48,425918 (Thread-1): Writing runtime SQL for node "model.my_new_project.covid19_stats_materialized"
2020-10-27 21:35:48,426302 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,426394 (Thread-1): On model.my_new_project.covid19_stats_materialized: BEGIN
2020-10-27 21:35:48,427701 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:35:48,427852 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,427945 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
create view "covid19"."public"."covid19_stats_materialized__dbt_tmp" as (
    SELECT data #>> '{Country}' as country, 
                             day,
                             sum((data #>> '{Confirmed}')::int) as confirmed,
                             sum((data #>> '{Deaths}')::int) as deaths,
                             sum((data #>> '{Recovered}')::int) as recovered,   
                             sum((data #>> '{Active}')::int) as active
                      FROM covid19
                      GROUP BY country, day
  );

2020-10-27 21:35:48,436927 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-10-27 21:35:48,440988 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,441127 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
alter table "covid19"."public"."covid19_stats_materialized" rename to "covid19_stats_materialized__dbt_backup"
2020-10-27 21:35:48,443128 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-27 21:35:48,445431 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,445551 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
alter table "covid19"."public"."covid19_stats_materialized__dbt_tmp" rename to "covid19_stats_materialized"
2020-10-27 21:35:48,447273 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-10-27 21:35:48,448198 (Thread-1): On model.my_new_project.covid19_stats_materialized: COMMIT
2020-10-27 21:35:48,448306 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,448384 (Thread-1): On model.my_new_project.covid19_stats_materialized: COMMIT
2020-10-27 21:35:48,450468 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-10-27 21:35:48,452205 (Thread-1): Using postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:48,452309 (Thread-1): On model.my_new_project.covid19_stats_materialized: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.covid19_stats_materialized"} */
drop view if exists "covid19"."public"."covid19_stats_materialized__dbt_backup" cascade
2020-10-27 21:35:48,456244 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-10-27 21:35:48,458545 (Thread-1): finished collecting timing info
2020-10-27 21:35:48,459134 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8addbe9-a6a2-484e-b562-5d10947abb78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa7e910>]}
2020-10-27 21:35:48,963176 (Thread-1): 21:35:48 | 1 of 1 OK created view model public.covid19_stats_materialized....... [CREATE VIEW in 0.10s]
2020-10-27 21:35:48,963349 (Thread-1): Finished running node model.my_new_project.covid19_stats_materialized
2020-10-27 21:35:48,964535 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,964638 (MainThread): On master: BEGIN
2020-10-27 21:35:48,966173 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:35:48,966319 (MainThread): On master: COMMIT
2020-10-27 21:35:48,966403 (MainThread): Using postgres connection "master".
2020-10-27 21:35:48,966475 (MainThread): On master: COMMIT
2020-10-27 21:35:48,967948 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-10-27 21:35:48,968302 (MainThread): 21:35:48 | 
2020-10-27 21:35:48,968482 (MainThread): 21:35:48 | Finished running 1 view model in 0.80s.
2020-10-27 21:35:48,968599 (MainThread): Connection 'master' was left open.
2020-10-27 21:35:48,968675 (MainThread): On master: Close
2020-10-27 21:35:48,968815 (MainThread): Connection 'model.my_new_project.covid19_stats_materialized' was left open.
2020-10-27 21:35:48,968889 (MainThread): On model.my_new_project.covid19_stats_materialized: Close
2020-10-27 21:35:48,972431 (MainThread): 
2020-10-27 21:35:48,972619 (MainThread): Completed successfully
2020-10-27 21:35:48,972733 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-27 21:35:48,972919 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11adfa1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11adfa070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11adfa040>]}
2020-10-27 21:35:49,477060 (MainThread): Flushing usage events
2020-10-27 21:35:53,799666 (MainThread): Running with dbt=0.15.0
2020-10-27 21:35:53,878250 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/cdiniz/Projects/data-engineering/airflow-poc/dbt/ci_profiles', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 21:35:53,878718 (MainThread): Tracking: tracking
2020-10-27 21:35:53,891262 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a165cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a532e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a560790>]}
2020-10-27 21:35:54,424395 (MainThread): Partial parsing not enabled
2020-10-27 21:35:54,426123 (MainThread): Parsing macros/core.sql
2020-10-27 21:35:54,429602 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 21:35:54,435409 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 21:35:54,436802 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 21:35:54,446247 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 21:35:54,462014 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 21:35:54,476592 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 21:35:54,478373 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 21:35:54,483781 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 21:35:54,489692 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 21:35:54,494810 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 21:35:54,499736 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 21:35:54,503855 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 21:35:54,504739 (MainThread): Parsing macros/etc/query.sql
2020-10-27 21:35:54,505748 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 21:35:54,507239 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-10-27 21:35:54,509033 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 21:35:54,516107 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 21:35:54,517902 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 21:35:54,540195 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 21:35:54,541268 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 21:35:54,542109 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 21:35:54,543082 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 21:35:54,545043 (MainThread): Parsing macros/catalog.sql
2020-10-27 21:35:54,546373 (MainThread): Parsing macros/relations.sql
2020-10-27 21:35:54,547399 (MainThread): Parsing macros/adapters.sql
2020-10-27 21:35:54,555694 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-10-27 21:35:54,578701 (MainThread): Partial parsing not enabled
2020-10-27 21:35:54,592139 (MainThread): Acquiring new postgres connection "model.my_new_project.covid19_stats_materialized".
2020-10-27 21:35:54,592297 (MainThread): Opening a new connection, currently in state init
2020-10-27 21:35:54,654372 (MainThread): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:35:54,654529 (MainThread): Re-using an available connection from the pool (formerly model.my_new_project.covid19_stats_materialized).
2020-10-27 21:35:54,887734 (MainThread): scipy not found, skipping conversion test.
2020-10-27 21:35:54,889055 (MainThread): Found 1 model, 1 test, 0 snapshots, 0 analyses, 120 macros, 0 operations, 0 seed files, 0 sources
2020-10-27 21:35:54,890952 (MainThread): 
2020-10-27 21:35:54,891256 (MainThread): Acquiring new postgres connection "master".
2020-10-27 21:35:54,891344 (MainThread): Re-using an available connection from the pool (formerly test.my_new_project.not_null_covid19_stats_materialized_country).
2020-10-27 21:35:54,985474 (MainThread): Using postgres connection "master".
2020-10-27 21:35:54,985622 (MainThread): On master: BEGIN
2020-10-27 21:35:54,988307 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:35:54,988481 (MainThread): Using postgres connection "master".
2020-10-27 21:35:54,988569 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
select
      'covid19' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'covid19' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-10-27 21:35:54,997702 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-10-27 21:35:55,17421 (MainThread): Using postgres connection "master".
2020-10-27 21:35:55,17556 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-10-27 21:35:55,26764 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-10-27 21:35:55,28718 (MainThread): On master: ROLLBACK
2020-10-27 21:35:55,30164 (MainThread): 21:35:55 | Concurrency: 4 threads (target='dev')
2020-10-27 21:35:55,30316 (MainThread): 21:35:55 | 
2020-10-27 21:35:55,33037 (Thread-1): Began running node test.my_new_project.not_null_covid19_stats_materialized_country
2020-10-27 21:35:55,33208 (Thread-1): 21:35:55 | 1 of 1 START test not_null_covid19_stats_materialized_country........ [RUN]
2020-10-27 21:35:55,33478 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:35:55,33570 (Thread-1): Opening a new connection, currently in state init
2020-10-27 21:35:55,43565 (Thread-1): Compiling test.my_new_project.not_null_covid19_stats_materialized_country
2020-10-27 21:35:55,57778 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_covid19_stats_materialized_country"
2020-10-27 21:35:55,58165 (Thread-1): finished collecting timing info
2020-10-27 21:35:55,58436 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:35:55,58529 (Thread-1): On test.my_new_project.not_null_covid19_stats_materialized_country: BEGIN
2020-10-27 21:35:55,61551 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-10-27 21:35:55,61730 (Thread-1): Using postgres connection "test.my_new_project.not_null_covid19_stats_materialized_country".
2020-10-27 21:35:55,61821 (Thread-1): On test.my_new_project.not_null_covid19_stats_materialized_country: /* {"app": "dbt", "dbt_version": "0.15.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_covid19_stats_materialized_country"} */




select count(*)
from "covid19"."public"."covid19_stats_materialized"
where country is null

2020-10-27 21:35:55,66813 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2020-10-27 21:35:55,67140 (Thread-1): finished collecting timing info
2020-10-27 21:35:55,67397 (Thread-1): On test.my_new_project.not_null_covid19_stats_materialized_country: ROLLBACK
2020-10-27 21:35:55,68850 (Thread-1): 21:35:55 | 1 of 1 PASS not_null_covid19_stats_materialized_country.............. [PASS in 0.04s]
2020-10-27 21:35:55,69030 (Thread-1): Finished running node test.my_new_project.not_null_covid19_stats_materialized_country
2020-10-27 21:35:55,70932 (MainThread): 21:35:55 | 
2020-10-27 21:35:55,71204 (MainThread): 21:35:55 | Finished running 1 test in 0.18s.
2020-10-27 21:35:55,71321 (MainThread): Connection 'master' was left open.
2020-10-27 21:35:55,71406 (MainThread): On master: Close
2020-10-27 21:35:55,71525 (MainThread): Connection 'test.my_new_project.not_null_covid19_stats_materialized_country' was left open.
2020-10-27 21:35:55,71869 (MainThread): On test.my_new_project.not_null_covid19_stats_materialized_country: Close
2020-10-27 21:35:55,77330 (MainThread): 
2020-10-27 21:35:55,77528 (MainThread): Completed successfully
2020-10-27 21:35:55,77897 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-27 21:35:55,78397 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cbc3a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cbc3fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ccab190>]}
2020-10-27 21:35:55,585833 (MainThread): Flushing usage events
